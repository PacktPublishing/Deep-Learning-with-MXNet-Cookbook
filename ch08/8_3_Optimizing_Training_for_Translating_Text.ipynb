{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de6b5fce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "117850d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import gluonnlp as nlp\n",
    "from mxnet.contrib import amp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import sacremoses\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import io\n",
    "from importlib import reload\n",
    "\n",
    "# Local Libraries\n",
    "import nmt\n",
    "import dataprocessor\n",
    "import utils\n",
    "import nmt.transformer_hparams\n",
    "import transformer_model\n",
    "\n",
    "# Hyperparameters for Dataloaders and Training\n",
    "hparams = nmt.transformer_hparams\n",
    "\n",
    "# Seeds for reproducibility\n",
    "np.random.seed(100)\n",
    "random.seed(100)\n",
    "mx.random.seed(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3974c42d",
   "metadata": {},
   "source": [
    "##Â Dataset Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99204447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WMT2016 Dataset\n",
    "src_lang, tgt_lang = \"en\", \"de\"\n",
    "\n",
    "wmt2016_train_data = nlp.data.WMT2016BPE(\n",
    "    'train',\n",
    "    src_lang=src_lang,\n",
    "    tgt_lang=tgt_lang)\n",
    "\n",
    "wmt2016_val_data = nlp.data.WMT2016BPE(\n",
    "    'newstest2016',\n",
    "    src_lang=src_lang,\n",
    "    tgt_lang=tgt_lang)\n",
    "\n",
    "wmt2016_test_data = nlp.data.WMT2016BPE(\n",
    "    'newstest2016',\n",
    "    src_lang=src_lang,\n",
    "    tgt_lang=tgt_lang)\n",
    "\n",
    "# Text sentences for evaluation\n",
    "wmt2016_val_text = nlp.data.WMT2016(\n",
    "    'newstest2016',\n",
    "    src_lang=src_lang,\n",
    "    tgt_lang=tgt_lang)\n",
    "\n",
    "wmt2016_test_text = nlp.data.WMT2016(\n",
    "    'newstest2016',\n",
    "    src_lang=src_lang,\n",
    "    tgt_lang=tgt_lang)\n",
    "\n",
    "src_max_len, tgt_max_len = 50, 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66cb8581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data test\n",
    "# train_length = 100000\n",
    "train_length = 5000\n",
    "wmt2016_train_data._data[0] = wmt2016_train_data._data[0][:train_length]\n",
    "wmt2016_train_data._data[1] = wmt2016_train_data._data[1][:train_length]\n",
    "wmt2016_train_data._length = train_length\n",
    "\n",
    "# Split Val / Test sets\n",
    "val_length = 1500\n",
    "test_length = len(wmt2016_test_text) - val_length\n",
    "\n",
    "wmt2016_val_data._data[0] = wmt2016_val_data._data[0][:val_length]\n",
    "wmt2016_val_data._data[1] = wmt2016_val_data._data[1][:val_length]\n",
    "wmt2016_val_data._length = val_length\n",
    "\n",
    "wmt2016_val_text._data[0] = wmt2016_val_text._data[0][:val_length]\n",
    "wmt2016_val_text._data[1] = wmt2016_val_text._data[1][:val_length]\n",
    "wmt2016_val_text._length = val_length\n",
    "\n",
    "wmt2016_test_data._data[0] = wmt2016_test_data._data[0][-test_length:]\n",
    "wmt2016_test_data._data[1] = wmt2016_test_data._data[1][-test_length:]\n",
    "wmt2016_test_data._length = test_length\n",
    "\n",
    "wmt2016_test_text._data[0] = wmt2016_test_text._data[0][-test_length:]\n",
    "wmt2016_test_text._data[1] = wmt2016_test_text._data[1][-test_length:]\n",
    "wmt2016_test_text._length = test_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "362bfba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train set: 5000\n",
      "Length of val set  : 1500\n",
      "Length of test set : 1499\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of train set:\", len(wmt2016_train_data))\n",
    "print(\"Length of val set  :\", len(wmt2016_val_data))\n",
    "print(\"Length of test set :\", len(wmt2016_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6971c960",
   "metadata": {},
   "outputs": [],
   "source": [
    "wmt2016_val_tgt_sentences = wmt2016_val_text.transform(lambda src, tgt: tgt, lazy=False)\n",
    "wmt2016_test_tgt_sentences = wmt2016_test_text.transform(lambda src, tgt: tgt, lazy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fcb0b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ext_andres_pereztorres_oxbotica_/.local/lib/python3.9/site-packages/gluonnlp/vocab/vocab.py:590: UserWarning: Detected a corrupted index in the deserialize vocabulary. For versions before GluonNLP v0.7 the index is corrupted by specifying the same token for different special purposes, for example eos_token == padding_token. Deserializing the vocabulary nevertheless.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "reload(transformer_model)\n",
    "\n",
    "# For vocab\n",
    "wmt_model_name = \"transformer_en_de_512\"\n",
    "_, wmt_src_vocab, wmt_tgt_vocab = nlp.model.get_model(\n",
    "    wmt_model_name,\n",
    "    dataset_name='WMT2014',\n",
    "    pretrained=True,\n",
    "    ctx=mx.cpu())\n",
    "\n",
    "# Pre-processing WMT2016\n",
    "wmt_transform_fn = dataprocessor.TrainValDataTransform(\n",
    "    # wmt2016_train_data.src_vocab,\n",
    "    # wmt2016_train_data.tgt_vocab,\n",
    "    wmt_src_vocab,\n",
    "    wmt_tgt_vocab,\n",
    "    src_max_len,\n",
    "    tgt_max_len)\n",
    "\n",
    "wmt2016_train_data_processed = wmt2016_train_data.transform(\n",
    "    wmt_transform_fn)\n",
    "\n",
    "wmt2016_val_data_processed = wmt2016_val_data.transform(\n",
    "    wmt_transform_fn)\n",
    "\n",
    "wmt2016_test_data_processed = wmt2016_test_data.transform(\n",
    "    wmt_transform_fn)\n",
    "\n",
    "wmt2016_train_data_lengths = transformer_model.get_data_lengths(wmt2016_train_data_processed)\n",
    "wmt2016_val_data_lengths = transformer_model.get_data_lengths(wmt2016_val_data_processed)\n",
    "wmt2016_test_data_lengths = transformer_model.get_data_lengths(wmt2016_test_data_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74c35966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Lengths to the datasets and indexes for validation and test\n",
    "wmt2016_train_data_len_processed = wmt2016_train_data_processed.transform(lambda src, tgt: (src, tgt, len(src), len(tgt)), lazy=False)\n",
    "wmt2016_val_data_len_processed = wmt2016_val_data_processed.transform(transformer_model.get_length_index_fn(), lazy=False)\n",
    "wmt2016_test_data_len_processed = wmt2016_test_data_processed.transform(transformer_model.get_length_index_fn(), lazy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6d2c5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batchify_fn = nlp.data.batchify.Tuple(\n",
    "    nlp.data.batchify.Pad(pad_val=0),\n",
    "    nlp.data.batchify.Pad(pad_val=0),\n",
    "    nlp.data.batchify.Stack(dtype='float32'),\n",
    "    nlp.data.batchify.Stack(dtype='float32'))\n",
    "\n",
    "val_batchify_fn = nlp.data.batchify.Tuple(\n",
    "    nlp.data.batchify.Pad(pad_val=0),\n",
    "    nlp.data.batchify.Pad(pad_val=0),\n",
    "    nlp.data.batchify.Stack(dtype='float32'),\n",
    "    nlp.data.batchify.Stack(dtype='float32'),\n",
    "    nlp.data.batchify.Stack())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b31ad55",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(transformer_model)\n",
    "\n",
    "bucket_scheme = nlp.data.ExpWidthBucket(bucket_len_step=1.2)\n",
    "\n",
    "wmt2016_train_batch_sampler = nlp.data.FixedBucketSampler(\n",
    "    lengths=wmt2016_train_data_lengths,\n",
    "    use_average_length=True, # control the element lengths (i.e. number of tokens) to be about the same\n",
    "    num_buckets=hparams.num_buckets,\n",
    "    bucket_scheme=bucket_scheme,\n",
    "    batch_size=hparams.batch_size,\n",
    "    shuffle=True)\n",
    "\n",
    "wmt2016_val_batch_sampler = nlp.data.FixedBucketSampler(\n",
    "    lengths=wmt2016_val_data_lengths,\n",
    "    use_average_length=True, # control the element lengths (i.e. number of tokens) to be about the same\n",
    "    num_buckets=hparams.num_buckets,\n",
    "    bucket_scheme=bucket_scheme,\n",
    "    batch_size=hparams.test_batch_size,\n",
    "    shuffle=False)\n",
    "\n",
    "wmt2016_test_batch_sampler = nlp.data.FixedBucketSampler(\n",
    "    lengths=wmt2016_test_data_lengths,\n",
    "    use_average_length=True, # control the element lengths (i.e. number of tokens) to be about the same\n",
    "    num_buckets=hparams.num_buckets,\n",
    "    bucket_scheme=bucket_scheme,\n",
    "    batch_size=hparams.batch_size,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b1c3f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 0\n",
    "\n",
    "wmt2016_train_data_loader = nlp.data.ShardedDataLoader(\n",
    "    wmt2016_train_data_len_processed,\n",
    "    batch_sampler=wmt2016_train_batch_sampler,\n",
    "    batchify_fn=train_batchify_fn,\n",
    "    num_workers=num_workers)\n",
    "\n",
    "wmt2016_val_data_loader = nlp.data.ShardedDataLoader(\n",
    "    wmt2016_val_data_len_processed,\n",
    "    batch_sampler=wmt2016_val_batch_sampler,\n",
    "    batchify_fn=val_batchify_fn,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=False)\n",
    "\n",
    "wmt2016_test_data_loader = nlp.data.ShardedDataLoader(\n",
    "    wmt2016_test_data_len_processed,\n",
    "    batch_sampler=wmt2016_test_batch_sampler,\n",
    "    batchify_fn=val_batchify_fn,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf43455",
   "metadata": {},
   "source": [
    "## Naive Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "404f3720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single GPU training\n",
    "ctx_list = [mx.gpu(0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c5a5fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20:43:26] /work/mxnet/src/base.cc:79: cuDNN lib mismatch: linked-against version 8200 != compiled-against version 8201.  Set MXNET_CUDNN_LIB_CHECKING=0 to quiet this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Vocab: 36794 , Target Vocab: 36794\n"
     ]
    }
   ],
   "source": [
    "# Build on top of Pre-Trained model\n",
    "wmt_model_name = 'transformer_en_de_512'\n",
    "wmt_transformer_model_ft_direct, _, _ = nlp.model.get_model(\n",
    "    wmt_model_name,\n",
    "    dataset_name='WMT2014',\n",
    "    pretrained=True,\n",
    "    ctx=ctx_list)\n",
    "\n",
    "print('Source Vocab:', len(wmt_src_vocab), ', Target Vocab:', len(wmt_tgt_vocab))\n",
    "\n",
    "# No need to re-configure last layer, just re-initialize\n",
    "# wmt_transformer_model_ft_direct.tgt_proj.initialize(ctx=ctx, force_reinit=True)\n",
    "\n",
    "model_filename_ft_direct = \"transformer_en_de_512_ft_direct.params\"\n",
    "\n",
    "wmt_translator_ft_direct = nmt.translation.BeamSearchTranslator(\n",
    "    model=wmt_transformer_model_ft_direct,\n",
    "    beam_size=hparams.beam_size,\n",
    "    scorer=nlp.model.BeamSearchScorer(alpha=hparams.lp_alpha, K=hparams.lp_k),\n",
    "    max_length=200)\n",
    "\n",
    "# hparams.epochs = 10\n",
    "hparams.epochs = 2\n",
    "hparams.lr = 0.00003\n",
    "hparams.log_interval = 100\n",
    "\n",
    "loss_function = nlp.loss.MaskedSoftmaxCELoss()\n",
    "\n",
    "wmt_detokenizer = nlp.data.SacreMosesDetokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6984010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec1343cee9e54c2391160371b37c8e35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b706a9ed9e049d5a021f242491e0c6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/184 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 100/748] loss=1.7004, ppl=5.4762, throughput=4.56K wps, wc=43.96K\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "644944e8e2cc4d05a51cdf0df20fd08c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1030 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_59661/20877163.py\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;31m# Validation step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     wmt2016_valid_loss, wmt2016_valid_translation_out = transformer_model.evaluate(\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0mwmt_transformer_model_ft_direct\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mwmt2016_val_data_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/public/Deep-Learning-with-MXNet-Cookbook/ch08/transformer_model.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, data_loader, test_loss_function, translator, tgt_vocab, detokenizer, ctx)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# Translate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_valid_length\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0mtranslator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_seq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_valid_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_valid_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mmax_score_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/public/Deep-Learning-with-MXNet-Cookbook/ch08/nmt/translation.py\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(self, src_seq, src_valid_length)\u001b[0m\n\u001b[1;32m     79\u001b[0m         inputs = mx.nd.full(shape=(batch_size,), ctx=src_seq.context, dtype=np.float32,\n\u001b[1;32m     80\u001b[0m                             val=self._model.tgt_vocab.token_to_idx[self._model.tgt_vocab.bos_token])\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_valid_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_valid_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/gluonnlp/model/sequence_sampler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, states)\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m             \u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m             \u001b[0mvocab_size_nd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlog_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             batch_shift_nd = mx.nd.arange(0, batch_size * beam_size, beam_size, ctx=ctx,\n",
      "\u001b[0;32m~/code/public/Deep-Learning-with-MXNet-Cookbook/ch08/nmt/translation.py\u001b[0m in \u001b[0;36m_decode_logprob\u001b[0;34m(self, step_input, states)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_decode_logprob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/gluonnlp/model/translation.py\u001b[0m in \u001b[0;36mdecode_step\u001b[0;34m(self, step_input, states)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \"\"\"\n\u001b[1;32m    188\u001b[0m         \u001b[0mstep_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_additional_outputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_step_ahead_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtgt_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         \u001b[0mstep_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtgt_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstep_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_additional_outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    823\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/gluonnlp/model/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, step_input, states)\u001b[0m\n\u001b[1;32m    830\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhybrid_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m   1500\u001b[0m                     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reg_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1502\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhybrid_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1503\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reg_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1504\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/gluonnlp/model/transformer.py\u001b[0m in \u001b[0;36mhybrid_forward\u001b[0;34m(self, F, inputs, states, position_weight)\u001b[0m\n\u001b[1;32m    856\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m         \"\"\"\n\u001b[0;32m--> 858\u001b[0;31m         outputs, states, additional_outputs = super().hybrid_forward(\n\u001b[0m\u001b[1;32m    859\u001b[0m             F, inputs, states, valid_length=None, position_weight=position_weight)\n\u001b[1;32m    860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/gluonnlp/model/transformer.py\u001b[0m in \u001b[0;36mhybrid_forward\u001b[0;34m(self, F, inputs, states, valid_length, position_weight)\u001b[0m\n\u001b[1;32m    710\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_cells\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m             \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    713\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_attention\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m                 \u001b[0mattention_weights_l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    823\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m   1500\u001b[0m                     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reg_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1502\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhybrid_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1503\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reg_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1504\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/gluonnlp/model/transformer.py\u001b[0m in \u001b[0;36mhybrid_forward\u001b[0;34m(self, F, inputs, mem_value, mask, mem_mask)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \"\"\"\n\u001b[1;32m    558\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_in_outputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_cell_in\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproj_in\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dropout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/gluonnlp/model/attention_cell.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, query, key, value, mask)\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mShape\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \"\"\"\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMultiHeadAttentionCell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_project\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/gluonnlp/model/attention_cell.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, query, key, value, mask)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0mAttention\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mShape\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \"\"\"\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAttentionCell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhybrid_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=arguments-differ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    823\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m   1500\u001b[0m                     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reg_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1502\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhybrid_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1503\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reg_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1504\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/gluonnlp/model/attention_cell.py\u001b[0m in \u001b[0;36mhybrid_forward\u001b[0;34m(self, F, query, key, value, mask)\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0matt_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0mcontext_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_by_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matt_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcontext_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matt_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/gluonnlp/model/attention_cell.py\u001b[0m in \u001b[0;36m_read_by_weight\u001b[0;34m(self, F, att_weights, value)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_by_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matt_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0matt_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matt_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_project\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'value'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m         \u001b[0mcontext_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base_cell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_by_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matt_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         context_vec = F.transpose(context_vec.reshape(shape=(-1, self._num_heads, 0, 0),\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/gluonnlp/model/attention_cell.py\u001b[0m in \u001b[0;36m_project\u001b[0;34m(self, F, name, x)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_project\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;31m# Shape (batch_size, query_length, query_units)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'proj_{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m         \u001b[0;31m# Shape (batch_size * num_heads, query_length, ele_units)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         x = F.transpose(x.reshape(shape=(0, 0, self._num_heads, -1)),\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    823\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m   1500\u001b[0m                     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reg_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1502\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhybrid_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1503\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reg_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1504\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/mxnet/gluon/nn/basic_layers.py\u001b[0m in \u001b[0;36mhybrid_forward\u001b[0;34m(self, F, x, weight, bias)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhybrid_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0mfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfully_connected\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_np_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFullyConnected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         act = fc(x, weight, bias, no_bias=bias is None, num_hidden=self._units,\n\u001b[0m\u001b[1;32m    225\u001b[0m                  flatten=self._flatten, name='fwd')\n\u001b[1;32m    226\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/mxnet/ndarray/register.py\u001b[0m in \u001b[0;36mFullyConnected\u001b[0;34m(data, weight, bias, num_hidden, no_bias, flatten, out, name, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/mxnet/ndarray/register.py\u001b[0m in \u001b[0;36m_verify_all_legacy_ndarrays\u001b[0;34m(op_name, func_name, args, out)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mUser\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mprovided\u001b[0m \u001b[0moutput\u001b[0m \u001b[0mndarrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \"\"\"\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mndarray\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp_ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp_ndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reload(transformer_model)\n",
    "\n",
    "# Let's train\n",
    "trainer = mx.gluon.Trainer(wmt_transformer_model_ft_direct.collect_params(), hparams.optimizer, {'learning_rate': hparams.lr})\n",
    "\n",
    "best_valid_bleu = 0.0\n",
    "\n",
    "wmt2016_train_losses = []\n",
    "wmt2016_valid_losses = []\n",
    "wmt2016_valid_bleus  = []\n",
    "wmt2016_valid_perplexities = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch_id in tqdm(range(hparams.epochs)):\n",
    "\n",
    "    acc_train_loss_batch = 0\n",
    "    log_loss = 0\n",
    "    log_denom = 0\n",
    "    log_wc = 0\n",
    "    log_start_time = time.time()\n",
    "\n",
    "    # Iterate through each batch\n",
    "    for batch_id, (src_seq, tgt_seq, src_valid_length, tgt_valid_length) in enumerate(tqdm(wmt2016_train_data_loader)):\n",
    "\n",
    "        src_seq = src_seq.as_in_context(ctx_list[0])\n",
    "        tgt_seq = tgt_seq.as_in_context(ctx_list[0])\n",
    "        src_valid_length = src_valid_length.as_in_context(ctx_list[0])\n",
    "        tgt_valid_length = tgt_valid_length.as_in_context(ctx_list[0])\n",
    "        \n",
    "        with mx.autograd.record():\n",
    "            out, _ = wmt_transformer_model_ft_direct(\n",
    "                src_seq,\n",
    "                tgt_seq[:, :-1],\n",
    "                src_valid_length,\n",
    "                tgt_valid_length - 1)\n",
    "\n",
    "            loss = loss_function(out, tgt_seq[:, 1:], tgt_valid_length - 1).mean()\n",
    "            \n",
    "            loss.backward()\n",
    "            loss = loss * (tgt_seq.shape[1] - 1)\n",
    "            log_loss += loss * tgt_seq.shape[0]\n",
    "            log_denom += (tgt_valid_length - 1).sum()\n",
    "            loss = loss / (tgt_valid_length - 1).mean()\n",
    "\n",
    "        trainer.step(1)\n",
    "        \n",
    "        src_wc = src_valid_length.sum().asscalar()\n",
    "        tgt_wc = (tgt_valid_length - 1).sum().asscalar()\n",
    "        log_loss = log_loss.asscalar()\n",
    "        log_denom = log_denom.asscalar()\n",
    "        log_wc += src_wc + tgt_wc\n",
    "        \n",
    "        train_loss = log_loss / log_denom\n",
    "        acc_train_loss_batch += train_loss\n",
    "        \n",
    "        if (batch_id + 1) % hparams.log_interval == 0:\n",
    "            wps = log_wc / (time.time() - log_start_time)\n",
    "            print(\"[Epoch {} Batch {}/{}] loss={:.4f}, ppl={:.4f}, \"\n",
    "                         \"throughput={:.2f}K wps, wc={:.2f}K\"\n",
    "                         .format(epoch_id, batch_id + 1, len(wmt2016_train_data_loader),\n",
    "                                 train_loss,\n",
    "                                 np.exp(log_loss / log_denom),\n",
    "                                 wps / 1000, log_wc / 1000))\n",
    "            \n",
    "            log_start_time = time.time()\n",
    "            log_loss = 0\n",
    "            log_denom = 0\n",
    "            log_avg_gnorm = 0\n",
    "            log_wc = 0\n",
    "\n",
    "    wmt2016_train_loss = acc_train_loss_batch / len(wmt2016_train_data_loader)\n",
    "    wmt2016_train_losses.append(wmt2016_train_loss)\n",
    "    \n",
    "    # Validation step\n",
    "    wmt2016_valid_loss, wmt2016_valid_translation_out = transformer_model.evaluate(\n",
    "        wmt_transformer_model_ft_direct,\n",
    "        wmt2016_val_data_loader,\n",
    "        loss_function,\n",
    "        wmt_translator_ft_direct,\n",
    "        # wmt2016_train_data.tgt_vocab,\n",
    "        wmt_tgt_vocab,\n",
    "        wmt_detokenizer,\n",
    "        ctx_list[0])\n",
    "\n",
    "    wmt2016_valid_bleu_score, _, _, _, _ = nmt.bleu.compute_bleu(\n",
    "        [wmt2016_val_tgt_sentences],\n",
    "        wmt2016_valid_translation_out,\n",
    "        tokenized=False,\n",
    "        tokenizer=\"13a\",\n",
    "        split_compound_word=False,\n",
    "        bpe=False)\n",
    "    \n",
    "    wmt2016_valid_perplexity = np.exp(wmt2016_valid_loss)\n",
    "    wmt2016_valid_perplexities.append(wmt2016_valid_perplexity)\n",
    "    wmt2016_valid_losses.append(wmt2016_valid_loss)\n",
    "    wmt2016_valid_bleus.append(wmt2016_valid_bleu_score * 100)\n",
    "    \n",
    "    print(\"[Epoch {}] valid Loss={:.4f}, valid ppl={:.4f}, valid bleu={:.2f}\"\n",
    "          .format(epoch_id, wmt2016_valid_loss, wmt2016_valid_perplexity, wmt2016_valid_bleu_score * 100))\n",
    "    \n",
    "    if wmt2016_valid_bleu_score > best_valid_bleu:\n",
    "        best_valid_bleu = wmt2016_valid_bleu_score\n",
    "        print(\"Save best parameters to {}\".format(model_filename_ft_direct))\n",
    "        wmt_transformer_model_ft_direct.save_parameters(model_filename_ft_direct)\n",
    "    \n",
    "print(\"Training time for 10 epochs:\", time.time() - start_time, \"/ Best validation loss:\", min(wmt2016_valid_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7076f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the losses\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, hparams.epochs), wmt2016_valid_losses, label=\"Validation Loss\")\n",
    "plt.plot(np.arange(0, hparams.epochs), wmt2016_train_losses, label=\"Training Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"Losses\")\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccb7318",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c04b73",
   "metadata": {},
   "source": [
    "#### Quantitative Evaluation: Test Loss and BLEU score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a25b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantitative Evaluation\n",
    "# Load best model\n",
    "wmt_transformer_model_ft_direct.load_parameters(model_filename_ft_direct)\n",
    "\n",
    "wmt2016_test_loss, wmt2016_test_translation_out = transformer_model.evaluate(\n",
    "    wmt_transformer_model_ft_direct,\n",
    "    wmt2016_test_data_loader,\n",
    "    loss_function,\n",
    "    wmt_translator_ft_direct,\n",
    "    wmt_tgt_vocab,\n",
    "    wmt_detokenizer,\n",
    "    ctx_list[0])\n",
    "\n",
    "wmt2016_test_bleu_score, _, _, _, _ = nmt.bleu.compute_bleu(\n",
    "    [wmt2016_test_tgt_sentences],\n",
    "    wmt2016_test_translation_out,\n",
    "    tokenized=False,\n",
    "    tokenizer=\"13a\",\n",
    "    split_compound_word=False,\n",
    "    bpe=False)\n",
    "\n",
    "print('WMT16 test loss: %.2f; test bleu score: %.2f'\n",
    "      %(wmt2016_test_loss, wmt2016_test_bleu_score * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8f57d8",
   "metadata": {},
   "source": [
    "#### Qualitative Evaluation: Translation from English to German Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c607c341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qualitative Evaluation\n",
    "reload(transformer_model)\n",
    "\n",
    "print(\"Qualitative Evaluation: Translating from English to German\")\n",
    "\n",
    "# From Google Translate\n",
    "expected_tgt_seq = \"Ich lerne neue Dinge jeden Tag.\"\n",
    "print(\"Expected translation:\")\n",
    "print(expected_tgt_seq)\n",
    "\n",
    "src_seq = \"I learn new things every day.\"\n",
    "print(\"In English:\")\n",
    "print(src_seq)\n",
    "\n",
    "# translation_out = nmt.utils.translate_with_unk(\n",
    "# translation_out = nmt.utils.translate(\n",
    "translation_out = transformer_model.translate(\n",
    "    wmt_translator_ft_direct,\n",
    "    src_seq,\n",
    "    # wmt2016_train_data.src_vocab,\n",
    "    # wmt2016_train_data.tgt_vocab,\n",
    "    wmt_src_vocab,\n",
    "    wmt_tgt_vocab,\n",
    "    wmt_detokenizer,\n",
    "    ctx_list[0])\n",
    "\n",
    "print(\"The German translation is:\")\n",
    "print(\" \".join(translation_out[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f7a93e",
   "metadata": {},
   "source": [
    "## Optimal Data Loading: CPU/GPU Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab3dbc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Context variable is now a list,\n",
    "# with each element corresponding to a GPU device\n",
    "ctx_list = [mx.gpu(0), mx.gpu(1), mx.gpu(2), mx.gpu(3)]\n",
    "num_gpus = len(ctx_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "173daaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From strings converted to ND arrays,\n",
    "# we can continue processing in GPU\n",
    "# wmt2016_train_data_processed_gpu = mx.gluon.data.SimpleDataset(\n",
    "#     [(mx.nd.array(data).as_in_context(ctx_list[idx % num_gpus]), mx.nd.array(label).as_in_context(ctx_list[idx % num_gpus])) \n",
    "#      for idx, (data, label) in enumerate(wmt2016_train_data_processed)])\n",
    "\n",
    "# wmt2016_val_data_processed_gpu = mx.gluon.data.SimpleDataset(\n",
    "#     [(mx.nd.array(data).as_in_context(ctx_list[idx % num_gpus]), mx.nd.array(label).as_in_context(ctx_list[idx % num_gpus])) \n",
    "#      for idx, (data, label) in enumerate(wmt2016_val_data_processed)])\n",
    "\n",
    "# wmt2016_test_data_processed_gpu = mx.gluon.data.SimpleDataset(\n",
    "#     [(mx.nd.array(data).as_in_context(ctx_list[idx % num_gpus]), mx.nd.array(label).as_in_context(ctx_list[idx % num_gpus])) \n",
    "#      for idx, (data, label) in enumerate(wmt2016_test_data_processed)])\n",
    "\n",
    "# Pre-processing in CPU to free GPU memory\n",
    "wmt2016_train_data_processed_gpu = wmt2016_train_data_processed\n",
    "wmt2016_val_data_processed_gpu = wmt2016_val_data_processed\n",
    "wmt2016_test_data_processed_gpu = wmt2016_test_data_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "971e2bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "wmt2016_train_data_len_processed_gpu = wmt2016_train_data_processed_gpu.transform(lambda src, tgt: (src, tgt, len(src), len(tgt)), lazy=False)\n",
    "wmt2016_val_data_len_processed_gpu = wmt2016_val_data_processed_gpu.transform(transformer_model.get_length_index_fn(), lazy=False)\n",
    "wmt2016_test_data_len_processed_gpu = wmt2016_test_data_processed_gpu.transform(transformer_model.get_length_index_fn(), lazy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86cadbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(transformer_model)\n",
    "\n",
    "bucket_scheme = nlp.data.ExpWidthBucket(bucket_len_step=1.2)\n",
    "\n",
    "wmt2016_train_batch_sampler_gpu = nlp.data.FixedBucketSampler(\n",
    "    lengths=wmt2016_train_data_lengths,\n",
    "    use_average_length=True, # control the element lengths (i.e. number of tokens) to be about the same\n",
    "#     use_average_length=False,\n",
    "    bucket_scheme=bucket_scheme,\n",
    "    batch_size=hparams.batch_size * 16,\n",
    "    shuffle=True)\n",
    "\n",
    "wmt2016_val_batch_sampler_gpu = nlp.data.FixedBucketSampler(\n",
    "    lengths=wmt2016_val_data_lengths,\n",
    "    use_average_length=True, # control the element lengths (i.e. number of tokens) to be about the same\n",
    "#     use_average_length=False,\n",
    "    num_buckets=hparams.num_buckets,\n",
    "    bucket_scheme=bucket_scheme,\n",
    "    batch_size=hparams.batch_size * 16,\n",
    "    shuffle=False)\n",
    "\n",
    "wmt2016_test_batch_sampler_gpu = nlp.data.FixedBucketSampler(\n",
    "    lengths=wmt2016_test_data_lengths,\n",
    "    use_average_length=True, # control the element lengths (i.e. number of tokens) to be about the same\n",
    "#     use_average_length=False,\n",
    "    num_buckets=hparams.num_buckets,\n",
    "    bucket_scheme=bucket_scheme,\n",
    "    batch_size=hparams.batch_size * 16,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "476721fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 0\n",
    "\n",
    "wmt2016_train_data_loader_gpu = mx.gluon.data.DataLoader(\n",
    "    wmt2016_train_data_len_processed_gpu,\n",
    "    batch_sampler=wmt2016_train_batch_sampler_gpu,\n",
    "    batchify_fn=train_batchify_fn,\n",
    "    num_workers=num_workers)\n",
    "\n",
    "wmt2016_val_data_loader_gpu = mx.gluon.data.DataLoader(\n",
    "    wmt2016_val_data_len_processed_gpu,\n",
    "    batch_sampler=wmt2016_val_batch_sampler_gpu,\n",
    "    batchify_fn=val_batchify_fn,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=False)\n",
    "\n",
    "wmt2016_test_data_loader_gpu = mx.gluon.data.DataLoader(\n",
    "    wmt2016_test_data_len_processed_gpu,\n",
    "    batch_sampler=wmt2016_test_batch_sampler_gpu,\n",
    "    batchify_fn=val_batchify_fn,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddd30b8",
   "metadata": {},
   "source": [
    "## Optimal Training: Automatic Mixed Precision (AMP) + Multi-GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9466424a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx_list = [mx.gpu(0), mx.gpu(1), mx.gpu(2), mx.gpu(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b6d8b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Vocab: 36794 , Target Vocab: 36794\n"
     ]
    }
   ],
   "source": [
    "# AMP\n",
    "amp.init()\n",
    "\n",
    "# Build on top of Pre-Trained model\n",
    "wmt_model_name = 'transformer_en_de_512'\n",
    "wmt_transformer_model_ft_direct_opt, _, _ = nlp.model.get_model(\n",
    "    wmt_model_name,\n",
    "    dataset_name='WMT2014',\n",
    "    pretrained=True,\n",
    "    ctx=ctx_list)\n",
    "\n",
    "print('Source Vocab:', len(wmt_src_vocab), ', Target Vocab:', len(wmt_tgt_vocab))\n",
    "\n",
    "# No need to re-configure last layer, just re-initialize\n",
    "# wmt_transformer_model_ft_direct.tgt_proj.initialize(ctx=ctx_list, force_reinit=True)\n",
    "\n",
    "wmt_transformer_model_ft_direct_opt.hybridize(static_alloc=True, static_shape=True)\n",
    "\n",
    "model_filename_ft_direct_opt = \"transformer_en_de_512_ft_direct_opt.params\"\n",
    "\n",
    "\n",
    "wmt_translator_ft_direct_opt = nmt.translation.BeamSearchTranslator(\n",
    "    model=wmt_transformer_model_ft_direct_opt,\n",
    "    beam_size=hparams.beam_size,\n",
    "    scorer=nlp.model.BeamSearchScorer(alpha=hparams.lp_alpha, K=hparams.lp_k),\n",
    "    max_length=200)\n",
    "\n",
    "# hparams.epochs = 10\n",
    "hparams.epochs = 2\n",
    "# hparams.lr = 0.00003\n",
    "hparams.lr = 0.0001\n",
    "hparams.log_interval = 1\n",
    "\n",
    "loss_function = nlp.loss.MaskedSoftmaxCELoss()\n",
    "loss_function.hybridize(static_alloc=True)\n",
    "\n",
    "wmt_detokenizer = nlp.data.SacreMosesDetokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "66984439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd0a3566ae04413392fe86ce8fa37b2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6da9c468cb8d4a2195be6c4a8b13fcb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[21:09:15] /work/mxnet/src/kvstore/././comm.h:741: only 4 out of 12 GPU pairs are enabled direct access. It may affect the performance. You can set MXNET_ENABLE_GPU_P2P=0 to turn it off\n",
      "[21:09:15] /work/mxnet/src/kvstore/././comm.h:750: .v..\n",
      "[21:09:15] /work/mxnet/src/kvstore/././comm.h:750: v...\n",
      "[21:09:15] /work/mxnet/src/kvstore/././comm.h:750: ...v\n",
      "[21:09:15] /work/mxnet/src/kvstore/././comm.h:750: ..v.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 1/46] loss=1.4720, ppl=4.3580, throughput=5.57K wps, wc=7.12K\n",
      "[Epoch 0 Batch 2/46] loss=1.3862, ppl=3.9994, throughput=4.04K wps, wc=7.13K\n",
      "[Epoch 0 Batch 3/46] loss=1.4630, ppl=4.3188, throughput=1.47K wps, wc=3.34K\n",
      "[Epoch 0 Batch 4/46] loss=1.0851, ppl=2.9599, throughput=2.30K wps, wc=5.90K\n",
      "[Epoch 0 Batch 5/46] loss=1.3467, ppl=3.8446, throughput=2.47K wps, wc=7.05K\n",
      "[Epoch 0 Batch 6/46] loss=1.4643, ppl=4.3245, throughput=2.28K wps, wc=7.21K\n",
      "[Epoch 0 Batch 7/46] loss=1.6961, ppl=5.4527, throughput=2.13K wps, wc=7.38K\n",
      "[Epoch 0 Batch 8/46] loss=1.2501, ppl=3.4908, throughput=0.21K wps, wc=0.80K\n",
      "[Epoch 0 Batch 9/46] loss=1.7349, ppl=5.6681, throughput=1.78K wps, wc=7.23K\n",
      "[Epoch 0 Batch 10/46] loss=1.2133, ppl=3.3646, throughput=1.60K wps, wc=7.00K\n",
      "[Epoch 0 Batch 11/46] loss=1.6265, ppl=5.0859, throughput=1.58K wps, wc=7.36K\n",
      "[Epoch 0 Batch 12/46] loss=1.4110, ppl=4.0999, throughput=1.47K wps, wc=7.25K\n",
      "[Epoch 0 Batch 13/46] loss=1.6590, ppl=5.2539, throughput=1.40K wps, wc=7.29K\n",
      "[Epoch 0 Batch 14/46] loss=0.9957, ppl=2.7065, throughput=0.09K wps, wc=0.50K\n",
      "[Epoch 0 Batch 15/46] loss=1.3850, ppl=3.9949, throughput=1.26K wps, wc=7.29K\n",
      "[Epoch 0 Batch 16/46] loss=1.6617, ppl=5.2680, throughput=1.20K wps, wc=7.27K\n",
      "[Epoch 0 Batch 17/46] loss=1.1048, ppl=3.0186, throughput=1.09K wps, wc=6.94K\n",
      "[Epoch 0 Batch 18/46] loss=1.7427, ppl=5.7127, throughput=1.10K wps, wc=7.40K\n",
      "[Epoch 0 Batch 19/46] loss=1.5984, ppl=4.9451, throughput=1.06K wps, wc=7.30K\n",
      "[Epoch 0 Batch 20/46] loss=1.6349, ppl=5.1290, throughput=1.03K wps, wc=7.30K\n",
      "[Epoch 0 Batch 21/46] loss=1.6907, ppl=5.4233, throughput=0.99K wps, wc=7.22K\n",
      "[Epoch 0 Batch 22/46] loss=1.6308, ppl=5.1079, throughput=0.96K wps, wc=7.23K\n",
      "[Epoch 0 Batch 23/46] loss=1.6158, ppl=5.0320, throughput=0.94K wps, wc=7.22K\n",
      "[Epoch 0 Batch 24/46] loss=1.2162, ppl=3.3744, throughput=0.50K wps, wc=4.02K\n",
      "[Epoch 0 Batch 25/46] loss=1.3405, ppl=3.8211, throughput=0.86K wps, wc=7.17K\n",
      "[Epoch 0 Batch 26/46] loss=1.6871, ppl=5.4036, throughput=0.83K wps, wc=7.09K\n",
      "[Epoch 0 Batch 27/46] loss=1.3369, ppl=3.8073, throughput=0.81K wps, wc=7.19K\n",
      "[Epoch 0 Batch 28/46] loss=1.4858, ppl=4.4187, throughput=0.79K wps, wc=7.19K\n",
      "[Epoch 0 Batch 29/46] loss=1.5981, ppl=4.9437, throughput=0.76K wps, wc=7.21K\n",
      "[Epoch 0 Batch 30/46] loss=1.4825, ppl=4.4041, throughput=0.30K wps, wc=2.92K\n",
      "[Epoch 0 Batch 31/46] loss=1.3552, ppl=3.8777, throughput=0.70K wps, wc=7.03K\n",
      "[Epoch 0 Batch 32/46] loss=0.6093, ppl=1.8392, throughput=0.04K wps, wc=0.44K\n",
      "[Epoch 0 Batch 33/46] loss=1.3662, ppl=3.9204, throughput=0.67K wps, wc=7.22K\n",
      "[Epoch 0 Batch 34/46] loss=1.4044, ppl=4.0729, throughput=0.65K wps, wc=7.14K\n",
      "[Epoch 0 Batch 35/46] loss=1.2586, ppl=3.5204, throughput=0.63K wps, wc=7.07K\n",
      "[Epoch 0 Batch 36/46] loss=1.4378, ppl=4.2116, throughput=0.62K wps, wc=7.12K\n",
      "[Epoch 0 Batch 37/46] loss=1.0699, ppl=2.9151, throughput=0.21K wps, wc=2.48K\n",
      "[Epoch 0 Batch 38/46] loss=1.6521, ppl=5.2179, throughput=0.59K wps, wc=7.21K\n",
      "[Epoch 0 Batch 39/46] loss=1.5928, ppl=4.9176, throughput=0.60K wps, wc=7.36K\n",
      "[Epoch 0 Batch 40/46] loss=1.3895, ppl=4.0128, throughput=0.56K wps, wc=7.10K\n",
      "[Epoch 0 Batch 41/46] loss=1.4361, ppl=4.2043, throughput=0.55K wps, wc=7.14K\n",
      "[Epoch 0 Batch 42/46] loss=1.2891, ppl=3.6294, throughput=0.53K wps, wc=7.00K\n",
      "[Epoch 0 Batch 43/46] loss=0.8912, ppl=2.4381, throughput=0.01K wps, wc=0.09K\n",
      "[Epoch 0 Batch 44/46] loss=1.4598, ppl=4.3049, throughput=0.52K wps, wc=7.22K\n",
      "[Epoch 0 Batch 45/46] loss=1.5560, ppl=4.7396, throughput=0.52K wps, wc=7.31K\n",
      "[Epoch 0 Batch 46/46] loss=1.0908, ppl=2.9766, throughput=0.40K wps, wc=5.76K\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c78cf0152e78453485d12d2d40464979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[21:09:29] /work/mxnet/src/imperative/./cached_op.h:254: Disabling fusion due to altered topological order of inputs.\n",
      "[21:09:36] /work/mxnet/src/imperative/./cached_op.h:254: Disabling fusion due to altered topological order of inputs.\n",
      "[21:09:41] /work/mxnet/src/imperative/./cached_op.h:254: Disabling fusion due to altered topological order of inputs.\n",
      "[21:09:47] /work/mxnet/src/imperative/./cached_op.h:254: Disabling fusion due to altered topological order of inputs.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_63443/2183011615.py\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;31m# Validation step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     wmt2016_valid_loss, wmt2016_valid_translation_out = transformer_model.evaluate_multi(\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0mwmt_transformer_model_ft_direct_opt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mwmt2016_val_data_loader_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/public/Deep-Learning-with-MXNet-Cookbook/ch08/transformer_model.py\u001b[0m in \u001b[0;36mevaluate_multi\u001b[0;34m(model, data_loader, test_loss_function, translator, tgt_vocab, detokenizer, ctx_list)\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0;31m# Translate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_valid_length\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m                 \u001b[0mtranslator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_seq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_seq_slice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_valid_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_valid_length_slice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0msamples_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/public/Deep-Learning-with-MXNet-Cookbook/ch08/nmt/translation.py\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(self, src_seq, src_valid_length)\u001b[0m\n\u001b[1;32m     79\u001b[0m         inputs = mx.nd.full(shape=(batch_size,), ctx=src_seq.context, dtype=np.float32,\n\u001b[1;32m     80\u001b[0m                             val=self._model.tgt_vocab.token_to_idx[self._model.tgt_vocab.bos_token])\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_valid_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_valid_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/gluonnlp/model/sequence_sampler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, states)\u001b[0m\n\u001b[1;32m    546\u001b[0m                               new_states, vocab_size_nd, batch_shift_nd)\n\u001b[1;32m    547\u001b[0m             \u001b[0mstep_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchosen_word_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeam_alive_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         final_word = mx.nd.where(beam_alive_mask,\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masscalar\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2588\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The current array is not a scalar\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2589\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2590\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2591\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2592\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2566\u001b[0m         \"\"\"\n\u001b[1;32m   2567\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2568\u001b[0;31m         check_call(_LIB.MXNDArraySyncCopyToCPU(\n\u001b[0m\u001b[1;32m   2569\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2570\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reload(transformer_model)\n",
    "\n",
    "# Let's train\n",
    "trainer = mx.gluon.Trainer(wmt_transformer_model_ft_direct_opt.collect_params(), hparams.optimizer, {'learning_rate': hparams.lr})\n",
    "\n",
    "best_valid_bleu = 0.0\n",
    "\n",
    "wmt2016_train_losses = []\n",
    "wmt2016_valid_losses = []\n",
    "wmt2016_valid_bleus  = []\n",
    "wmt2016_valid_perplexities = []\n",
    "\n",
    "amp.init_trainer(trainer)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch_id in tqdm(range(hparams.epochs)):\n",
    "\n",
    "    acc_train_loss_batch = 0\n",
    "    log_loss = 0\n",
    "    log_denom = 0\n",
    "    log_wc = 0\n",
    "    log_start_time = time.time()\n",
    "\n",
    "    # Iterate through each batch\n",
    "    for batch_id, (src_seq, tgt_seq, src_valid_length, tgt_valid_length) in enumerate(tqdm(wmt2016_train_data_loader_gpu)):\n",
    "           \n",
    "        src_seq_list = mx.gluon.utils.split_and_load(src_seq, ctx_list=ctx_list, even_split=False)\n",
    "        tgt_seq_list = mx.gluon.utils.split_and_load(tgt_seq, ctx_list=ctx_list, even_split=False)\n",
    "        src_valid_length_list = mx.gluon.utils.split_and_load(src_valid_length, ctx_list=ctx_list, even_split=False)\n",
    "        tgt_valid_length_list = mx.gluon.utils.split_and_load(tgt_valid_length, ctx_list=ctx_list, even_split=False)\n",
    "        \n",
    "        losses = []\n",
    "        \n",
    "        with mx.autograd.record():\n",
    "            for src_seq_slice, tgt_seq_slice, src_valid_length_slice, tgt_valid_length_slice in zip(src_seq_list, tgt_seq_list, src_valid_length_list, tgt_valid_length_list):\n",
    "                \n",
    "                assert src_seq_slice.context == tgt_seq_slice.context == src_valid_length_slice.context == tgt_valid_length_slice.context                \n",
    "                \n",
    "                out_slice, _ = wmt_transformer_model_ft_direct_opt(\n",
    "                    src_seq_slice,\n",
    "                    tgt_seq_slice[:, :-1],\n",
    "                    src_valid_length_slice,\n",
    "                    tgt_valid_length_slice - 1)\n",
    "                \n",
    "                loss = loss_function(out_slice, tgt_seq_slice[:, 1:], tgt_valid_length_slice - 1)\n",
    "                loss.backward()\n",
    "                \n",
    "#                 with amp.scale_loss(loss, trainer) as scaled_loss:\n",
    "#                     scaled_loss.backward()\n",
    "                    \n",
    "                losses.append(loss)\n",
    "        \n",
    "        trainer.step(1)\n",
    "        \n",
    "        src_wc = 0\n",
    "        tgt_wc = 0\n",
    "        \n",
    "        for loss, tgt_seq_slice, src_valid_length_slice, tgt_valid_length_slice in zip(losses, tgt_seq_list, src_valid_length_list, tgt_valid_length_list):\n",
    "            \n",
    "            assert loss.context == tgt_seq_slice.context == src_valid_length_slice.context == tgt_valid_length_slice.context\n",
    "            \n",
    "            src_valid_length_slice_cpu = src_valid_length_slice.as_in_context(mx.cpu())\n",
    "            tgt_valid_length_slice_cpu = tgt_valid_length_slice.as_in_context(mx.cpu())\n",
    "            \n",
    "            loss = loss.mean().as_in_context(mx.cpu()) * (tgt_seq_slice.shape[1] - 1)\n",
    "            log_loss += loss * tgt_seq_slice.shape[0]\n",
    "            log_denom += (tgt_valid_length_slice_cpu - 1).sum()\n",
    "            loss = loss / (tgt_valid_length_slice_cpu - 1).mean()\n",
    "            \n",
    "            src_wc += src_valid_length_slice_cpu.sum().asscalar()\n",
    "            tgt_wc += (tgt_valid_length_slice_cpu - 1).sum().asscalar()\n",
    "        \n",
    "\n",
    "        log_loss = log_loss.asscalar()\n",
    "        log_denom = log_denom.asscalar()\n",
    "        log_wc += src_wc + tgt_wc\n",
    "            \n",
    "        train_loss = log_loss / log_denom\n",
    "        acc_train_loss_batch += train_loss\n",
    "        \n",
    "        if (batch_id + 1) % hparams.log_interval == 0:\n",
    "            wps = log_wc / (time.time() - log_start_time)\n",
    "            print(\"[Epoch {} Batch {}/{}] loss={:.4f}, ppl={:.4f}, \"\n",
    "                         \"throughput={:.2f}K wps, wc={:.2f}K\"\n",
    "                         .format(epoch_id, batch_id + 1, len(wmt2016_train_data_loader_gpu),\n",
    "                                 train_loss,\n",
    "                                 np.exp(log_loss / log_denom),\n",
    "                                 wps / 1000, log_wc / 1000))\n",
    "            \n",
    "            log_loss = 0\n",
    "            log_denom = 0\n",
    "            log_wc = 0\n",
    "\n",
    "    wmt2016_train_loss = acc_train_loss_batch / len(wmt2016_train_data_loader_gpu)\n",
    "    wmt2016_train_losses.append(wmt2016_train_loss)\n",
    "    \n",
    "    # Validation step\n",
    "    wmt2016_valid_loss, wmt2016_valid_translation_out = transformer_model.evaluate_multi(\n",
    "        wmt_transformer_model_ft_direct_opt,\n",
    "        wmt2016_val_data_loader_gpu,\n",
    "        loss_function,\n",
    "        wmt_translator_ft_direct_opt,\n",
    "        wmt_tgt_vocab,\n",
    "        wmt_detokenizer,\n",
    "        ctx_list=ctx_list)\n",
    "\n",
    "    wmt2016_valid_bleu_score, _, _, _, _ = nmt.bleu.compute_bleu(\n",
    "        [wmt2016_val_tgt_sentences],\n",
    "        wmt2016_valid_translation_out,\n",
    "        tokenized=False,\n",
    "        tokenizer=\"13a\",\n",
    "        split_compound_word=False,\n",
    "        bpe=False)\n",
    "\n",
    "    wmt2016_valid_perplexity = np.exp(wmt2016_valid_loss)\n",
    "    wmt2016_valid_perplexities.append(wmt2016_valid_perplexity)\n",
    "    wmt2016_valid_losses.append(wmt2016_valid_loss)\n",
    "    wmt2016_valid_bleus.append(wmt2016_valid_bleu_score * 100)\n",
    "    \n",
    "    print(\"[Epoch {}] valid Loss={:.4f}, valid ppl={:.4f}, valid bleu={:.2f}\"\n",
    "          .format(epoch_id, wmt2016_valid_loss, wmt2016_valid_perplexity, wmt2016_valid_bleu_score * 100))\n",
    "    \n",
    "    if wmt2016_valid_bleu_score > best_valid_bleu:\n",
    "        best_valid_bleu = wmt2016_valid_bleu_score\n",
    "        print(\"Save best parameters to {}\".format(model_filename_ft_direct_opt))\n",
    "        wmt_transformer_model_ft_direct_opt.save_parameters(model_filename_ft_direct_opt)\n",
    "\n",
    "print(\"Training time for 10 epochs:\", time.time() - start_time, \"/ Best validation loss:\", min(wmt2016_valid_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f749ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the losses\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, hparams.epochs), wmt2016_valid_losses, label=\"Validation Loss\")\n",
    "plt.plot(np.arange(0, hparams.epochs), wmt2016_train_losses, label=\"Training Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"Losses\")\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34257bc8",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877ede07",
   "metadata": {},
   "source": [
    "#### Quantitative Evaluation: Test Loss and BLEU score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7791f8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantitative Evaluation\n",
    "# Load best model\n",
    "wmt_transformer_model_ft_direct_opt.load_parameters(model_filename_ft_direct_opt)\n",
    "\n",
    "wmt2016_test_loss, wmt2016_test_translation_out = transformer_model.evaluate_multi(\n",
    "    wmt_transformer_model_ft_direct_opt,\n",
    "    wmt2016_test_data_loader_gpu,\n",
    "    loss_function,\n",
    "    wmt_translator_ft_direct_opt,\n",
    "    wmt_tgt_vocab,\n",
    "    wmt_detokenizer,\n",
    "    ctx_list)\n",
    "\n",
    "wmt2016_test_bleu_score, _, _, _, _ = nmt.bleu.compute_bleu(\n",
    "    [wmt2016_test_tgt_sentences],\n",
    "    wmt2016_test_translation_out,\n",
    "    tokenized=False,\n",
    "    tokenizer=\"13a\",\n",
    "    split_compound_word=False,\n",
    "    bpe=False)\n",
    "\n",
    "print('WMT16 test loss: %.2f; test bleu score: %.2f'\n",
    "      %(wmt2016_test_loss, wmt2016_test_bleu_score * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88895bcf",
   "metadata": {},
   "source": [
    "#### Qualitative Evaluation: Translation from English to German Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3e655e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qualitative Evaluation\n",
    "reload(transformer_model)\n",
    "\n",
    "print(\"Qualitative Evaluation: Translating from English to German\")\n",
    "\n",
    "# From Google Translate\n",
    "expected_tgt_seq = \"Ich lerne neue Dinge jeden Tag.\"\n",
    "print(\"Expected translation:\")\n",
    "print(expected_tgt_seq)\n",
    "\n",
    "src_seq = \"I learn new things every day.\"\n",
    "print(\"In English:\")\n",
    "print(src_seq)\n",
    "\n",
    "# translation_out = nmt.utils.translate_with_unk(\n",
    "# translation_out = nmt.utils.translate(\n",
    "translation_out = transformer_model.translate(\n",
    "    wmt_translator_ft_direct_opt,\n",
    "    src_seq,\n",
    "    # wmt2016_train_data.src_vocab,\n",
    "    # wmt2016_train_data.tgt_vocab,\n",
    "    wmt_src_vocab,\n",
    "    wmt_tgt_vocab,\n",
    "    wmt_detokenizer,\n",
    "    ctx_list[0])\n",
    "\n",
    "print(\"The German translation is:\")\n",
    "print(\" \".join(translation_out[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
