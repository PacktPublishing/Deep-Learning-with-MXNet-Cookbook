{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de6b5fce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bd2779f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Reference: https://mxnet.apache.org/versions/1.9.1/api/faq/env_var\n",
    "\n",
    "# os.environ[\"MXNET_CPU_WORKER_NTHREADS\"] = \"1\"\n",
    "# os.environ[\"MXNET_CPU_PRIORITY_NTHREADS\"] = \"1\"\n",
    "# os.environ[\"MXNET_CPU_NNPACK_NTHREADS\"] = \"1\"\n",
    "# os.environ[\"MXNET_EXEC_NUM_TEMP\"] = \"1\"\n",
    "# os.environ[\"MXNET_ENGINE_TYPE\"] = \"NaiveEngine\"\n",
    "\n",
    "# Default Mode: \"ThreadedEnginePerDevice\"\n",
    "# os.environ[\"MXNET_CPU_WORKER_NTHREADS\"] = \"4\"\n",
    "# os.environ[\"MXNET_CPU_PRIORITY_NTHREADS\"] = \"4\"\n",
    "# os.environ[\"MXNET_CPU_NNPACK_NTHREADS\"] = \"4\"\n",
    "# os.environ[\"MXNET_EXEC_NUM_TEMP\"] = \"4\"\n",
    "# os.environ[\"MXNET_ENGINE_TYPE\"] = \"ThreadedEnginePerDevice\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "117850d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import matplotlib.pyplot as plt\n",
    "import mxnet as mx\n",
    "from mxnet.contrib import amp\n",
    "import time\n",
    "import timeit\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "ctx = mx.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531c892c",
   "metadata": {},
   "source": [
    "## Creation of Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fd8db65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "489f3863b772412cb2ce330e4824a7f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19:54:31] /work/mxnet/src/engine/engine.cc:54: MXNet start using engine: ThreadedEnginePerDevice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 10.879605054855347\n"
     ]
    }
   ],
   "source": [
    "wait_for_operations = True\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for _ in tqdm(range(100)):\n",
    "    a = mx.nd.random.normal(shape=(1000, 1000))\n",
    "    if wait_for_operations:\n",
    "        a.wait_to_read()\n",
    "    b = mx.nd.random.normal(shape=(1000, 1000))\n",
    "    if wait_for_operations:\n",
    "        b.wait_to_read()\n",
    "    c = mx.nd.random.normal(shape=(1000, 1000))\n",
    "    if wait_for_operations:\n",
    "        c.wait_to_read()\n",
    "    d = mx.nd.random.normal(shape=(1000, 1000))\n",
    "    if wait_for_operations:\n",
    "        d.wait_to_read()\n",
    "\n",
    "\n",
    "print(\"Time (s):\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17c3fd84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0637d07c1ed44b87b640cdabc8cfbb6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 0.042786598205566406\n"
     ]
    }
   ],
   "source": [
    "wait_for_operations = False\n",
    "compute_results = False\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for _ in tqdm(range(100)):\n",
    "    a = mx.nd.random.normal(shape=(1000, 1000))\n",
    "    if wait_for_operations:\n",
    "        a.wait_to_read()\n",
    "    b = mx.nd.random.normal(shape=(1000, 1000))\n",
    "    if wait_for_operations:\n",
    "        b.wait_to_read()\n",
    "    c = mx.nd.random.normal(shape=(1000, 1000))\n",
    "    if wait_for_operations:\n",
    "        c.wait_to_read()\n",
    "    d = mx.nd.random.normal(shape=(1000, 1000))\n",
    "    if wait_for_operations:\n",
    "        d.wait_to_read()\n",
    "\n",
    "    if compute_results:\n",
    "        a.wait_to_read()\n",
    "        b.wait_to_read()\n",
    "        c.wait_to_read()\n",
    "        d.wait_to_read()\n",
    "        \n",
    "print(\"Time (s):\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d94c00e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "127658acc7334456918fefc2095d67bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 19.67207169532776\n"
     ]
    }
   ],
   "source": [
    "wait_for_operations = False\n",
    "compute_results = True\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for _ in tqdm(range(100)):\n",
    "    a = mx.nd.random.normal(shape=(1000, 1000))\n",
    "    if wait_for_operations:\n",
    "        a.wait_to_read()\n",
    "    b = mx.nd.random.normal(shape=(1000, 1000))\n",
    "    if wait_for_operations:\n",
    "        b.wait_to_read()\n",
    "    c = mx.nd.random.normal(shape=(1000, 1000))\n",
    "    if wait_for_operations:\n",
    "        c.wait_to_read()\n",
    "    d = mx.nd.random.normal(shape=(1000, 1000))\n",
    "    if wait_for_operations:\n",
    "        d.wait_to_read()\n",
    "\n",
    "    if compute_results:\n",
    "        a.wait_to_read()\n",
    "        b.wait_to_read()\n",
    "        c.wait_to_read()\n",
    "        d.wait_to_read()\n",
    "        \n",
    "print(\"Time (s):\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b5527d",
   "metadata": {},
   "source": [
    "## Multiplication of Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5c5a94a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42959f5923284b808ec5d1d5ad052528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 135.26983547210693\n"
     ]
    }
   ],
   "source": [
    "wait_for_operations = True\n",
    "compute_results = False\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for _ in tqdm(range(10)):\n",
    "    a = mx.nd.random.normal(shape=(10000, 10000))\n",
    "    if wait_for_operations:\n",
    "        a.wait_to_read()\n",
    "    b = mx.nd.random.normal(shape=(10000, 10000))\n",
    "    if wait_for_operations:\n",
    "        b.wait_to_read()\n",
    "    c = mx.nd.random.normal(shape=(10000, 10000))\n",
    "    if wait_for_operations:\n",
    "        c.wait_to_read()\n",
    "    d = mx.nd.random.normal(shape=(10000, 10000))\n",
    "    if wait_for_operations:\n",
    "        d.wait_to_read()\n",
    "\n",
    "    s1 = a * a * a * a * b * b * b * b\n",
    "    if wait_for_operations:\n",
    "        s1.wait_to_read()\n",
    "    s2 = c * c * c * c * d * d * d * d\n",
    "    if wait_for_operations:\n",
    "        s2.wait_to_read()\n",
    "    s1 = s1 * s1 * s1 * s1 * s1 * s1 * s1 * s1\n",
    "    if wait_for_operations:\n",
    "        s1.wait_to_read()\n",
    "    s2 = s2 * s2 * s2 * s2 * s2 * s2 * s2 * s2\n",
    "    if wait_for_operations:\n",
    "        s2.wait_to_read()\n",
    "    s_total = s1 * s2\n",
    "    s_total = s_total * s_total * s_total * s_total\n",
    "    if wait_for_operations:\n",
    "        s_total.wait_to_read()\n",
    "        \n",
    "    if compute_results:\n",
    "        s_total.wait_to_read()\n",
    "        \n",
    "print(\"Time (s):\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39c0554e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9b8e7f0081c42909b57df9bae6c411e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 111.36750531196594\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "s_total = []\n",
    "\n",
    "for _ in tqdm(range(10)):\n",
    "    a = mx.nd.random.normal(shape=(10000, 10000))\n",
    "    b = mx.nd.random.normal(shape=(10000, 10000))\n",
    "    c = mx.nd.random.normal(shape=(10000, 10000))\n",
    "    d = mx.nd.random.normal(shape=(10000, 10000))\n",
    "\n",
    "    s1 = a * a * a * a * b * b * b * b\n",
    "    s2 = c * c * c * c * d * d * d * d\n",
    "    s1 = s1 * s1 * s1 * s1 * s1 * s1 * s1 * s1 \n",
    "    s2 = s2 * s2 * s2 * s2 * s2 * s2 * s2 * s2\n",
    "    s_total = s1 * s2\n",
    "    s_total = s_total * s_total * s_total * s_total\n",
    "\n",
    "mx.nd.waitall()\n",
    "        \n",
    "print(\"Time (s):\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3974c42d",
   "metadata": {},
   "source": [
    "##Â DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71ce3f2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gluoncv as gcv\n",
    "\n",
    "# ADE20K Preliminary steps\n",
    "# Needs source code from Gluon-CV, run (in your desired code folder):\n",
    "# gh repo clone dmlc/gluon-cv\n",
    "# in the gluon-cv/scripts/datasets folder, there is a script called\n",
    "# ade20k.py, run it with:\n",
    "# !python3 ade20k.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcaf2935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d47599b006fb4867b8f991ed6229dfe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 21.621415376663208\n"
     ]
    }
   ],
   "source": [
    "# All in CPU, no transforms\n",
    "ade20k_val = gcv.data.ADE20KSegmentation(split='val')\n",
    "\n",
    "data_shape = []\n",
    "labels_shape = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for data, label in tqdm(ade20k_val):\n",
    "    data_shape.append(data.shape)\n",
    "    labels_shape.append(label.shape)\n",
    "    \n",
    "print(\"Time (s):\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42b38c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 1200\n",
    "\n",
    "input_transform_fn = mx.gluon.data.vision.transforms.Compose([\n",
    "    mx.gluon.data.vision.transforms.Resize(image_size, keep_ratio=True),\n",
    "    mx.gluon.data.vision.transforms.CenterCrop(image_size),\n",
    "    mx.gluon.data.vision.transforms.ToTensor(),\n",
    "    mx.gluon.data.vision.transforms.Normalize([.485, .456, .406], [.229, .224, .225])\n",
    "])\n",
    "\n",
    "to_gpu_fn = lambda x: x.as_in_context(mx.gpu())\n",
    "\n",
    "input_transform_fn_gpu = mx.gluon.data.vision.transforms.Compose([\n",
    "    to_gpu_fn,\n",
    "    input_transform_fn\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b88b1b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23e089b8ed2a4f2486be3b4e2be2036a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 39.527422189712524\n"
     ]
    }
   ],
   "source": [
    "# Pre-processing in CPU, with transforms\n",
    "ade20k_val_cpu = gcv.data.ADE20KSegmentation(split='val', transform=input_transform_fn)\n",
    "\n",
    "data_shape = []\n",
    "labels_shape = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for data, label in tqdm(ade20k_val_cpu):\n",
    "    data_shape.append(data.shape)\n",
    "    labels_shape.append(label.shape)\n",
    "    \n",
    "print(\"Time (s):\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d110200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e06cd11747794d7cb3d6840dd644e0a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16:51:51] /work/mxnet/src/base.cc:79: cuDNN lib mismatch: linked-against version 8200 != compiled-against version 8201.  Set MXNET_CUDNN_LIB_CHECKING=0 to quiet this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 25.4871244430542\n"
     ]
    }
   ],
   "source": [
    "# Pre-processing in GPU, with transforms\n",
    "# Unfortunately, we cannot copy directly into GPU the labels\n",
    "# Not supported ty ADE20KSegmentation class\n",
    "ade20k_val_gpu = gcv.data.ADE20KSegmentation(split='val', transform=input_transform_fn_gpu)\n",
    "\n",
    "_mask_transform_fn = mx.gluon.data.vision.transforms.Compose([\n",
    "    ade20k_val_gpu._mask_transform,\n",
    "    to_gpu_fn\n",
    "])\n",
    "\n",
    "ade20k_val_gpu._mask_transform = _mask_transform_fn\n",
    "\n",
    "data_shape = []\n",
    "labels_shape = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for data, label in tqdm(ade20k_val_gpu):\n",
    "    data_shape.append(data.shape)\n",
    "    labels_shape.append(label.shape)\n",
    "    \n",
    "print(\"Time (s):\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76463d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6119608ea77641269acc23ffef890847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 22.894771814346313\n"
     ]
    }
   ],
   "source": [
    "# Pre-processing in GPU, with transforms\n",
    "# then copying back to CPU memory space\n",
    "\n",
    "# Pre-processing in GPU, with transforms\n",
    "# Unfortunately, we cannot copy directly into GPU the labels\n",
    "# Not supported ty ADE20KSegmentation class\n",
    "\n",
    "to_cpu_fn = lambda x: x.as_in_context(mx.cpu())\n",
    "\n",
    "input_transform_fn_gpu_cpu = mx.gluon.data.vision.transforms.Compose([\n",
    "    input_transform_fn_gpu,\n",
    "    to_cpu_fn\n",
    "])\n",
    "\n",
    "# No need for mask transform changes\n",
    "ade20k_val_gpu_cpu = gcv.data.ADE20KSegmentation(split='val', transform=input_transform_fn_gpu_cpu)\n",
    "\n",
    "data_shape = []\n",
    "labels_shape = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for data, label in tqdm(ade20k_val_gpu_cpu):\n",
    "    data_shape.append(data.shape)\n",
    "    labels_shape.append(label.shape)\n",
    "    \n",
    "print(\"Time (s):\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18676e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_loader_cpu(num_workers, batch_size):\n",
    "    # DataLoader all in CPU, copied to GPU (for model processing)\n",
    "    ade20k_val_loader_cpu = mx.gluon.data.DataLoader(\n",
    "        ade20k_val_cpu,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers)\n",
    "\n",
    "    for data, label in tqdm(ade20k_val_loader_cpu):\n",
    "        data = data.as_in_context(mx.gpu())\n",
    "        label = label.as_in_context(mx.gpu())\n",
    "        \n",
    "def process_data_loader_gpu(num_workers, batch_size):\n",
    "    # DataLoader all in GPU, no copies necessary\n",
    "    ade20k_val_loader_gpu = mx.gluon.data.DataLoader(\n",
    "        ade20k_val_gpu,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        thread_pool=False)\n",
    "\n",
    "    for data, label in tqdm(ade20k_val_loader_gpu):\n",
    "        pass\n",
    "    \n",
    "def process_data_loader_gpu_cpu(num_workers, batch_size):\n",
    "    # DataLoader all in GPU, no copies necessary\n",
    "    ade20k_val_loader_gpu_cpu = mx.gluon.data.DataLoader(\n",
    "        ade20k_val_gpu_cpu,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        thread_pool=False)\n",
    "\n",
    "    for data, label in tqdm(ade20k_val_loader_gpu_cpu):\n",
    "        data = data.as_in_context(mx.gpu())\n",
    "        label = label.as_in_context(mx.gpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e8f3842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ebd03f971ba4976afe7dafa4151f9d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 58.293808698654175\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "process_data_loader_cpu(0, 4)\n",
    "\n",
    "print(\"Time (s):\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d79e9198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38a06d42a6044fa28ae2c0aff4edcba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 22.119566202163696\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "process_data_loader_gpu(0, 4)\n",
    "\n",
    "print(\"Time (s):\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de7c0726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "578350f360f84e47b7ba0b307b861899",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 38.39428663253784\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "process_data_loader_gpu_cpu(0, 4)\n",
    "\n",
    "print(\"Time (s):\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be8f64d",
   "metadata": {},
   "source": [
    "##Â DataLoader Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08126aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers_list = [0, 1, 2, 4, 8]\n",
    "batch_sizes = [1, 2, 4, 8, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c506449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb7c3be09898410ba4a17853fe2f1edf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23e47ff646434e70992c6c7a72a203fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "122bee1a4ed94d8989b0b4dad622af46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.7 s Â± 0 ns per loop (mean Â± std. dev. of 1 run, 3 loops each)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e97419d230db4524ab98dc328709cb41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_gpu = []\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    num_workers_gpu = 0\n",
    "    result = %timeit  -n 3 -r 1 -o process_data_loader_gpu(num_workers_gpu, batch_size)\n",
    "    results_gpu.append(result.average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764ef294",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_gpu_cpu = []\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    num_workers_gpu = 0\n",
    "    result = %timeit  -n 3 -r 1 -o process_data_loader_gpu_cpu(num_workers_gpu, batch_size)\n",
    "    results_gpu_cpu.append(result.average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4aafb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_cpu = []\n",
    "    \n",
    "for num_workers_cpu in num_workers_list:\n",
    "    temp_list = []\n",
    "    for batch_size in batch_sizes:\n",
    "        result = %timeit -n 3 -r 1 -o process_data_loader_cpu(num_workers_cpu, batch_size)\n",
    "        temp_list.append(result.average)\n",
    "    results_cpu.append(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ab1df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(batch_sizes, results_cpu[0], color='blue', marker='o')\n",
    "plt.plot(batch_sizes, results_cpu[1], color='green', marker='p')\n",
    "plt.plot(batch_sizes, results_cpu[2], color='yellow', marker='^')\n",
    "plt.plot(batch_sizes, results_cpu[3], color='orange', marker='*')\n",
    "plt.plot(batch_sizes, results_cpu[4], color='purple', marker='x')\n",
    "plt.plot(batch_sizes, results_gpu_cpu, color='pink', marker='x')\n",
    "plt.plot(batch_sizes, results_gpu, color='red', marker='s')\n",
    "plt.title(\"DataLoader Times\", fontsize=14)\n",
    "plt.xlabel(\"Batch Size\", fontsize=14)\n",
    "plt.ylabel(\"Runtime (s)\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.legend([\"CPU (workers: 0)\", \"CPU (workers: 1)\", \"CPU (workers: 2)\", \"CPU (workers: 4)\", \"CPU (workers: 8)\", \"GPU+CPU (workers: 0)\", \"GPU (workers: 0)\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443425a9",
   "metadata": {},
   "source": [
    "## Automatic Mixed Precision (AMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e1d7975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Libraries\n",
    "import collections\n",
    "import gluoncv as gcv\n",
    "from gluoncv.utils.metrics.segmentation import SegmentationMetric\n",
    "from mxnet.gluon.data.vision import transforms\n",
    "from gluoncv.loss import MixSoftmaxCrossEntropyLoss\n",
    "from importlib import reload\n",
    "import matplotlib.pyplot as plt\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn import metrics\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Local Libraries\n",
    "import pedestrian\n",
    "import seg_model\n",
    "\n",
    "# GPU mode\n",
    "ctx = mx.gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99204447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 120 images with 307 pedestrians\n",
      "Read 25 images with 68 pedestrians\n",
      "Read 25 images with 48 pedestrians\n"
     ]
    }
   ],
   "source": [
    "# Penn-Fudan Pedestrian Dataset\n",
    "# https://www.cis.upenn.edu/~jshi/ped_html/\n",
    "reload(pedestrian)\n",
    "\n",
    "if not os.path.exists(pedestrian.PEDESTRIAN_FILE):\n",
    "    !wget https://www.cis.upenn.edu/~jshi/ped_html/PennFudanPed.zip\n",
    "\n",
    "pedestrian_path = os.getcwd()\n",
    "\n",
    "# Datasets\n",
    "pedestrian_train_dataset = pedestrian.PedestrianDataset(\n",
    "    pedestrian_path,\n",
    "    split=\"train\",\n",
    "    is_segmentation_task=True,\n",
    "    invert_masks=False)\n",
    "\n",
    "pedestrian_val_dataset = pedestrian.PedestrianDataset(\n",
    "    pedestrian_path,\n",
    "    split=\"val\",\n",
    "    is_segmentation_task=True,\n",
    "    invert_masks=False)\n",
    "\n",
    "pedestrian_test_dataset = pedestrian.PedestrianDataset(\n",
    "    pedestrian_path,\n",
    "    split=\"test\",\n",
    "    is_segmentation_task=True,\n",
    "    invert_masks=False)\n",
    "\n",
    "\n",
    "# Further pre-processing\n",
    "# Training pre-processing optimized for speed\n",
    "# Evaluation pre-processing optimized for visualizations\n",
    "image_size = 480\n",
    "\n",
    "imagenet_transform = transforms.Compose([\n",
    "    transforms.Resize(image_size, keep_ratio=True),\n",
    "    transforms.CenterCrop(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([.485, .456, .406], [.229, .224, .225]),\n",
    "])\n",
    "\n",
    "size_transform = transforms.Compose([\n",
    "    transforms.Resize(image_size, keep_ratio=True),\n",
    "    transforms.CenterCrop(image_size)\n",
    "])\n",
    "\n",
    "train_val_transform = lambda data, output: (imagenet_transform(data), size_transform(output))\n",
    "test_transform = lambda data, output: (size_transform(data), mx.nd.moveaxis(size_transform(output), -1, 0))\n",
    "\n",
    "p_train = pedestrian_train_dataset.transform(train_val_transform)\n",
    "p_val   = pedestrian_val_dataset.transform(train_val_transform)\n",
    "p_test  = pedestrian_test_dataset.transform(test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "22c61436",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplab_pt = gcv.model_zoo.get_model('deeplab_resnet101_coco', pretrained=True, ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "72199802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data type: <class 'numpy.float32'> Model Parameters data type: <class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Input data type:\", p_val[0][0].dtype, \"Model Parameters data type:\", deeplab_pt.conv1[0].params[\"deeplabv337_resnetv1s_conv0_weight\"].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8212cf98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 as Float32: 0.333333343267440795898437500000\n",
      "1/3 as Float16: 0.333251953125000000000000000000\n"
     ]
    }
   ],
   "source": [
    "a = mx.nd.array([1/3], dtype=np.float32)\n",
    "b = a.astype(np.float16)\n",
    "\n",
    "print(\"1/3 as Float32: {0:.30f}\".format(a.asscalar()))\n",
    "print(\"1/3 as Float16: {0:.30f}\".format(b.asscalar()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a675a27",
   "metadata": {},
   "source": [
    "###Â Float32 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06d5ada5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16:13:06] /work/mxnet/src/base.cc:79: cuDNN lib mismatch: linked-against version 8200 != compiled-against version 8201.  Set MXNET_CUDNN_LIB_CHECKING=0 to quiet this warning.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b200d5c5bfe4638b5f4b05e2149a3de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16:13:10] /work/mxnet/src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:96: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:    1, TrL:      inf, VL: 1.052876 --- Updating saved model\n",
      "E:    2, TrL: 0.742097, VL: 1.714529\n",
      "E:    3, TrL: 0.702785, VL: 0.992210 --- Updating saved model\n",
      "E:    4, TrL: 0.648438, VL: 0.822017 --- Updating saved model\n",
      "E:    5, TrL: 0.593720, VL: 0.773931 --- Updating saved model\n",
      "E:    6, TrL: 0.572978, VL: 1.156278\n",
      "E:    7, TrL: 0.541276, VL: 0.680043 --- Updating saved model\n",
      "E:    8, TrL: 0.534532, VL: 0.854894\n",
      "E:    9, TrL: 0.511685, VL: 0.720281\n",
      "E:   10, TrL: 0.483089, VL: 1.077385\n",
      "Training time for 10 epochs: 594.4833037853241 / Best validation loss: 0.6800425\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "deeplab_ft_direct_f32 = gcv.model_zoo.get_model('deeplab_resnet101_coco', pretrained=True, ctx=ctx)\n",
    "\n",
    "# FT-Direct, no freezing layers\n",
    "# # Freeze Layers (keeping track of the updated parameters)\n",
    "# updated_params = []\n",
    "# for param in deeplab_ft_direct_f32.collect_params().values():\n",
    "#     if param.grad_req == \"write\":\n",
    "#         param.grad_req = \"null\"\n",
    "#         updated_params += [param.name]\n",
    "\n",
    "# Replace the last layers\n",
    "deeplab_ft_direct_f32.head = gcv.model_zoo.deeplabv3._DeepLabHead(2)\n",
    "deeplab_ft_direct_f32.head.initialize(ctx=ctx)\n",
    "\n",
    "# DeepLab v3 has an additional auxiliary output for training/loss\n",
    "# Not required for our person detector\n",
    "deeplab_ft_direct_f32.aux = False\n",
    "for param in deeplab_ft_direct_f32.auxlayer.collect_params().values():\n",
    "    if param.grad_req == \"write\":\n",
    "        param.grad_req = \"null\"\n",
    "\n",
    "deeplab_ft_direct_f32.hybridize(static_alloc=True, static_shape=True)\n",
    "\n",
    "model_filename_ft_direct_f32 = \"deeplab_resnet101_coco_ft_direct_f32.params\"\n",
    "\n",
    "reload(seg_model)\n",
    "\n",
    "loss_fn = gcv.loss.SoftmaxCrossEntropyLoss()\n",
    "\n",
    "# Epochs & Batch Size\n",
    "epochs = 10\n",
    "batch_size = 4\n",
    "\n",
    "# Define Optimizer and Hyper Parameters\n",
    "trainer = mx.gluon.Trainer(deeplab_ft_direct_f32.collect_params(), \"sgd\", {\"learning_rate\": 1.0})\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "training_loss, validation_loss = seg_model.training_loop(\n",
    "    deeplab_ft_direct_f32,\n",
    "    loss_fn, \n",
    "    trainer, \n",
    "    epochs, \n",
    "    batch_size, \n",
    "    p_train, \n",
    "    p_val, \n",
    "    model_filename_ft_direct_f32, \n",
    "    ctx)\n",
    "\n",
    "print(\"Training time for 10 epochs:\", time.time() - start_time, \"/ Best validation loss:\", min(validation_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0d44e6",
   "metadata": {},
   "source": [
    "###Â Float16 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "943cfc48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bebe5ad5dad495688cd7b3dfc5d46ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16:25:09] /work/mxnet/src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:96: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:    1, TrL:      nan, VL:      nan\n",
      "E:    2, TrL:      nan, VL:      nan\n",
      "E:    3, TrL:      nan, VL:      nan\n",
      "E:    4, TrL:      nan, VL:      nan\n",
      "E:    5, TrL:      nan, VL:      nan\n",
      "E:    6, TrL:      nan, VL:      nan\n",
      "E:    7, TrL:      nan, VL:      nan\n",
      "E:    8, TrL:      nan, VL:      nan\n",
      "E:    9, TrL:      nan, VL:      nan\n",
      "E:   10, TrL:      nan, VL:      nan\n",
      "Training time for 10 epochs: 199.80901980400085 / Best validation loss: nan\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "deeplab_ft_direct_f16 = gcv.model_zoo.get_model('deeplab_resnet101_coco', pretrained=True, ctx=ctx)\n",
    "\n",
    "# FT-Direct, no freezing layers\n",
    "# # Freeze Layers (keeping track of the updated parameters)\n",
    "# updated_params = []\n",
    "# for param in deeplab_ft_direct_f32.collect_params().values():\n",
    "#     if param.grad_req == \"write\":\n",
    "#         param.grad_req = \"null\"\n",
    "#         updated_params += [param.name]\n",
    "\n",
    "# Replace the last layers\n",
    "deeplab_ft_direct_f16.head = gcv.model_zoo.deeplabv3._DeepLabHead(2)\n",
    "deeplab_ft_direct_f16.head.initialize(ctx=ctx)\n",
    "\n",
    "# Float16 model\n",
    "deeplab_ft_direct_f16.cast('float16')\n",
    "\n",
    "# DeepLab v3 has an additional auxiliary output for training/loss\n",
    "# Not required for our person detector\n",
    "deeplab_ft_direct_f16.aux = False\n",
    "for param in deeplab_ft_direct_f16.auxlayer.collect_params().values():\n",
    "    if param.grad_req == \"write\":\n",
    "        param.grad_req = \"null\"\n",
    "\n",
    "deeplab_ft_direct_f16.hybridize(static_alloc=True, static_shape=True)\n",
    "\n",
    "model_filename_ft_direct_f16 = \"deeplab_resnet101_coco_ft_direct_f16.params\"\n",
    "\n",
    "reload(seg_model)\n",
    "\n",
    "loss_fn = gcv.loss.SoftmaxCrossEntropyLoss()\n",
    "\n",
    "# Epochs & Batch Size\n",
    "epochs = 10\n",
    "batch_size = 4\n",
    "\n",
    "# Define Optimizer and Hyper Parameters\n",
    "trainer = mx.gluon.Trainer(deeplab_ft_direct_f16.collect_params(), \"sgd\", {\n",
    "    \"learning_rate\": 1e-6, \n",
    "    \"multi_precision\": True\n",
    "})\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "training_loss, validation_loss = seg_model.training_loop(\n",
    "    deeplab_ft_direct_f16,\n",
    "    loss_fn, \n",
    "    trainer, \n",
    "    epochs, \n",
    "    batch_size, \n",
    "    p_train, \n",
    "    p_val, \n",
    "    model_filename_ft_direct_f16, \n",
    "    ctx,\n",
    "    half_precision=True)\n",
    "\n",
    "print(\"Training time for 10 epochs:\", time.time() - start_time, \"/ Best validation loss:\", min(validation_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f643a75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65519 as Float16: 65504.000000000000000000000000000000\n",
      "65520 as Float16: inf\n",
      "65519 as Float16: 0.000000119209289550781250000000\n",
      "65520 as Float16: 0.000000000000000000000000000000\n"
     ]
    }
   ],
   "source": [
    "a = mx.nd.array([65519], dtype=np.float16)\n",
    "b = mx.nd.array([65520], dtype=np.float16)\n",
    "\n",
    "print(\"65519 as Float16: {0:.30f}\".format(a.asscalar()))\n",
    "print(\"65520 as Float16: {0:.30f}\".format(b.asscalar()))\n",
    "\n",
    "a = mx.nd.array([1e-7], dtype=np.float16)\n",
    "b = mx.nd.array([1e-8], dtype=np.float16)\n",
    "\n",
    "print(\"65519 as Float16: {0:.30f}\".format(a.asscalar()))\n",
    "print(\"65520 as Float16: {0:.30f}\".format(b.asscalar()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddd30b8",
   "metadata": {},
   "source": [
    "###Â Automatic Mixed Precision (AMP) Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66984439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "464e0c1ef68f4913943e47baaee4d760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:    1, TrL:      inf, VL: 1.024292 --- Updating saved model\n",
      "E:    2, TrL: 0.797540, VL: 1.140231\n",
      "E:    3, TrL: 0.812618, VL: 0.979564 --- Updating saved model\n",
      "E:    4, TrL: 0.743529, VL: 1.035632\n",
      "E:    5, TrL: 0.687345, VL: 0.920520 --- Updating saved model\n",
      "E:    6, TrL: 0.646200, VL: 2.283948\n",
      "E:    7, TrL: 0.591441, VL: 0.914035 --- Updating saved model\n",
      "E:    8, TrL: 0.551181, VL: 0.775137 --- Updating saved model\n",
      "E:    9, TrL: 0.553194, VL: 0.784849\n",
      "E:   10, TrL: 0.517108, VL: 0.708273 --- Updating saved model\n",
      "Training time for 10 epochs: 217.64903020858765 / Best validation loss: 0.7082735\n"
     ]
    }
   ],
   "source": [
    "# AMP\n",
    "amp.init()\n",
    "\n",
    "# Model\n",
    "deeplab_ft_direct_amp = gcv.model_zoo.get_model('deeplab_resnet101_coco', pretrained=True, ctx=ctx)\n",
    "\n",
    "# FT-Direct, no freezing layers\n",
    "# # Freeze Layers (keeping track of the updated parameters)\n",
    "# updated_params = []\n",
    "# for param in deeplab_ft_direct_f32.collect_params().values():\n",
    "#     if param.grad_req == \"write\":\n",
    "#         param.grad_req = \"null\"\n",
    "#         updated_params += [param.name]\n",
    "\n",
    "# Replace the last layers\n",
    "deeplab_ft_direct_amp.head = gcv.model_zoo.deeplabv3._DeepLabHead(2)\n",
    "deeplab_ft_direct_amp.head.initialize(ctx=ctx)\n",
    "\n",
    "# DeepLab v3 has an additional auxiliary output for training/loss\n",
    "# Not required for our person detector\n",
    "deeplab_ft_direct_amp.aux = False\n",
    "for param in deeplab_ft_direct_amp.auxlayer.collect_params().values():\n",
    "    if param.grad_req == \"write\":\n",
    "        param.grad_req = \"null\"\n",
    "\n",
    "deeplab_ft_direct_amp.hybridize(static_alloc=True, static_shape=True)\n",
    "\n",
    "model_filename_ft_direct_amp = \"deeplab_resnet101_coco_ft_direct_amp.params\"\n",
    "\n",
    "reload(seg_model)\n",
    "\n",
    "loss_fn = gcv.loss.SoftmaxCrossEntropyLoss()\n",
    "\n",
    "# Epochs & Batch Size\n",
    "epochs = 10\n",
    "batch_size = 4\n",
    "\n",
    "# Define Optimizer and Hyper Parameters\n",
    "trainer = mx.gluon.Trainer(deeplab_ft_direct_amp.collect_params(), \"sgd\", {\"learning_rate\": 1.0})\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "training_loss, validation_loss = seg_model.training_loop(\n",
    "    deeplab_ft_direct_amp,\n",
    "    loss_fn, \n",
    "    trainer, \n",
    "    epochs, \n",
    "    batch_size, \n",
    "    p_train, \n",
    "    p_val, \n",
    "    model_filename_ft_direct_amp, \n",
    "    ctx,\n",
    "    amp_enabled=True)\n",
    "\n",
    "print(\"Training time for 10 epochs:\", time.time() - start_time, \"/ Best validation loss:\", min(validation_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a6f64e",
   "metadata": {},
   "source": [
    "#### 2x BatchSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "088cfa0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18bcdfe7c2ac4b30863838a6039aac61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:    1, TrL: 0.389132, VL: 0.303815 --- Updating saved model\n",
      "E:    2, TrL: 0.186275, VL: 0.257895 --- Updating saved model\n",
      "E:    3, TrL: 0.134914, VL: 0.210688 --- Updating saved model\n",
      "E:    4, TrL: 0.109792, VL: 0.223997\n",
      "E:    5, TrL: 0.095182, VL: 0.219189\n",
      "E:    6, TrL: 0.085338, VL: 0.195552 --- Updating saved model\n",
      "E:    7, TrL: 0.077981, VL: 0.181985 --- Updating saved model\n",
      "E:    8, TrL: 0.073843, VL: 0.193172\n",
      "E:    9, TrL: 0.068550, VL: 0.201830\n",
      "E:   10, TrL: 0.065619, VL: 0.192543\n",
      "Training time for 10 epochs: 218.82141995429993 / Best validation loss: 0.18198483\n"
     ]
    }
   ],
   "source": [
    "# AMP\n",
    "amp.init()\n",
    "\n",
    "# Model\n",
    "deeplab_ft_direct_amp = gcv.model_zoo.get_model('deeplab_resnet101_coco', pretrained=True, ctx=ctx)\n",
    "\n",
    "# FT-Direct, no freezing layers\n",
    "# # Freeze Layers (keeping track of the updated parameters)\n",
    "# updated_params = []\n",
    "# for param in deeplab_ft_direct_f32.collect_params().values():\n",
    "#     if param.grad_req == \"write\":\n",
    "#         param.grad_req = \"null\"\n",
    "#         updated_params += [param.name]\n",
    "\n",
    "# Replace the last layers\n",
    "deeplab_ft_direct_amp.head = gcv.model_zoo.deeplabv3._DeepLabHead(2)\n",
    "deeplab_ft_direct_amp.head.initialize(ctx=ctx)\n",
    "\n",
    "# DeepLab v3 has an additional auxiliary output for training/loss\n",
    "# Not required for our person detector\n",
    "deeplab_ft_direct_amp.aux = False\n",
    "for param in deeplab_ft_direct_amp.auxlayer.collect_params().values():\n",
    "    if param.grad_req == \"write\":\n",
    "        param.grad_req = \"null\"\n",
    "\n",
    "deeplab_ft_direct_amp.hybridize(static_alloc=True, static_shape=True)\n",
    "\n",
    "model_filename_ft_direct_amp = \"deeplab_resnet101_coco_ft_direct_amp.params\"\n",
    "\n",
    "reload(seg_model)\n",
    "\n",
    "loss_fn = gcv.loss.SoftmaxCrossEntropyLoss()\n",
    "\n",
    "# Epochs & Batch Size\n",
    "epochs = 10\n",
    "batch_size = 8\n",
    "\n",
    "# Define Optimizer and Hyper Parameters\n",
    "trainer = mx.gluon.Trainer(deeplab_ft_direct_amp.collect_params(), \"sgd\", {\"learning_rate\": 1.0})\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "training_loss, validation_loss = seg_model.training_loop(\n",
    "    deeplab_ft_direct_amp,\n",
    "    loss_fn, \n",
    "    trainer, \n",
    "    epochs, \n",
    "    batch_size, \n",
    "    p_train, \n",
    "    p_val, \n",
    "    model_filename_ft_direct_amp, \n",
    "    ctx,\n",
    "    amp_enabled=True)\n",
    "\n",
    "print(\"Training time for 10 epochs:\", time.time() - start_time, \"/ Best validation loss:\", min(validation_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c360c76b",
   "metadata": {},
   "source": [
    "#### 2x Batchsize + 3x epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "886c4efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a18d18dec44444d9a907d7bb52459463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:    1, TrL: 0.402396, VL: 0.277328 --- Updating saved model\n",
      "E:    2, TrL: 0.183476, VL: 0.250136 --- Updating saved model\n",
      "E:    3, TrL: 0.135281, VL: 0.200705 --- Updating saved model\n",
      "E:    4, TrL: 0.108729, VL: 0.218331\n",
      "E:    5, TrL: 0.096049, VL: 0.197262 --- Updating saved model\n",
      "E:    6, TrL: 0.087256, VL: 0.193183 --- Updating saved model\n",
      "E:    7, TrL: 0.078887, VL: 0.168608 --- Updating saved model\n",
      "E:    8, TrL: 0.073169, VL: 0.182085\n",
      "E:    9, TrL: 0.067686, VL: 0.194122\n",
      "E:   10, TrL: 0.065026, VL: 0.184833\n",
      "E:   11, TrL: 0.061416, VL: 0.164398 --- Updating saved model\n",
      "E:   12, TrL: 0.060552, VL: 0.179351\n",
      "E:   13, TrL: 0.059573, VL: 0.174664\n",
      "E:   14, TrL: 0.055687, VL: 0.213759\n",
      "E:   15, TrL: 0.054580, VL: 0.172833\n",
      "E:   16, TrL: 0.052671, VL: 0.178162\n",
      "E:   17, TrL: 0.051071, VL: 0.169275\n",
      "E:   18, TrL: 0.049306, VL: 0.201066\n",
      "E:   19, TrL: 0.048858, VL: 0.183281\n",
      "E:   20, TrL: 0.047757, VL: 0.223146\n",
      "E:   21, TrL: 0.046628, VL: 0.191476\n",
      "E:   22, TrL: 0.045585, VL: 0.194995\n",
      "E:   23, TrL: 0.045642, VL: 0.179634\n",
      "E:   24, TrL: 0.044161, VL: 0.209175\n",
      "E:   25, TrL: 0.044511, VL: 0.183108\n",
      "E:   26, TrL: 0.042922, VL: 0.202025\n",
      "E:   27, TrL: 0.042603, VL: 0.191739\n",
      "E:   28, TrL: 0.041666, VL: 0.205722\n",
      "E:   29, TrL: 0.041908, VL: 0.187950\n",
      "E:   30, TrL: 0.040699, VL: 0.218090\n",
      "Training time for 10 epochs: 645.7392318248749 / Best validation loss: 0.16439788\n"
     ]
    }
   ],
   "source": [
    "# AMP\n",
    "amp.init()\n",
    "\n",
    "# Model\n",
    "deeplab_ft_direct_amp = gcv.model_zoo.get_model('deeplab_resnet101_coco', pretrained=True, ctx=ctx)\n",
    "\n",
    "# FT-Direct, no freezing layers\n",
    "# # Freeze Layers (keeping track of the updated parameters)\n",
    "# updated_params = []\n",
    "# for param in deeplab_ft_direct_f32.collect_params().values():\n",
    "#     if param.grad_req == \"write\":\n",
    "#         param.grad_req = \"null\"\n",
    "#         updated_params += [param.name]\n",
    "\n",
    "# Replace the last layers\n",
    "deeplab_ft_direct_amp.head = gcv.model_zoo.deeplabv3._DeepLabHead(2)\n",
    "deeplab_ft_direct_amp.head.initialize(ctx=ctx)\n",
    "\n",
    "# DeepLab v3 has an additional auxiliary output for training/loss\n",
    "# Not required for our person detector\n",
    "deeplab_ft_direct_amp.aux = False\n",
    "for param in deeplab_ft_direct_amp.auxlayer.collect_params().values():\n",
    "    if param.grad_req == \"write\":\n",
    "        param.grad_req = \"null\"\n",
    "\n",
    "deeplab_ft_direct_amp.hybridize(static_alloc=True, static_shape=True)\n",
    "\n",
    "model_filename_ft_direct_amp = \"deeplab_resnet101_coco_ft_direct_amp.params\"\n",
    "\n",
    "reload(seg_model)\n",
    "\n",
    "loss_fn = gcv.loss.SoftmaxCrossEntropyLoss()\n",
    "\n",
    "# Epochs & Batch Size\n",
    "epochs = 30\n",
    "batch_size = 8\n",
    "\n",
    "# Define Optimizer and Hyper Parameters\n",
    "trainer = mx.gluon.Trainer(deeplab_ft_direct_amp.collect_params(), \"sgd\", {\"learning_rate\": 1.0})\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "training_loss, validation_loss = seg_model.training_loop(\n",
    "    deeplab_ft_direct_amp,\n",
    "    loss_fn, \n",
    "    trainer, \n",
    "    epochs, \n",
    "    batch_size, \n",
    "    p_train, \n",
    "    p_val, \n",
    "    model_filename_ft_direct_amp, \n",
    "    ctx,\n",
    "    amp_enabled=True)\n",
    "\n",
    "print(\"Training time for 10 epochs:\", time.time() - start_time, \"/ Best validation loss:\", min(validation_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c506b654",
   "metadata": {},
   "source": [
    "### Multi-GPU Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5172906d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Context variable is now a list,\n",
    "# with each element corresponding to a GPU device\n",
    "ctx_list = [mx.gpu(0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afb5464d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ext_andres_pereztorres_oxbotica_/.local/lib/python3.9/site-packages/mxnet/gluon/block.py:825: UserWarning: Parameter deeplabv30__fcnhead0_hybridsequential0_batchnorm0_running_mean, deeplabv30__fcnhead0_hybridsequential0_conv0_weight, deeplabv30__fcnhead0_hybridsequential0_conv1_weight, deeplabv30__fcnhead0_hybridsequential0_conv1_bias, deeplabv30__fcnhead0_hybridsequential0_batchnorm0_running_var, deeplabv30__fcnhead0_hybridsequential0_batchnorm0_gamma, deeplabv30__fcnhead0_hybridsequential0_batchnorm0_beta is not used by any computation. Is this intended?\n",
      "  out = self.forward(*args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:    1, TrL: 1.057983, VL: 0.220516 --- Updating saved model\n",
      "E:    2, TrL: 0.503621, VL: 0.158298 --- Updating saved model\n",
      "E:    3, TrL: 0.393605, VL: 0.123313 --- Updating saved model\n",
      "E:    4, TrL: 0.308222, VL: 0.141282\n",
      "E:    5, TrL: 0.267527, VL: 0.107261 --- Updating saved model\n",
      "E:    6, TrL: 0.248439, VL: 0.099912 --- Updating saved model\n",
      "E:    7, TrL: 0.221087, VL: 0.099837 --- Updating saved model\n",
      "E:    8, TrL: 0.201491, VL: 0.107823\n",
      "E:    9, TrL: 0.191541, VL: 0.106381\n",
      "E:   10, TrL: 0.182945, VL: 0.093767 --- Updating saved model\n",
      "Training time for 10 epochs: 647.753002166748 / Best validation loss: 0.0937674343585968\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "deeplab_ft_direct_f32 = gcv.model_zoo.get_model('deeplab_resnet101_coco', pretrained=True, ctx=ctx_list)\n",
    "\n",
    "# FT-Direct, no freezing layers\n",
    "# # Freeze Layers (keeping track of the updated parameters)\n",
    "# updated_params = []\n",
    "# for param in deeplab_ft_direct_f32.collect_params().values():\n",
    "#     if param.grad_req == \"write\":\n",
    "#         param.grad_req = \"null\"\n",
    "#         updated_params += [param.name]\n",
    "\n",
    "# Replace the last layers\n",
    "deeplab_ft_direct_f32.head = gcv.model_zoo.deeplabv3._DeepLabHead(2)\n",
    "deeplab_ft_direct_f32.head.initialize(ctx=ctx_list)\n",
    "\n",
    "# DeepLab v3 has an additional auxiliary output for training/loss\n",
    "# Not required for our person detector\n",
    "deeplab_ft_direct_f32.aux = False\n",
    "for param in deeplab_ft_direct_f32.auxlayer.collect_params().values():\n",
    "    if param.grad_req == \"write\":\n",
    "        param.grad_req = \"null\"\n",
    "\n",
    "deeplab_ft_direct_f32.hybridize(static_alloc=True, static_shape=True)\n",
    "\n",
    "model_filename_ft_direct_f32 = \"deeplab_resnet101_coco_ft_direct_f32.params\"\n",
    "\n",
    "reload(seg_model)\n",
    "\n",
    "loss_fn = gcv.loss.SoftmaxCrossEntropyLoss()\n",
    "\n",
    "# Epochs & Batch Size\n",
    "epochs = 10\n",
    "batch_size = 4\n",
    "\n",
    "# Define Optimizer and Hyper Parameters\n",
    "trainer = mx.gluon.Trainer(deeplab_ft_direct_f32.collect_params(), \"sgd\", {\"learning_rate\": 0.1})\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "training_loss, validation_loss = seg_model.multi_training_loop(\n",
    "    deeplab_ft_direct_f32,\n",
    "    loss_fn, \n",
    "    trainer, \n",
    "    epochs, \n",
    "    batch_size, \n",
    "    p_train, \n",
    "    p_val, \n",
    "    model_filename_ft_direct_f32, \n",
    "    ctx_list)\n",
    "\n",
    "print(\"Training time for 10 epochs:\", time.time() - start_time, \"/ Best validation loss:\", min(validation_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b089a804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Context variable is now a list,\n",
    "# with each element corresponding to a GPU device\n",
    "ctx_list = [mx.gpu(0), mx.gpu(1), mx.gpu(2), mx.gpu(3)]\n",
    "num_gpus = len(ctx_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac7e6be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ext_andres_pereztorres_oxbotica_/.local/lib/python3.9/site-packages/mxnet/gluon/block.py:825: UserWarning: Parameter deeplabv31__fcnhead0_hybridsequential0_conv0_weight, deeplabv31__fcnhead0_hybridsequential0_conv1_bias, deeplabv31__fcnhead0_hybridsequential0_batchnorm0_running_mean, deeplabv31__fcnhead0_hybridsequential0_batchnorm0_gamma, deeplabv31__fcnhead0_hybridsequential0_batchnorm0_beta, deeplabv31__fcnhead0_hybridsequential0_conv1_weight, deeplabv31__fcnhead0_hybridsequential0_batchnorm0_running_var is not used by any computation. Is this intended?\n",
      "  out = self.forward(*args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:    1, TrL: 4.510626, VL: 0.330724 --- Updating saved model\n",
      "E:    2, TrL: 2.277204, VL: 0.408388\n",
      "E:    3, TrL: 1.589747, VL: 0.156678 --- Updating saved model\n",
      "E:    4, TrL: 1.382671, VL: 0.313606\n",
      "E:    5, TrL: 1.031660, VL: 0.131599 --- Updating saved model\n",
      "E:    6, TrL: 1.122431, VL: 0.185414\n",
      "E:    7, TrL: 0.862841, VL: 0.091557 --- Updating saved model\n",
      "E:    8, TrL: 0.932939, VL: 0.195323\n",
      "E:    9, TrL: 0.740517, VL: 0.165574\n",
      "E:   10, TrL: 0.920897, VL: 0.082047 --- Updating saved model\n",
      "Training time for 10 epochs: 177.23532104492188 / Best validation loss: 0.082047363743186\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "deeplab_ft_direct_f32 = gcv.model_zoo.get_model('deeplab_resnet101_coco', pretrained=True, ctx=ctx_list)\n",
    "\n",
    "# FT-Direct, no freezing layers\n",
    "# # Freeze Layers (keeping track of the updated parameters)\n",
    "# updated_params = []\n",
    "# for param in deeplab_ft_direct_f32.collect_params().values():\n",
    "#     if param.grad_req == \"write\":\n",
    "#         param.grad_req = \"null\"\n",
    "#         updated_params += [param.name]\n",
    "\n",
    "# Replace the last layers\n",
    "deeplab_ft_direct_f32.head = gcv.model_zoo.deeplabv3._DeepLabHead(2)\n",
    "deeplab_ft_direct_f32.head.initialize(ctx=ctx_list)\n",
    "\n",
    "# DeepLab v3 has an additional auxiliary output for training/loss\n",
    "# Not required for our person detector\n",
    "deeplab_ft_direct_f32.aux = False\n",
    "for param in deeplab_ft_direct_f32.auxlayer.collect_params().values():\n",
    "    if param.grad_req == \"write\":\n",
    "        param.grad_req = \"null\"\n",
    "\n",
    "deeplab_ft_direct_f32.hybridize(static_alloc=True, static_shape=True)\n",
    "\n",
    "model_filename_ft_direct_f32 = \"deeplab_resnet101_coco_ft_direct_f32.params\"\n",
    "\n",
    "reload(seg_model)\n",
    "\n",
    "loss_fn = gcv.loss.SoftmaxCrossEntropyLoss()\n",
    "\n",
    "# Epochs & Batch Size\n",
    "epochs = 10\n",
    "batch_size_per_gpu = 4\n",
    "batch_size = len(ctx_list) * batch_size_per_gpu\n",
    "\n",
    "# Define Optimizer and Hyper Parameters\n",
    "trainer = mx.gluon.Trainer(deeplab_ft_direct_f32.collect_params(), \"sgd\", {\"learning_rate\": 0.5})\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "training_loss, validation_loss = seg_model.multi_training_loop(\n",
    "    deeplab_ft_direct_f32,\n",
    "    loss_fn, \n",
    "    trainer, \n",
    "    epochs, \n",
    "    batch_size, \n",
    "    p_train, \n",
    "    p_val, \n",
    "    model_filename_ft_direct_f32, \n",
    "    ctx_list)\n",
    "\n",
    "print(\"Training time for 10 epochs:\", time.time() - start_time, \"/ Best validation loss:\", min(validation_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
