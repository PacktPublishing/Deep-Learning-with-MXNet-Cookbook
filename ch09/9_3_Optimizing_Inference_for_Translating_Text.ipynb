{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de6b5fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPUs: 16\n"
     ]
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "import os\n",
    "import multiprocessing\n",
    "num_cpus = multiprocessing.cpu_count()\n",
    "\n",
    "print(\"Number of CPUs:\", num_cpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "117850d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Libraries\n",
    "import gluonnlp as nlp\n",
    "from mxnet.contrib import amp\n",
    "from mxnet.contrib import quantization\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import sacremoses\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import io\n",
    "from importlib import reload\n",
    "\n",
    "# Local Libraries\n",
    "import nmt\n",
    "import dataprocessor\n",
    "import utils\n",
    "import nmt.transformer_hparams\n",
    "import transformer_model\n",
    "\n",
    "# Hyperparameters for Dataloaders and Training\n",
    "hparams = nmt.transformer_hparams\n",
    "\n",
    "# Seeds for reproducibility\n",
    "np.random.seed(100)\n",
    "random.seed(100)\n",
    "mx.random.seed(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3974c42d",
   "metadata": {},
   "source": [
    "##Â Datasets & DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99204447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WMT2016 Dataset\n",
    "src_lang, tgt_lang = \"en\", \"de\"\n",
    "\n",
    "wmt2016_val_data = nlp.data.WMT2016BPE(\n",
    "    'newstest2016',\n",
    "    src_lang=src_lang,\n",
    "    tgt_lang=tgt_lang)\n",
    "\n",
    "wmt2016_test_data = nlp.data.WMT2016BPE(\n",
    "    'newstest2016',\n",
    "    src_lang=src_lang,\n",
    "    tgt_lang=tgt_lang)\n",
    "\n",
    "# Text sentences for evaluation\n",
    "wmt2016_val_text = nlp.data.WMT2016(\n",
    "    'newstest2016',\n",
    "    src_lang=src_lang,\n",
    "    tgt_lang=tgt_lang)\n",
    "\n",
    "wmt2016_test_text = nlp.data.WMT2016(\n",
    "    'newstest2016',\n",
    "    src_lang=src_lang,\n",
    "    tgt_lang=tgt_lang)\n",
    "\n",
    "src_max_len, tgt_max_len = 50, 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66cb8581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Val / Test sets\n",
    "val_length = 150\n",
    "test_length = 150\n",
    "\n",
    "wmt2016_val_data._data[0] = wmt2016_val_data._data[0][:val_length]\n",
    "wmt2016_val_data._data[1] = wmt2016_val_data._data[1][:val_length]\n",
    "wmt2016_val_data._length = val_length\n",
    "\n",
    "wmt2016_val_text._data[0] = wmt2016_val_text._data[0][:val_length]\n",
    "wmt2016_val_text._data[1] = wmt2016_val_text._data[1][:val_length]\n",
    "wmt2016_val_text._length = val_length\n",
    "\n",
    "wmt2016_test_data._data[0] = wmt2016_test_data._data[0][-test_length:]\n",
    "wmt2016_test_data._data[1] = wmt2016_test_data._data[1][-test_length:]\n",
    "wmt2016_test_data._length = test_length\n",
    "\n",
    "wmt2016_test_text._data[0] = wmt2016_test_text._data[0][-test_length:]\n",
    "wmt2016_test_text._data[1] = wmt2016_test_text._data[1][-test_length:]\n",
    "wmt2016_test_text._length = test_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5ff8f67-2637-4058-857f-492d6b2d52ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of val set  : 150\n",
      "Length of test set : 150\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of val set  :\", len(wmt2016_val_data))\n",
    "print(\"Length of test set :\", len(wmt2016_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "240de0dc-3437-4827-9ddc-8f366c3c331f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wmt2016_val_tgt_sentences = wmt2016_val_text.transform(lambda src, tgt: tgt, lazy=False)\n",
    "wmt2016_test_tgt_sentences = wmt2016_test_text.transform(lambda src, tgt: tgt, lazy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0c1b083-b303-4028-945a-f2b458b44c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa_109024352321806746181/anaconda3/envs/mxnet/lib/python3.8/site-packages/gluonnlp/vocab/vocab.py:590: UserWarning: Detected a corrupted index in the deserialize vocabulary. For versions before GluonNLP v0.7 the index is corrupted by specifying the same token for different special purposes, for example eos_token == padding_token. Deserializing the vocabulary nevertheless.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "reload(transformer_model)\n",
    "\n",
    "# For vocab\n",
    "wmt_model_name = \"transformer_en_de_512\"\n",
    "_, wmt_src_vocab, wmt_tgt_vocab = nlp.model.get_model(\n",
    "    wmt_model_name,\n",
    "    dataset_name='WMT2014',\n",
    "    pretrained=True,\n",
    "    ctx=mx.cpu())\n",
    "\n",
    "# Pre-processing WMT2016\n",
    "wmt_transform_fn = dataprocessor.TrainValDataTransform(\n",
    "    # wmt2016_train_data.src_vocab,\n",
    "    # wmt2016_train_data.tgt_vocab,\n",
    "    wmt_src_vocab,\n",
    "    wmt_tgt_vocab,\n",
    "    src_max_len,\n",
    "    tgt_max_len)\n",
    "\n",
    "wmt2016_val_data_processed = wmt2016_val_data.transform(\n",
    "    wmt_transform_fn)\n",
    "\n",
    "wmt2016_test_data_processed = wmt2016_test_data.transform(\n",
    "    wmt_transform_fn)\n",
    "\n",
    "wmt2016_val_data_lengths = transformer_model.get_data_lengths(wmt2016_val_data_processed)\n",
    "wmt2016_test_data_lengths = transformer_model.get_data_lengths(wmt2016_test_data_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fca7d42-592a-4f44-9f7e-5cab8b40ea2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Lengths to the datasets and indexes for validation and test\n",
    "wmt2016_val_data_len_processed = wmt2016_val_data_processed.transform(transformer_model.get_length_index_fn(), lazy=False)\n",
    "wmt2016_test_data_len_processed = wmt2016_test_data_processed.transform(transformer_model.get_length_index_fn(), lazy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10186cbc-33a2-46f3-9aa5-79883bbf05e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_batchify_fn = nlp.data.batchify.Tuple(\n",
    "    nlp.data.batchify.Pad(pad_val=0),\n",
    "    nlp.data.batchify.Pad(pad_val=0),\n",
    "    nlp.data.batchify.Stack(dtype='float32'),\n",
    "    nlp.data.batchify.Stack(dtype='float32'),\n",
    "    nlp.data.batchify.Stack())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee452323-64da-4f7e-8ec6-a66c865d2ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(transformer_model)\n",
    "\n",
    "bucket_scheme = nlp.data.ExpWidthBucket(bucket_len_step=1.2)\n",
    "\n",
    "wmt2016_val_batch_sampler = nlp.data.FixedBucketSampler(\n",
    "    lengths=wmt2016_val_data_lengths,\n",
    "    use_average_length=True, # control the element lengths (i.e. number of tokens) to be about the same\n",
    "    num_buckets=hparams.num_buckets,\n",
    "    bucket_scheme=bucket_scheme,\n",
    "    batch_size=hparams.batch_size,\n",
    "    shuffle=False)\n",
    "\n",
    "wmt2016_test_batch_sampler = nlp.data.FixedBucketSampler(\n",
    "    lengths=wmt2016_test_data_lengths,\n",
    "    use_average_length=True, # control the element lengths (i.e. number of tokens) to be about the same\n",
    "    num_buckets=hparams.num_buckets,\n",
    "    bucket_scheme=bucket_scheme,\n",
    "    batch_size=hparams.batch_size,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9701c17b-a4ce-4cb7-bb23-ea037fd23667",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 0\n",
    "\n",
    "wmt2016_val_data_loader = mx.gluon.data.DataLoader(\n",
    "    wmt2016_val_data_len_processed,\n",
    "    batch_sampler=wmt2016_val_batch_sampler,\n",
    "    batchify_fn=val_batchify_fn,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=False)\n",
    "\n",
    "wmt2016_test_data_loader = mx.gluon.data.DataLoader(\n",
    "    wmt2016_test_data_len_processed,\n",
    "    batch_sampler=wmt2016_test_batch_sampler,\n",
    "    batchify_fn=val_batchify_fn,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf43455",
   "metadata": {},
   "source": [
    "## Naive CPU Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb75a00-a5eb-4113-a675-871c23c5b478",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98bdfcf1-5059-47f1-9d6a-1cead872a902",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = mx.cpu()\n",
    "wmt_model_name = 'transformer_en_de_512'\n",
    "wmt_transformer_pt_cpu, _, _ = nlp.model.get_model(\n",
    "    wmt_model_name,\n",
    "    dataset_name='WMT2014',\n",
    "    pretrained=True,\n",
    "    ctx=ctx)\n",
    "\n",
    "wmt_translator_pt_cpu = nmt.translation.BeamSearchTranslator(\n",
    "    model=wmt_transformer_pt_cpu,\n",
    "    beam_size=hparams.beam_size,\n",
    "    scorer=nlp.model.BeamSearchScorer(alpha=hparams.lp_alpha, K=hparams.lp_k),\n",
    "    max_length=200)\n",
    "\n",
    "loss_function = nlp.loss.MaskedSoftmaxCELoss()\n",
    "wmt_detokenizer = nlp.data.SacreMosesDetokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c04b73",
   "metadata": {},
   "source": [
    "#### Quantitative Evaluation: Test Loss and BLEU score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe387274-e56d-4eb1-941e-c27f1deaa082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "603e735e299a4810ae734e3f4b724a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 373.5446252822876\n",
      "WMT16 test loss: 1.53; test bleu score: 26.40\n"
     ]
    }
   ],
   "source": [
    "# Quantitative Evaluation\n",
    "start_time = time.time()\n",
    "\n",
    "wmt2016_test_loss, wmt2016_test_translation_out = transformer_model.evaluate(\n",
    "    wmt_transformer_pt_cpu,\n",
    "    wmt2016_test_data_loader,\n",
    "    loss_function,\n",
    "    wmt_translator_pt_cpu,\n",
    "    wmt_tgt_vocab,\n",
    "    wmt_detokenizer,\n",
    "    ctx)\n",
    "\n",
    "wmt2016_test_bleu_score, _, _, _, _ = nmt.bleu.compute_bleu(\n",
    "    [wmt2016_test_tgt_sentences],\n",
    "    wmt2016_test_translation_out,\n",
    "    tokenized=False,\n",
    "    tokenizer=\"13a\",\n",
    "    split_compound_word=False,\n",
    "    bpe=False)\n",
    "\n",
    "mx.nd.waitall()\n",
    "print(\"Time (s):\", time.time() - start_time)\n",
    "\n",
    "print('WMT16 test loss: %.2f; test bleu score: %.2f'\n",
    "      %(wmt2016_test_loss, wmt2016_test_bleu_score * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8f57d8",
   "metadata": {},
   "source": [
    "#### Qualitative Evaluation: Translation from English to German Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3da0c0c-d73f-4485-857e-a437d72c46c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mx.profiler.set_config(\n",
    "    profile_all=True,\n",
    "    aggregate_stats=True,\n",
    "    continuous_dump=True,\n",
    "    filename='profile_transformer_cpu.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c607c341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qualitative Evaluation: Translating from English to German\n",
      "Expected translation:\n",
      "Ich lerne neue Dinge jeden Tag.\n",
      "In English:\n",
      "I learn new things every day.\n",
      "The German translation is:\n",
      "Ich lerne neue Dinge, die in jedem Fall auftreten.\n"
     ]
    }
   ],
   "source": [
    "# Qualitative Evaluation\n",
    "reload(transformer_model)\n",
    "\n",
    "print(\"Qualitative Evaluation: Translating from English to German\")\n",
    "\n",
    "# From Google Translate\n",
    "expected_tgt_seq = \"Ich lerne neue Dinge jeden Tag.\"\n",
    "print(\"Expected translation:\")\n",
    "print(expected_tgt_seq)\n",
    "\n",
    "src_seq = \"I learn new things every day.\"\n",
    "print(\"In English:\")\n",
    "print(src_seq)\n",
    "\n",
    "# Profiler start\n",
    "mx.profiler.set_state('run')\n",
    "\n",
    "translation_out = transformer_model.translate(\n",
    "    wmt_translator_pt_cpu,\n",
    "    src_seq,\n",
    "    # wmt2016_train_data.src_vocab,\n",
    "    # wmt2016_train_data.tgt_vocab,\n",
    "    wmt_src_vocab,\n",
    "    wmt_tgt_vocab,\n",
    "    wmt_detokenizer,\n",
    "    ctx)\n",
    "\n",
    "# Wait until all operations have completed\n",
    "mx.nd.waitall()\n",
    "# Stop recording\n",
    "mx.profiler.set_state('stop')\n",
    "# Log results\n",
    "mx.profiler.dump()\n",
    "\n",
    "print(\"The German translation is:\")\n",
    "print(\" \".join(translation_out[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218326cf-a90b-4e72-96b8-0d7a026f5249",
   "metadata": {},
   "source": [
    "## Optimal CPU Inference - Hybridation with MKLDNN and static ops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcf4592-9e86-4a3c-a041-01fc935d5d29",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5defb21-54fe-44ff-b3a3-489d3459e6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = mx.cpu()\n",
    "wmt_model_name = 'transformer_en_de_512'\n",
    "wmt_transformer_pt_cpu_hybrid, _, _ = nlp.model.get_model(\n",
    "    wmt_model_name,\n",
    "    dataset_name='WMT2014',\n",
    "    pretrained=True,\n",
    "    ctx=ctx)\n",
    "\n",
    "wmt_transformer_pt_cpu_hybrid.hybridize(backend=\"MKLDNN\", static_alloc=True, static_shape=True)\n",
    "\n",
    "wmt_translator_pt_cpu_hybrid = nmt.translation.BeamSearchTranslator(\n",
    "    model=wmt_transformer_pt_cpu_hybrid,\n",
    "    beam_size=hparams.beam_size,\n",
    "    scorer=nlp.model.BeamSearchScorer(alpha=hparams.lp_alpha, K=hparams.lp_k),\n",
    "    max_length=200)\n",
    "\n",
    "wmt_detokenizer = nlp.data.SacreMosesDetokenizer()\n",
    "\n",
    "loss_function = nlp.loss.MaskedSoftmaxCELoss()\n",
    "loss_function.hybridize(backend=\"MKLDNN\", static_alloc=True, static_shape=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf72917-f5b9-4215-94a7-7906b0c4d059",
   "metadata": {},
   "source": [
    "#### Quantitative Evaluation: Test Loss and BLEU score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53d988ab-d229-4ae2-a660-54be18ba9056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5210c69573f400399e249d397f039f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 312.5660226345062\n",
      "WMT16 test loss: 1.53; test bleu score: 26.40\n"
     ]
    }
   ],
   "source": [
    "# Quantitative Evaluation\n",
    "start_time = time.time()\n",
    "\n",
    "wmt2016_test_loss, wmt2016_test_translation_out = transformer_model.evaluate(\n",
    "    wmt_transformer_pt_cpu_hybrid,\n",
    "    wmt2016_test_data_loader,\n",
    "    loss_function,\n",
    "    wmt_translator_pt_cpu_hybrid,\n",
    "    wmt_tgt_vocab,\n",
    "    wmt_detokenizer,\n",
    "    ctx)\n",
    "\n",
    "wmt2016_test_bleu_score, _, _, _, _ = nmt.bleu.compute_bleu(\n",
    "    [wmt2016_test_tgt_sentences],\n",
    "    wmt2016_test_translation_out,\n",
    "    tokenized=False,\n",
    "    tokenizer=\"13a\",\n",
    "    split_compound_word=False,\n",
    "    bpe=False)\n",
    "\n",
    "mx.nd.waitall()\n",
    "print(\"Time (s):\", time.time() - start_time)\n",
    "\n",
    "print('WMT16 test loss: %.2f; test bleu score: %.2f'\n",
    "      %(wmt2016_test_loss, wmt2016_test_bleu_score * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54794b90-888c-4085-845c-2a3fc9f38d31",
   "metadata": {},
   "source": [
    "#### Qualitative Evaluation: Translation from English to German Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c979228-2bb7-444e-a7e7-695e80e75c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mx.profiler.set_config(\n",
    "    profile_all=True,\n",
    "    aggregate_stats=True,\n",
    "    continuous_dump=True,\n",
    "    filename='profile_transformer_cpu_hybrid.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0d96910-e272-4ff5-b1bd-124906a49cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qualitative Evaluation: Translating from English to German\n",
      "Expected translation:\n",
      "Ich lerne neue Dinge jeden Tag.\n",
      "In English:\n",
      "I learn new things every day.\n",
      "The German translation is:\n",
      "Ich lerne neue Dinge, die in jedem Fall auftreten.\n"
     ]
    }
   ],
   "source": [
    "# Qualitative Evaluation\n",
    "reload(transformer_model)\n",
    "\n",
    "print(\"Qualitative Evaluation: Translating from English to German\")\n",
    "\n",
    "# From Google Translate\n",
    "expected_tgt_seq = \"Ich lerne neue Dinge jeden Tag.\"\n",
    "print(\"Expected translation:\")\n",
    "print(expected_tgt_seq)\n",
    "\n",
    "src_seq = \"I learn new things every day.\"\n",
    "print(\"In English:\")\n",
    "print(src_seq)\n",
    "\n",
    "# Profiler start\n",
    "mx.profiler.set_state('run')\n",
    "\n",
    "translation_out = transformer_model.translate(\n",
    "    wmt_translator_pt_cpu_hybrid,\n",
    "    src_seq,\n",
    "    # wmt2016_train_data.src_vocab,\n",
    "    # wmt2016_train_data.tgt_vocab,\n",
    "    wmt_src_vocab,\n",
    "    wmt_tgt_vocab,\n",
    "    wmt_detokenizer,\n",
    "    ctx)\n",
    "\n",
    "# Wait until all operations have completed\n",
    "mx.nd.waitall()\n",
    "# Stop recording\n",
    "mx.profiler.set_state('stop')\n",
    "# Log results\n",
    "mx.profiler.dump()\n",
    "\n",
    "print(\"The German translation is:\")\n",
    "print(\" \".join(translation_out[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ab1e3c-3807-4d43-94a4-33349d714b53",
   "metadata": {},
   "source": [
    "## Naive GPU Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981a098d-d03e-4eba-96e5-8fd93a02abcb",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "309ae71f-709e-48a1-98b1-63f643d6a48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20:09:22] /work/mxnet/src/base.cc:79: cuDNN lib mismatch: linked-against version 8600 != compiled-against version 8204.  Set MXNET_CUDNN_LIB_CHECKING=0 to quiet this warning.\n"
     ]
    }
   ],
   "source": [
    "ctx = mx.gpu()\n",
    "wmt_model_name = 'transformer_en_de_512'\n",
    "wmt_transformer_pt_gpu, _, _ = nlp.model.get_model(\n",
    "    wmt_model_name,\n",
    "    dataset_name='WMT2014',\n",
    "    pretrained=True,\n",
    "    ctx=ctx)\n",
    "\n",
    "wmt_translator_pt_gpu = nmt.translation.BeamSearchTranslator(\n",
    "    model=wmt_transformer_pt_gpu,\n",
    "    beam_size=hparams.beam_size,\n",
    "    scorer=nlp.model.BeamSearchScorer(alpha=hparams.lp_alpha, K=hparams.lp_k),\n",
    "    max_length=200)\n",
    "\n",
    "loss_function = nlp.loss.MaskedSoftmaxCELoss()\n",
    "wmt_detokenizer = nlp.data.SacreMosesDetokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ccf48b-33f0-4f19-97a3-85b2e073939c",
   "metadata": {},
   "source": [
    "#### Quantitative Evaluation: Test Loss and BLEU score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fdeb4d1-8601-489d-ae21-546a764aa032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc2d08324b0e440da82e855898498c85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 61.67868137359619\n",
      "WMT16 test loss: 1.53; test bleu score: 26.40\n"
     ]
    }
   ],
   "source": [
    "# Quantitative Evaluation\n",
    "start_time = time.time()\n",
    "\n",
    "wmt2016_test_loss, wmt2016_test_translation_out = transformer_model.evaluate(\n",
    "    wmt_transformer_pt_gpu,\n",
    "    wmt2016_test_data_loader,\n",
    "    loss_function,\n",
    "    wmt_translator_pt_gpu,\n",
    "    wmt_tgt_vocab,\n",
    "    wmt_detokenizer,\n",
    "    ctx)\n",
    "\n",
    "wmt2016_test_bleu_score, _, _, _, _ = nmt.bleu.compute_bleu(\n",
    "    [wmt2016_test_tgt_sentences],\n",
    "    wmt2016_test_translation_out,\n",
    "    tokenized=False,\n",
    "    tokenizer=\"13a\",\n",
    "    split_compound_word=False,\n",
    "    bpe=False)\n",
    "\n",
    "mx.nd.waitall()\n",
    "print(\"Time (s):\", time.time() - start_time)\n",
    "\n",
    "print('WMT16 test loss: %.2f; test bleu score: %.2f'\n",
    "      %(wmt2016_test_loss, wmt2016_test_bleu_score * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9433fc77-a9f6-4331-ac62-3a71d90da543",
   "metadata": {},
   "source": [
    "#### Qualitative Evaluation: Translation from English to German Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01a15ebe-1ce8-4fb0-b39f-4b98f5d03a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "mx.profiler.set_config(\n",
    "    profile_all=True,\n",
    "    aggregate_stats=True,\n",
    "    continuous_dump=True,\n",
    "    filename='profile_transformer_gpu.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a248d40c-3302-4724-a077-8452524e6dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qualitative Evaluation: Translating from English to German\n",
      "Expected translation:\n",
      "Ich lerne neue Dinge jeden Tag.\n",
      "In English:\n",
      "I learn new things every day.\n",
      "The German translation is:\n",
      "Ich lerne neue Dinge, die in jedem Fall auftreten.\n"
     ]
    }
   ],
   "source": [
    "# Qualitative Evaluation\n",
    "reload(transformer_model)\n",
    "\n",
    "print(\"Qualitative Evaluation: Translating from English to German\")\n",
    "\n",
    "# From Google Translate\n",
    "expected_tgt_seq = \"Ich lerne neue Dinge jeden Tag.\"\n",
    "print(\"Expected translation:\")\n",
    "print(expected_tgt_seq)\n",
    "\n",
    "src_seq = \"I learn new things every day.\"\n",
    "print(\"In English:\")\n",
    "print(src_seq)\n",
    "\n",
    "# Profiler start\n",
    "mx.profiler.set_state('run')\n",
    "\n",
    "translation_out = transformer_model.translate(\n",
    "    wmt_translator_pt_gpu,\n",
    "    src_seq,\n",
    "    # wmt2016_train_data.src_vocab,\n",
    "    # wmt2016_train_data.tgt_vocab,\n",
    "    wmt_src_vocab,\n",
    "    wmt_tgt_vocab,\n",
    "    wmt_detokenizer,\n",
    "    ctx)\n",
    "\n",
    "# Wait until all operations have completed\n",
    "mx.nd.waitall()\n",
    "# Stop recording\n",
    "mx.profiler.set_state('stop')\n",
    "# Log results\n",
    "mx.profiler.dump()\n",
    "\n",
    "print(\"The German translation is:\")\n",
    "print(\" \".join(translation_out[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6a1d2d-5baf-4acd-b359-d10af3562c17",
   "metadata": {},
   "source": [
    "## Optimal GPU Inference - Hybridation with static ops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439c7be5-caef-4523-b34f-4ba996900235",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a06f145-4cc0-4941-b49e-6eda722fdac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:09:37] /work/mxnet/src/base.cc:79: cuDNN lib mismatch: linked-against version 8600 != compiled-against version 8204.  Set MXNET_CUDNN_LIB_CHECKING=0 to quiet this warning.\n"
     ]
    }
   ],
   "source": [
    "ctx = mx.gpu()\n",
    "wmt_model_name = 'transformer_en_de_512'\n",
    "wmt_transformer_pt_gpu_hybrid, _, _ = nlp.model.get_model(\n",
    "    wmt_model_name,\n",
    "    dataset_name='WMT2014',\n",
    "    pretrained=True,\n",
    "    ctx=ctx)\n",
    "\n",
    "wmt_transformer_pt_gpu_hybrid.hybridize(static_alloc=True, static_shape=True)\n",
    "\n",
    "loss_function = nlp.loss.MaskedSoftmaxCELoss()\n",
    "loss_function.hybridize(static_alloc=True, static_shape=True)\n",
    "\n",
    "wmt_detokenizer = nlp.data.SacreMosesDetokenizer()\n",
    "\n",
    "wmt_translator_pt_gpu_hybrid = nmt.translation.BeamSearchTranslator(\n",
    "    model=wmt_transformer_pt_gpu_hybrid,\n",
    "    beam_size=hparams.beam_size,\n",
    "    scorer=nlp.model.BeamSearchScorer(alpha=hparams.lp_alpha, K=hparams.lp_k),\n",
    "    max_length=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673f97da-b7c7-4eb3-9f3f-035abb80926a",
   "metadata": {},
   "source": [
    "#### Quantitative Evaluation: Test Loss and BLEU score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ffd3c25-a5d6-4ad5-88db-9a7d0794fb55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec83042679e64c7bb1e629e27c93062f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 53.31840801239014\n",
      "WMT16 test loss: 1.53; test bleu score: 26.40\n"
     ]
    }
   ],
   "source": [
    "# Quantitative Evaluation\n",
    "start_time = time.time()\n",
    "\n",
    "wmt2016_test_loss, wmt2016_test_translation_out = transformer_model.evaluate(\n",
    "    wmt_transformer_pt_gpu_hybrid,\n",
    "    wmt2016_test_data_loader,\n",
    "    loss_function,\n",
    "    wmt_translator_pt_gpu_hybrid,\n",
    "    wmt_tgt_vocab,\n",
    "    wmt_detokenizer,\n",
    "    ctx)\n",
    "\n",
    "wmt2016_test_bleu_score, _, _, _, _ = nmt.bleu.compute_bleu(\n",
    "    [wmt2016_test_tgt_sentences],\n",
    "    wmt2016_test_translation_out,\n",
    "    tokenized=False,\n",
    "    tokenizer=\"13a\",\n",
    "    split_compound_word=False,\n",
    "    bpe=False)\n",
    "\n",
    "mx.nd.waitall()\n",
    "print(\"Time (s):\", time.time() - start_time)\n",
    "\n",
    "print('WMT16 test loss: %.2f; test bleu score: %.2f'\n",
    "      %(wmt2016_test_loss, wmt2016_test_bleu_score * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e7d6e1-03eb-4379-a2b8-86fd03ef030f",
   "metadata": {},
   "source": [
    "#### Qualitative Evaluation: Translation from English to German Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7004618b-c8ed-41da-9136-7f331b4c7865",
   "metadata": {},
   "outputs": [],
   "source": [
    "mx.profiler.set_config(\n",
    "    profile_all=True,\n",
    "    aggregate_stats=True,\n",
    "    continuous_dump=True,\n",
    "    filename='profile_transformer_gpu_hybrid.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "769f2fa3-e125-46eb-b1d4-7e6ed52022e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qualitative Evaluation: Translating from English to German\n",
      "Expected translation:\n",
      "Ich lerne neue Dinge jeden Tag.\n",
      "In English:\n",
      "I learn new things every day.\n",
      "The German translation is:\n",
      "Ich lerne neue Dinge, die in jedem Fall auftreten.\n"
     ]
    }
   ],
   "source": [
    "# Qualitative Evaluation\n",
    "reload(transformer_model)\n",
    "\n",
    "print(\"Qualitative Evaluation: Translating from English to German\")\n",
    "\n",
    "# From Google Translate\n",
    "expected_tgt_seq = \"Ich lerne neue Dinge jeden Tag.\"\n",
    "print(\"Expected translation:\")\n",
    "print(expected_tgt_seq)\n",
    "\n",
    "src_seq = \"I learn new things every day.\"\n",
    "print(\"In English:\")\n",
    "print(src_seq)\n",
    "\n",
    "# Profiler start\n",
    "mx.profiler.set_state('run')\n",
    "\n",
    "translation_out = transformer_model.translate(\n",
    "    wmt_translator_pt_gpu_hybrid,\n",
    "    src_seq,\n",
    "    # wmt2016_train_data.src_vocab,\n",
    "    # wmt2016_train_data.tgt_vocab,\n",
    "    wmt_src_vocab,\n",
    "    wmt_tgt_vocab,\n",
    "    wmt_detokenizer,\n",
    "    ctx)\n",
    "\n",
    "# Wait until all operations have completed\n",
    "mx.nd.waitall()\n",
    "# Stop recording\n",
    "mx.profiler.set_state('stop')\n",
    "# Log results\n",
    "mx.profiler.dump()\n",
    "\n",
    "print(\"The German translation is:\")\n",
    "print(\" \".join(translation_out[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f7a93e",
   "metadata": {},
   "source": [
    "##Â Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab3dbc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "wmt_transformer_pt_gpu_hybrid.save('transformer_pt_gpu_hybrid')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
