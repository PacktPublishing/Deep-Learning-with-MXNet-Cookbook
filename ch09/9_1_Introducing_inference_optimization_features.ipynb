{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de6b5fce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "117850d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import matplotlib.pyplot as plt\n",
    "import mxnet as mx\n",
    "from mxnet.contrib import amp\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import gluoncv as gcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a808af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41b718a675cc472e9e29180cc3046694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18:04:59] /work/mxnet/src/base.cc:79: cuDNN lib mismatch: linked-against version 8200 != compiled-against version 8201.  Set MXNET_CUDNN_LIB_CHECKING=0 to quiet this warning.\n"
     ]
    }
   ],
   "source": [
    "# Dataset Loading & Transforming\n",
    "image_size = 640\n",
    "\n",
    "input_transform_fn = mx.gluon.data.vision.transforms.Compose([\n",
    "    mx.gluon.data.vision.transforms.Resize(image_size, keep_ratio=True),\n",
    "    mx.gluon.data.vision.transforms.CenterCrop(image_size),\n",
    "    mx.gluon.data.vision.transforms.ToTensor(),\n",
    "    mx.gluon.data.vision.transforms.Normalize([.485, .456, .406], [.229, .224, .225])\n",
    "])\n",
    "\n",
    "to_gpu_fn = lambda x: x.as_in_context(mx.gpu())\n",
    "\n",
    "input_transform_fn_gpu = mx.gluon.data.vision.transforms.Compose([\n",
    "    to_gpu_fn,\n",
    "    input_transform_fn\n",
    "])\n",
    "\n",
    "# Pre-processing in GPU, with transforms\n",
    "# then copying back to CPU memory space\n",
    "\n",
    "# Pre-processing in GPU, with transforms\n",
    "# Unfortunately, we cannot copy directly into GPU the labels\n",
    "# Not supported ty ADE20KSegmentation class\n",
    "\n",
    "to_cpu_fn = lambda x: x.as_in_context(mx.cpu())\n",
    "\n",
    "input_transform_fn_gpu_cpu = mx.gluon.data.vision.transforms.Compose([\n",
    "    input_transform_fn_gpu,\n",
    "    to_cpu_fn\n",
    "])\n",
    "\n",
    "# No need for mask transform changes\n",
    "ade20k_val_cpu = gcv.data.ADE20KSegmentation(split='val')\n",
    "\n",
    "# Limit to 500 samples\n",
    "max_samples = 500\n",
    "samples = range(0, max_samples)\n",
    "\n",
    "ade20k_val_cpu_pre = mx.gluon.data.SimpleDataset([(ade20k_val_cpu[i][0], ade20k_val_cpu[i][1]) for i in tqdm(samples)])\n",
    "ade20k_val_gpu_cpu = ade20k_val_cpu_pre.transform_first(input_transform_fn_gpu_cpu, lazy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1edf4aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 0\n",
    "batch_size = 4\n",
    "\n",
    "# DataLoader for data processed in GPU, loaded in CPU\n",
    "ade20k_val_loader_gpu_cpu = mx.gluon.data.DataLoader(\n",
    "    ade20k_val_gpu_cpu,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    last_batch=\"rollover\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531c892c",
   "metadata": {},
   "source": [
    "## Hybridize (CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc5608c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6ff2b0987b14902837b2d495953d8a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 3.9511704444885254\n"
     ]
    }
   ],
   "source": [
    "deeplab_pt_cpu = gcv.model_zoo.get_model('deeplab_resnet101_coco', pretrained=True, ctx=mx.cpu())\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for data, _ in tqdm(ade20k_val_loader_gpu_cpu):\n",
    "    deeplab_pt_cpu.predict(data)\n",
    "    \n",
    "print(\"Time (s):\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15db2b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7864bf9130647138ab5a4af1aed13bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 0.6758739948272705\n"
     ]
    }
   ],
   "source": [
    "deeplab_pt_cpu_hybrid = gcv.model_zoo.get_model('deeplab_resnet101_coco', pretrained=True, ctx=mx.cpu())\n",
    "deeplab_pt_cpu_hybrid.hybridize()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for data, _ in tqdm(ade20k_val_loader_gpu_cpu):\n",
    "    deeplab_pt_cpu_hybrid.predict(data)\n",
    "    \n",
    "print(\"Time (s):\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5584485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e7175d9ce084898a8570532764093e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 0.6158411502838135\n"
     ]
    }
   ],
   "source": [
    "deeplab_pt_cpu_hybrid = gcv.model_zoo.get_model('deeplab_resnet101_coco', pretrained=True, ctx=mx.cpu())\n",
    "deeplab_pt_cpu_hybrid.hybridize(backend = \"MKLDNN\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for data, _ in tqdm(ade20k_val_loader_gpu_cpu):\n",
    "    deeplab_pt_cpu_hybrid.predict(data)\n",
    "    \n",
    "print(\"Time (s):\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc14a00",
   "metadata": {},
   "source": [
    "## Hybridize (GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed30f828",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 0\n",
    "batch_size = 16\n",
    "\n",
    "# DataLoader for data processed in GPU, loaded in CPU\n",
    "ade20k_val_loader_gpu_cpu = mx.gluon.data.DataLoader(\n",
    "    ade20k_val_cpu_pre,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    last_batch=\"rollover\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82ccb02d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "406e665a13594c24b13956c081745634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18:27:05] /work/mxnet/src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:96: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 1.6065938472747803\n"
     ]
    }
   ],
   "source": [
    "deeplab_pt_gpu = gcv.model_zoo.get_model('deeplab_resnet101_coco', pretrained=True, ctx=mx.gpu())\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for data, _ in tqdm(ade20k_val_loader_gpu_cpu):\n",
    "    deeplab_pt_gpu.predict(data.as_in_context(mx.gpu()))\n",
    "    \n",
    "print(\"Time (s):\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fd8db65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3885fc9172bd416aa78db2ebadc0760e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 0.3877408504486084\n"
     ]
    }
   ],
   "source": [
    "deeplab_pt_hybrid_default = gcv.model_zoo.get_model('deeplab_resnet101_coco', pretrained=True, ctx=mx.gpu())\n",
    "deeplab_pt_hybrid_default.hybridize()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for data, _ in tqdm(ade20k_val_loader_gpu_cpu):\n",
    "    deeplab_pt_hybrid_default.predict(data.as_in_context(mx.gpu()))\n",
    "    \n",
    "print(\"Time (s):\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17c3fd84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bb686ba701b4298a75c97811b394f5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 0.29736924171447754\n"
     ]
    }
   ],
   "source": [
    "deeplab_pt_hybrid_static_alloc = gcv.model_zoo.get_model('deeplab_resnet101_coco', pretrained=True, ctx=mx.gpu())\n",
    "deeplab_pt_hybrid_static_alloc.hybridize(static_alloc=True)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for data, _ in tqdm(ade20k_val_loader_gpu_cpu):\n",
    "    deeplab_pt_hybrid_static_alloc.predict(data.as_in_context(mx.gpu()))\n",
    "    \n",
    "print(\"Time (s):\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "657cca3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cf34898ff1942daa0f6555b55e6b090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 0.2136681079864502\n"
     ]
    }
   ],
   "source": [
    "deeplab_pt_hybrid_static_alloc_shape = gcv.model_zoo.get_model('deeplab_resnet101_coco', pretrained=True, ctx=mx.gpu())\n",
    "deeplab_pt_hybrid_static_alloc_shape.hybridize(static_alloc=True, static_shape=True)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for data, _ in tqdm(ade20k_val_loader_gpu_cpu):\n",
    "    deeplab_pt_hybrid_static_alloc_shape.predict(data.as_in_context(mx.gpu()))\n",
    "    \n",
    "print(\"Time (s):\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd98f5d",
   "metadata": {},
   "source": [
    "I can talk about symbolic and imperative programming\n",
    "HybridSequential / HybridBlock / Hybrid_forward\n",
    "\n",
    "https://github.com/awslabs/dynamic-training-with-apache-mxnet-on-aws/blob/master/docs/tutorials/gluon/custom_layer.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443425a9",
   "metadata": {},
   "source": [
    "## Automatic Mixed Precision (AMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "312679db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.contrib import amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2e784ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbffc444000c4631b99731f066eaa05c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20:19:45] /work/mxnet/src/base.cc:79: cuDNN lib mismatch: linked-against version 8200 != compiled-against version 8201.  Set MXNET_CUDNN_LIB_CHECKING=0 to quiet this warning.\n"
     ]
    }
   ],
   "source": [
    "# Dataset Loading & Transforming\n",
    "image_size = 1280\n",
    "\n",
    "input_transform_fn = mx.gluon.data.vision.transforms.Compose([\n",
    "    mx.gluon.data.vision.transforms.Resize(image_size, keep_ratio=True),\n",
    "    mx.gluon.data.vision.transforms.CenterCrop(image_size),\n",
    "    mx.gluon.data.vision.transforms.ToTensor(),\n",
    "    mx.gluon.data.vision.transforms.Normalize([.485, .456, .406], [.229, .224, .225])\n",
    "])\n",
    "\n",
    "to_gpu_fn = lambda x: x.as_in_context(mx.gpu())\n",
    "\n",
    "input_transform_fn_gpu = mx.gluon.data.vision.transforms.Compose([\n",
    "    to_gpu_fn,\n",
    "    input_transform_fn\n",
    "])\n",
    "\n",
    "# Pre-processing in GPU, with transforms\n",
    "# then copying back to CPU memory space\n",
    "to_cpu_fn = lambda x: x.as_in_context(mx.cpu())\n",
    "\n",
    "input_transform_fn_gpu_cpu = mx.gluon.data.vision.transforms.Compose([\n",
    "    input_transform_fn_gpu,\n",
    "    to_cpu_fn\n",
    "])\n",
    "\n",
    "# No need for mask transform changes\n",
    "ade20k_val_cpu = gcv.data.ADE20KSegmentation(split='val')\n",
    "\n",
    "# Limit to 500 samples\n",
    "max_samples = 500\n",
    "samples = range(0, max_samples)\n",
    "\n",
    "ade20k_val_cpu_pre = mx.gluon.data.SimpleDataset([(ade20k_val_cpu[i][0], ade20k_val_cpu[i][1]) for i in tqdm(samples)])\n",
    "ade20k_val_gpu_cpu = ade20k_val_cpu_pre.transform_first(input_transform_fn_gpu_cpu, lazy=False)\n",
    "\n",
    "# Single sample for forward pass (AMP requirement)\n",
    "original_shape = ade20k_val_gpu_cpu[0][0].shape[1:]\n",
    "single_sample_gpu = ade20k_val_gpu_cpu[0][0].reshape((1, 3) + original_shape).as_in_context(mx.gpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3b5e2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 0\n",
    "batch_size = 16\n",
    "\n",
    "# DataLoader for data processed in GPU, loaded in CPU\n",
    "ade20k_val_loader_gpu_cpu = mx.gluon.data.DataLoader(\n",
    "    ade20k_val_gpu_cpu,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    last_batch=\"rollover\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62cf8127",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20:19:59] /work/mxnet/src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:96: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\n"
     ]
    }
   ],
   "source": [
    "deeplab_pt_hybrid = gcv.model_zoo.get_model('deeplab_resnet101_coco', pretrained=True, ctx=mx.gpu())\n",
    "deeplab_pt_hybrid.predict(single_sample_gpu)\n",
    "deeplab_pt_hybrid.hybridize(static_alloc=True, static_shape=True)\n",
    "deeplab_pt_hybrid.forward(single_sample_gpu);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10f498c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ext_andres_pereztorres_oxbotica_/.local/lib/python3.7/site-packages/mxnet/gluon/block.py:1784: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:\n",
      "\tdata: None\n",
      "  input_sym_arg_type = in_param.infer_type()[0]\n"
     ]
    }
   ],
   "source": [
    "deeplab_pt_hybrid_amp = amp.convert_hybrid_block(deeplab_pt_hybrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c7f8f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d478a6eb9b3647178de4261730c7b0e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 0.29921650886535645\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for data, _ in tqdm(ade20k_val_loader_gpu_cpu):\n",
    "    deeplab_pt_hybrid_amp.forward(data.as_in_context(mx.gpu()))\n",
    "    \n",
    "print(\"Time (s):\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4e8116",
   "metadata": {},
   "source": [
    "## Quantisation (INT8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00bf3e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.contrib import quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579cd70e",
   "metadata": {},
   "source": [
    "### Calibration Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccb2480b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e801f47b02544c7bc87bbffd2fe9bb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dataset Loading & Transforming\n",
    "# Limit to 10 samples (last ones)\n",
    "max_samples = 10\n",
    "samples = range(0, max_samples)\n",
    "\n",
    "ade20k_cal_cpu_pre = mx.gluon.data.SimpleDataset([(ade20k_val_cpu[-i][0], ade20k_val_cpu[-i][1]) for i in tqdm(samples)])\n",
    "ade20k_cal_gpu_cpu = ade20k_cal_cpu_pre.transform_first(input_transform_fn_gpu_cpu, lazy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "543fca2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets / DataLoaders for Calibration & Validation\n",
    "# Pre-processed in GPU, copied back to CPU memory space)\n",
    "num_workers = 0\n",
    "batch_size = 4\n",
    "\n",
    "# DataLoader for calibration data processed in GPU, loaded in CPU\n",
    "ade20k_cal_loader_gpu_cpu = mx.gluon.data.DataLoader(\n",
    "    ade20k_cal_gpu_cpu,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    last_batch=\"rollover\")\n",
    "\n",
    "# DataLoader for validarion data processed in GPU, loaded in CPU\n",
    "ade20k_val_loader_gpu_cpu = mx.gluon.data.DataLoader(\n",
    "    ade20k_val_gpu_cpu,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    last_batch=\"rollover\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73e7e3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single sample for forward pass (Quantization requirement)\n",
    "original_shape = ade20k_cal_gpu_cpu[0][0].shape[1:]\n",
    "single_sample_gpu = ade20k_cal_gpu_cpu[0][0].reshape((1, 3) + original_shape).as_in_context(mx.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0657b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplab_pt_hybrid = gcv.model_zoo.get_model('deeplab_resnet101_coco', pretrained=True, ctx=mx.cpu())\n",
    "deeplab_pt_hybrid.predict(single_sample_gpu);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f9a3673",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[12:29:12] /work/mxnet/src/executor/graph_executor.cc:1991: Subgraph backend MKLDNN is activated.\n",
      "/home/ext_andres_pereztorres_oxbotica_/.local/lib/python3.7/site-packages/mxnet/gluon/block.py:1784: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:\n",
      "\tdata: None\n",
      "  input_sym_arg_type = in_param.infer_type()[0]\n"
     ]
    }
   ],
   "source": [
    "deeplab_pt_hybrid_q = quantization.quantize_net_v2(\n",
    "    deeplab_pt_hybrid,\n",
    "    quantized_dtype='auto',\n",
    "    exclude_layers=None,\n",
    "    exclude_layers_match=None,\n",
    "    calib_data=ade20k_cal_loader_gpu_cpu,\n",
    "    calib_mode='entropy',\n",
    "    num_calib_examples=None,\n",
    "    ctx=mx.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfb66b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplab_pt_hybrid_q.hybridize(static_alloc=True, static_shape=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "307e35b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38640174cc5c47e8a705e48114a3844d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 0.19214582443237305\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for data, _ in tqdm(ade20k_val_loader_gpu_cpu):\n",
    "    deeplab_pt_hybrid_q.forward(data)\n",
    "    \n",
    "print(\"Time (s):\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a26c87",
   "metadata": {},
   "source": [
    "## ONNX Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de64bafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONNX library must be installed for this\n",
    "# !python3 -m pip install onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed2cc578",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplab_pt_hybrid = gcv.model_zoo.get_model('deeplab_resnet101_coco', pretrained=True, ctx=mx.cpu())\n",
    "deeplab_pt_hybrid.predict(single_sample_gpu)\n",
    "deeplab_pt_hybrid.hybridize()\n",
    "deeplab_pt_hybrid.forward(single_sample_gpu)\n",
    "\n",
    "# Need to be exported externally for the symbols to be loaded\n",
    "deeplab_pt_hybrid_filename = \"deeplab_resnet101_coco_pt_hybrid\"\n",
    "deeplab_pt_hybrid.export(deeplab_pt_hybrid_filename)\n",
    "\n",
    "# Files exported\n",
    "sym_filename = deeplab_pt_hybrid_filename + \"-symbol.json\"\n",
    "params_filename = deeplab_pt_hybrid_filename + \"-0000.params\"\n",
    "\n",
    "# Verify generated files\n",
    "assert os.path.exists(sym_filename)\n",
    "assert os.path.exists(params_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1143996a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deeplab_resnet101_coco_pt_hybrid.onnx'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_file_name = \"deeplab_resnet101_coco_pt_hybrid.onnx\"\n",
    "in_shapes = [single_sample_gpu.shape]\n",
    "in_types = [mx.np.float32]\n",
    "\n",
    "onnx_model_path = mx.onnx.export_model(\n",
    "    sym_filename,\n",
    "    params_filename,\n",
    "    in_shapes,\n",
    "    in_types,\n",
    "    onnx_file_name)\n",
    "\n",
    "onnx_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09e0dcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Verification\n",
    "import onnx\n",
    "\n",
    "# Load the ONNX model\n",
    "onnx_model = onnx.load_model(onnx_model_path)\n",
    "\n",
    "# Check the ONNX graph\n",
    "onnx.checker.check_graph(onnx_model.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1d167c",
   "metadata": {},
   "source": [
    "## TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1f88541",
   "metadata": {},
   "outputs": [],
   "source": [
    "sym, arg_params, aux_params = mx.model.load_checkpoint(deeplab_pt_hybrid_filename, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30a5ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute with MXNet\n",
    "batch_shape = (batch_size, 3) + original_shape\n",
    "\n",
    "executor = sym.simple_bind(\n",
    "    ctx=mx.gpu(),\n",
    "    data=batch_shape,\n",
    "    grad_req='null',\n",
    "    force_rebind=True)\n",
    "executor.copy_params_from(arg_params, aux_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10a791dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warming up MXNet\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8b9f09f7f5742a9892cccdd310fa93c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[13:04:43] /work/mxnet/src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:96: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting MXNet timed run\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50589a9a8fad403e969d05fbe77b702b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119.123826382\n"
     ]
    }
   ],
   "source": [
    "# Warmup\n",
    "print('Warming up MXNet')\n",
    "for data, _ in tqdm(ade20k_cal_loader_gpu_cpu):\n",
    "    y_gen = executor.forward(is_train=False, data=data)\n",
    "    y_gen[0].wait_to_read()\n",
    "\n",
    "# Timing\n",
    "print('Starting MXNet timed run')\n",
    "start_time = time.time()\n",
    "for data, _ in tqdm(ade20k_val_loader_gpu_cpu):\n",
    "    y_gen = executor.forward(is_train=False, data=data)\n",
    "    y_gen[0].wait_to_read()\n",
    "\n",
    "print(\"Time (s):\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db05852e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building TensorRT engine\n"
     ]
    },
    {
     "ename": "MXNetError",
     "evalue": "Traceback (most recent call last):\n  File \"/work/mxnet/src/c_api/../operator/subgraph/subgraph_property.h\", line 532\nMXNetError: Check failed: it != backend_map_.end(): SubgraphProperty TensorRT is not found in SubgraphBackendRegistry",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMXNetError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_7957/2903360327.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Execute with TensorRT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Building TensorRT engine'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrt_sym\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_backend_symbol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TensorRT'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0marg_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorrt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_tensorrt_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrt_sym\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorrt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_use_fp16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/mxnet/symbol/symbol.py\u001b[0m in \u001b[0;36mget_backend_symbol\u001b[0;34m(self, backend)\u001b[0m\n\u001b[1;32m   2877\u001b[0m         \"\"\"\n\u001b[1;32m   2878\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSymbolHandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2879\u001b[0;31m         \u001b[0mcheck_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMXGenBackendSubgraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2880\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mSymbol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/mxnet/base.py\u001b[0m in \u001b[0;36mcheck_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \"\"\"\n\u001b[1;32m    245\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mget_last_ffi_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMXNetError\u001b[0m: Traceback (most recent call last):\n  File \"/work/mxnet/src/c_api/../operator/subgraph/subgraph_property.h\", line 532\nMXNetError: Check failed: it != backend_map_.end(): SubgraphProperty TensorRT is not found in SubgraphBackendRegistry"
     ]
    }
   ],
   "source": [
    "# Execute with TensorRT\n",
    "print('Building TensorRT engine')\n",
    "trt_sym = sym.get_backend_symbol('TensorRT')\n",
    "arg_params, aux_params = mx.contrib.tensorrt.init_tensorrt_params(trt_sym, arg_params, aux_params)\n",
    "mx.contrib.tensorrt.set_use_fp16(True)\n",
    "\n",
    "executor = trt_sym.simple_bind(\n",
    "    ctx=mx.gpu(),\n",
    "    data=batch_shape,\n",
    "    grad_req='null',\n",
    "    force_rebind=True)\n",
    "\n",
    "executor.copy_params_from(arg_params, aux_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b6dccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warmup\n",
    "print('Warming up TRT')\n",
    "for data, _ in tqdm(ade20k_cal_loader_gpu_cpu):\n",
    "    y_gen = executor.forward(is_train=False, data=data)\n",
    "    y_gen[0].wait_to_read()\n",
    "\n",
    "# Timing\n",
    "print('Starting TRT timed run')\n",
    "start_time = time.time()\n",
    "for data, _ in tqdm(ade20k_val_loader_gpu_cpu):\n",
    "    y_gen = executor.forward(is_train=False, data=data)\n",
    "    y_gen[0].wait_to_read()\n",
    "\n",
    "print(\"Time (s):\", time.time() - start_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
