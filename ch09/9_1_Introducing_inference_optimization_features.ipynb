{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de6b5fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "117850d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import matplotlib.pyplot as plt\n",
    "import mxnet as mx\n",
    "from mxnet.contrib import amp\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import gluoncv as gcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a808af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dae2d5f410974129816d711c05fcbb5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[21:13:20] /work/mxnet/src/base.cc:79: cuDNN lib mismatch: linked-against version 8600 != compiled-against version 8204.  Set MXNET_CUDNN_LIB_CHECKING=0 to quiet this warning.\n"
     ]
    }
   ],
   "source": [
    "# Dataset Loading & Transforming\n",
    "image_size = 640\n",
    "\n",
    "input_transform_fn = mx.gluon.data.vision.transforms.Compose([\n",
    "    mx.gluon.data.vision.transforms.Resize(image_size, keep_ratio=True),\n",
    "    mx.gluon.data.vision.transforms.CenterCrop(image_size),\n",
    "    mx.gluon.data.vision.transforms.ToTensor(),\n",
    "    mx.gluon.data.vision.transforms.Normalize([.485, .456, .406], [.229, .224, .225])\n",
    "])\n",
    "\n",
    "to_gpu_fn = lambda x: x.as_in_context(mx.gpu())\n",
    "\n",
    "input_transform_fn_gpu = mx.gluon.data.vision.transforms.Compose([\n",
    "    to_gpu_fn,\n",
    "    input_transform_fn\n",
    "])\n",
    "\n",
    "# Pre-processing in GPU, with transforms\n",
    "# then copying back to CPU memory space\n",
    "\n",
    "# Pre-processing in GPU, with transforms\n",
    "# Unfortunately, we cannot copy directly into GPU the labels\n",
    "# Not supported ty ADE20KSegmentation class\n",
    "\n",
    "to_cpu_fn = lambda x: x.as_in_context(mx.cpu())\n",
    "\n",
    "input_transform_fn_gpu_cpu = mx.gluon.data.vision.transforms.Compose([\n",
    "    input_transform_fn_gpu,\n",
    "    to_cpu_fn\n",
    "])\n",
    "\n",
    "# No need for mask transform changes\n",
    "ade20k_val_cpu = gcv.data.ADE20KSegmentation(split='val')\n",
    "\n",
    "# Limit to 500 samples\n",
    "max_samples = 500\n",
    "samples = range(0, max_samples)\n",
    "\n",
    "ade20k_val_cpu_pre = mx.gluon.data.SimpleDataset([(ade20k_val_cpu[i][0], ade20k_val_cpu[i][1]) for i in tqdm(samples)])\n",
    "ade20k_val_gpu_cpu = ade20k_val_cpu_pre.transform_first(input_transform_fn_gpu_cpu, lazy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1edf4aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 0\n",
    "batch_size = 4\n",
    "\n",
    "# DataLoader for data processed in GPU, loaded in CPU\n",
    "ade20k_val_loader_gpu_cpu = mx.gluon.data.DataLoader(\n",
    "    ade20k_val_gpu_cpu,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    last_batch=\"rollover\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531c892c",
   "metadata": {},
   "source": [
    "## Hybridize (CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc5608c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6ff2b0987b14902837b2d495953d8a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 3.9511704444885254\n"
     ]
    }
   ],
   "source": [
    "deeplab_pt_cpu = gcv.model_zoo.get_model('deeplab_resnet101_coco', pretrained=True, ctx=mx.cpu())\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for data, _ in tqdm(ade20k_val_loader_gpu_cpu):\n",
    "    deeplab_pt_cpu.predict(data)\n",
    "    \n",
    "print(\"Time (s):\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15db2b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7864bf9130647138ab5a4af1aed13bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 0.6758739948272705\n"
     ]
    }
   ],
   "source": [
    "deeplab_pt_cpu_hybrid = gcv.model_zoo.get_model('deeplab_resnet101_coco', pretrained=True, ctx=mx.cpu())\n",
    "deeplab_pt_cpu_hybrid.hybridize()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for data, _ in tqdm(ade20k_val_loader_gpu_cpu):\n",
    "    deeplab_pt_cpu_hybrid.predict(data)\n",
    "    \n",
    "print(\"Time (s):\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5584485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e7175d9ce084898a8570532764093e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 0.6158411502838135\n"
     ]
    }
   ],
   "source": [
    "deeplab_pt_cpu_hybrid = gcv.model_zoo.get_model('deeplab_resnet101_coco', pretrained=True, ctx=mx.cpu())\n",
    "deeplab_pt_cpu_hybrid.hybridize(backend = \"MKLDNN\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for data, _ in tqdm(ade20k_val_loader_gpu_cpu):\n",
    "    deeplab_pt_cpu_hybrid.predict(data)\n",
    "    \n",
    "print(\"Time (s):\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc14a00",
   "metadata": {},
   "source": [
    "## Hybridize (GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed30f828",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 0\n",
    "batch_size = 16\n",
    "\n",
    "# DataLoader for data processed in GPU, loaded in CPU\n",
    "ade20k_val_loader_gpu_cpu = mx.gluon.data.DataLoader(\n",
    "    ade20k_val_cpu_pre,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    last_batch=\"rollover\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82ccb02d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "406e665a13594c24b13956c081745634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18:27:05] /work/mxnet/src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:96: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 1.6065938472747803\n"
     ]
    }
   ],
   "source": [
    "deeplab_pt_gpu = gcv.model_zoo.get_model('deeplab_resnet101_coco', pretrained=True, ctx=mx.gpu())\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for data, _ in tqdm(ade20k_val_loader_gpu_cpu):\n",
    "    deeplab_pt_gpu.predict(data.as_in_context(mx.gpu()))\n",
    "    \n",
    "print(\"Time (s):\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fd8db65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3885fc9172bd416aa78db2ebadc0760e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 0.3877408504486084\n"
     ]
    }
   ],
   "source": [
    "deeplab_pt_hybrid_default = gcv.model_zoo.get_model('deeplab_resnet101_coco', pretrained=True, ctx=mx.gpu())\n",
    "deeplab_pt_hybrid_default.hybridize()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for data, _ in tqdm(ade20k_val_loader_gpu_cpu):\n",
    "    deeplab_pt_hybrid_default.predict(data.as_in_context(mx.gpu()))\n",
    "    \n",
    "print(\"Time (s):\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17c3fd84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bb686ba701b4298a75c97811b394f5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 0.29736924171447754\n"
     ]
    }
   ],
   "source": [
    "deeplab_pt_hybrid_static_alloc = gcv.model_zoo.get_model('deeplab_resnet101_coco', pretrained=True, ctx=mx.gpu())\n",
    "deeplab_pt_hybrid_static_alloc.hybridize(static_alloc=True)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for data, _ in tqdm(ade20k_val_loader_gpu_cpu):\n",
    "    deeplab_pt_hybrid_static_alloc.predict(data.as_in_context(mx.gpu()))\n",
    "    \n",
    "print(\"Time (s):\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "657cca3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cf34898ff1942daa0f6555b55e6b090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 0.2136681079864502\n"
     ]
    }
   ],
   "source": [
    "deeplab_pt_hybrid_static_alloc_shape = gcv.model_zoo.get_model('deeplab_resnet101_coco', pretrained=True, ctx=mx.gpu())\n",
    "deeplab_pt_hybrid_static_alloc_shape.hybridize(static_alloc=True, static_shape=True)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for data, _ in tqdm(ade20k_val_loader_gpu_cpu):\n",
    "    deeplab_pt_hybrid_static_alloc_shape.predict(data.as_in_context(mx.gpu()))\n",
    "    \n",
    "print(\"Time (s):\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd98f5d",
   "metadata": {},
   "source": [
    "I can talk about symbolic and imperative programming\n",
    "HybridSequential / HybridBlock / Hybrid_forward\n",
    "\n",
    "https://github.com/awslabs/dynamic-training-with-apache-mxnet-on-aws/blob/master/docs/tutorials/gluon/custom_layer.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443425a9",
   "metadata": {},
   "source": [
    "## Automatic Mixed Precision (AMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "312679db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.contrib import amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2e784ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbffc444000c4631b99731f066eaa05c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20:19:45] /work/mxnet/src/base.cc:79: cuDNN lib mismatch: linked-against version 8200 != compiled-against version 8201.  Set MXNET_CUDNN_LIB_CHECKING=0 to quiet this warning.\n"
     ]
    }
   ],
   "source": [
    "# Dataset Loading & Transforming\n",
    "image_size = 1280\n",
    "\n",
    "input_transform_fn = mx.gluon.data.vision.transforms.Compose([\n",
    "    mx.gluon.data.vision.transforms.Resize(image_size, keep_ratio=True),\n",
    "    mx.gluon.data.vision.transforms.CenterCrop(image_size),\n",
    "    mx.gluon.data.vision.transforms.ToTensor(),\n",
    "    mx.gluon.data.vision.transforms.Normalize([.485, .456, .406], [.229, .224, .225])\n",
    "])\n",
    "\n",
    "to_gpu_fn = lambda x: x.as_in_context(mx.gpu())\n",
    "\n",
    "input_transform_fn_gpu = mx.gluon.data.vision.transforms.Compose([\n",
    "    to_gpu_fn,\n",
    "    input_transform_fn\n",
    "])\n",
    "\n",
    "# Pre-processing in GPU, with transforms\n",
    "# then copying back to CPU memory space\n",
    "to_cpu_fn = lambda x: x.as_in_context(mx.cpu())\n",
    "\n",
    "input_transform_fn_gpu_cpu = mx.gluon.data.vision.transforms.Compose([\n",
    "    input_transform_fn_gpu,\n",
    "    to_cpu_fn\n",
    "])\n",
    "\n",
    "# No need for mask transform changes\n",
    "ade20k_val_cpu = gcv.data.ADE20KSegmentation(split='val')\n",
    "\n",
    "# Limit to 500 samples\n",
    "max_samples = 500\n",
    "samples = range(0, max_samples)\n",
    "\n",
    "ade20k_val_cpu_pre = mx.gluon.data.SimpleDataset([(ade20k_val_cpu[i][0], ade20k_val_cpu[i][1]) for i in tqdm(samples)])\n",
    "ade20k_val_gpu_cpu = ade20k_val_cpu_pre.transform_first(input_transform_fn_gpu_cpu, lazy=False)\n",
    "\n",
    "# Single sample for forward pass (AMP requirement)\n",
    "original_shape = ade20k_val_gpu_cpu[0][0].shape[1:]\n",
    "single_sample_gpu = ade20k_val_gpu_cpu[0][0].reshape((1, 3) + original_shape).as_in_context(mx.gpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3b5e2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 0\n",
    "batch_size = 16\n",
    "\n",
    "# DataLoader for data processed in GPU, loaded in CPU\n",
    "ade20k_val_loader_gpu_cpu = mx.gluon.data.DataLoader(\n",
    "    ade20k_val_gpu_cpu,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    last_batch=\"rollover\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62cf8127",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20:19:59] /work/mxnet/src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:96: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\n"
     ]
    }
   ],
   "source": [
    "deeplab_pt_hybrid = gcv.model_zoo.get_model('deeplab_resnet101_coco', pretrained=True, ctx=mx.gpu())\n",
    "deeplab_pt_hybrid.predict(single_sample_gpu)\n",
    "deeplab_pt_hybrid.hybridize(static_alloc=True, static_shape=True)\n",
    "deeplab_pt_hybrid.forward(single_sample_gpu);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10f498c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ext_andres_pereztorres_oxbotica_/.local/lib/python3.7/site-packages/mxnet/gluon/block.py:1784: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:\n",
      "\tdata: None\n",
      "  input_sym_arg_type = in_param.infer_type()[0]\n"
     ]
    }
   ],
   "source": [
    "deeplab_pt_hybrid_amp = amp.convert_hybrid_block(deeplab_pt_hybrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c7f8f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d478a6eb9b3647178de4261730c7b0e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 0.29921650886535645\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for data, _ in tqdm(ade20k_val_loader_gpu_cpu):\n",
    "    deeplab_pt_hybrid_amp.forward(data.as_in_context(mx.gpu()))\n",
    "    \n",
    "print(\"Time (s):\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4e8116",
   "metadata": {},
   "source": [
    "## Quantisation (INT8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00bf3e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.contrib import quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579cd70e",
   "metadata": {},
   "source": [
    "### Calibration Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccb2480b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fd0bf01a84c4fcf855f6179764fa1b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dataset Loading & Transforming\n",
    "# Limit to 10 samples (last ones)\n",
    "max_samples = 10\n",
    "samples = range(0, max_samples)\n",
    "\n",
    "ade20k_cal_cpu_pre = mx.gluon.data.SimpleDataset([(ade20k_val_cpu[-i][0], ade20k_val_cpu[-i][1]) for i in tqdm(samples)])\n",
    "ade20k_cal_gpu_cpu = ade20k_cal_cpu_pre.transform_first(input_transform_fn_gpu_cpu, lazy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "543fca2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets / DataLoaders for Calibration & Validation\n",
    "# Pre-processed in GPU, copied back to CPU memory space)\n",
    "num_workers = 0\n",
    "batch_size = 4\n",
    "\n",
    "# DataLoader for calibration data processed in GPU, loaded in CPU\n",
    "ade20k_cal_loader_gpu_cpu = mx.gluon.data.DataLoader(\n",
    "    ade20k_cal_gpu_cpu,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    last_batch=\"rollover\")\n",
    "\n",
    "# DataLoader for validarion data processed in GPU, loaded in CPU\n",
    "ade20k_val_loader_gpu_cpu = mx.gluon.data.DataLoader(\n",
    "    ade20k_val_gpu_cpu,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    last_batch=\"rollover\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73e7e3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single sample for forward pass (Quantization requirement)\n",
    "original_shape = ade20k_cal_gpu_cpu[0][0].shape[1:]\n",
    "single_sample_gpu = ade20k_cal_gpu_cpu[0][0].reshape((1, 3) + original_shape).as_in_context(mx.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0657b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplab_pt = gcv.model_zoo.get_model('deeplab_resnet101_coco', pretrained=True, ctx=mx.cpu())\n",
    "deeplab_pt.predict(single_sample_gpu);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f9a3673",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[21:15:25] /work/mxnet/src/executor/graph_executor.cc:1991: Subgraph backend MKLDNN is activated.\n",
      "/home/sa_109024352321806746181/anaconda3/envs/mxnet/lib/python3.8/site-packages/mxnet/gluon/block.py:1784: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:\n",
      "\tdata: None\n",
      "  input_sym_arg_type = in_param.infer_type()[0]\n"
     ]
    }
   ],
   "source": [
    "deeplab_pt_q_hybrid = quantization.quantize_net_v2(\n",
    "    deeplab_pt,\n",
    "    quantized_dtype='auto',\n",
    "    exclude_layers=None,\n",
    "    exclude_layers_match=None,\n",
    "    calib_data=ade20k_cal_loader_gpu_cpu,\n",
    "    calib_mode='entropy',\n",
    "    ctx=mx.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfb66b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplab_pt_q_hybrid.hybridize(static_alloc=True, static_shape=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "307e35b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38640174cc5c47e8a705e48114a3844d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 0.19214582443237305\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for data, _ in tqdm(ade20k_val_loader_gpu_cpu):\n",
    "    deeplab_pt_hybrid_q.forward(data)\n",
    "    \n",
    "print(\"Time (s):\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a26c87",
   "metadata": {},
   "source": [
    "## ONNX Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de64bafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONNX library must be installed for this\n",
    "# !python3 -m pip install onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed2cc578",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplab_pt_hybrid = gcv.model_zoo.get_model('deeplab_resnet101_coco', pretrained=True, ctx=mx.cpu())\n",
    "deeplab_pt_hybrid.predict(single_sample_gpu)\n",
    "deeplab_pt_hybrid.hybridize()\n",
    "deeplab_pt_hybrid.forward(single_sample_gpu)\n",
    "\n",
    "# Need to be exported externally for the symbols to be loaded\n",
    "deeplab_pt_hybrid_filename = \"deeplab_resnet101_coco_pt_hybrid\"\n",
    "deeplab_pt_hybrid.export(deeplab_pt_hybrid_filename)\n",
    "\n",
    "# Files exported\n",
    "sym_filename = deeplab_pt_hybrid_filename + \"-symbol.json\"\n",
    "params_filename = deeplab_pt_hybrid_filename + \"-0000.params\"\n",
    "\n",
    "# Verify generated files\n",
    "assert os.path.exists(sym_filename)\n",
    "assert os.path.exists(params_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1143996a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deeplab_resnet101_coco_pt_hybrid.onnx'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_file_name = \"deeplab_resnet101_coco_pt_hybrid.onnx\"\n",
    "in_shapes = [single_sample_gpu.shape]\n",
    "in_types = [mx.np.float32]\n",
    "\n",
    "onnx_model_path = mx.onnx.export_model(\n",
    "    sym_filename,\n",
    "    params_filename,\n",
    "    in_shapes,\n",
    "    in_types,\n",
    "    onnx_file_name)\n",
    "\n",
    "onnx_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09e0dcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Verification\n",
    "import onnx\n",
    "\n",
    "# Load the ONNX model\n",
    "onnx_model = onnx.load_model(onnx_model_path)\n",
    "\n",
    "# Check the ONNX graph\n",
    "onnx.checker.check_graph(onnx_model.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1d167c",
   "metadata": {},
   "source": [
    "## TensorRT Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e22b19c8-e788-4a77-9fce-5cc2a3596311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b86eeaf6-73b6-4d2a-bc34-010d728a81c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trt_file_name = \"deeplab_resnet101_coco_pt_hybrid.trt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35f63b69-633c-40b1-8554-f9e51f29c032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/20/2023-18:30:31] [TRT] [I] [MemUsageChange] Init CUDA: CPU +297, GPU +0, now: CPU 8139, GPU 1442 (MiB)\n",
      "[10/20/2023-18:30:34] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +261, GPU +74, now: CPU 8455, GPU 1516 (MiB)\n",
      "[10/20/2023-18:30:34] [TRT] [W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage. See `CUDA_MODULE_LOADING` in https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#env-vars\n"
     ]
    }
   ],
   "source": [
    "TRT_LOGGER = trt.Logger(trt.Logger.INFO)\n",
    "builder = trt.Builder(TRT_LOGGER)\n",
    "config = builder.create_builder_config()\n",
    "\n",
    "explicit_batch = 1 << (int) (trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
    "network = builder.create_network(explicit_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9939cb2d-4712-4021-a7fd-eeae6ebed5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/20/2023-18:30:37] [TRT] [W] onnx2trt_utils.cpp:377: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "network.num_layers 394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9480/3814366024.py:7: DeprecationWarning: Use build_serialized_network instead.\n",
      "  engine = builder.build_engine(network, config=config)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/20/2023-18:30:39] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 8925, GPU 1524 (MiB)\n",
      "[10/20/2023-18:30:39] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +10, now: CPU 8925, GPU 1534 (MiB)\n",
      "[10/20/2023-18:30:39] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[10/20/2023-18:31:37] [TRT] [I] Total Activation Memory: 17525805568\n",
      "[10/20/2023-18:31:37] [TRT] [I] Detected 1 inputs and 2 output network tensors.\n",
      "[10/20/2023-18:31:37] [TRT] [I] Total Host Persistent Memory: 313440\n",
      "[10/20/2023-18:31:37] [TRT] [I] Total Device Persistent Memory: 5349888\n",
      "[10/20/2023-18:31:37] [TRT] [I] Total Scratch Memory: 134217728\n",
      "[10/20/2023-18:31:37] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 257 MiB, GPU 8426 MiB\n",
      "[10/20/2023-18:31:37] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 125 steps to complete.\n",
      "[10/20/2023-18:31:37] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 2.27807ms to assign 6 blocks to 125 nodes requiring 219952640 bytes.\n",
      "[10/20/2023-18:31:37] [TRT] [I] Total Activation Memory: 219952640\n",
      "[10/20/2023-18:31:37] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +1, GPU +10, now: CPU 9373, GPU 1978 (MiB)\n",
      "[10/20/2023-18:31:37] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +233, GPU +251, now: CPU 233, GPU 251 (MiB)\n"
     ]
    }
   ],
   "source": [
    "with trt.OnnxParser(network, TRT_LOGGER) as parser:\n",
    "    with open(onnx_file_name, 'rb') as model:\n",
    "        parsed = parser.parse(model.read())\n",
    "        engine = builder.build_engine(network, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a83db1c-8923-49a4-be7e-99d9b83d2977",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(trt_file_name, 'wb') as f:\n",
    "    f.write(bytearray(engine.serialize()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea68c053-c9c6-491c-8e54-4f6a94676eaf",
   "metadata": {},
   "source": [
    "## Profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18cbff51-603c-4837-9abc-e524731643a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mx.profiler.set_config(\n",
    "    profile_all=True,\n",
    "    aggregate_stats=True,\n",
    "    continuous_dump=True,\n",
    "    filename='profile_output.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fbaa732-5ee9-4020-a089-9afa03115083",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mx.profiler.set_state('run')\n",
    "\n",
    "for data, _ in ade20k_val_loader_gpu_cpu:\n",
    "    # deeplab_pt.forward(data)\n",
    "    deeplab_pt(data)\n",
    "    break\n",
    "\n",
    "# Wait until all operations have completed\n",
    "mx.nd.waitall()\n",
    "# Stop recording\n",
    "mx.profiler.set_state('stop')\n",
    "# Log results\n",
    "mx.profiler.dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f85b72c-3f96-4b39-8280-1c9c12782706",
   "metadata": {},
   "outputs": [],
   "source": [
    "mx.profiler.set_config(\n",
    "    profile_all=True,\n",
    "    aggregate_stats=True,\n",
    "    # continuous_dump=True,\n",
    "    filename='profile_output_q_hybrid.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71cf16b3-799d-427f-8a06-938de4f14786",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mx.profiler.set_state('run')\n",
    "\n",
    "for data, _ in ade20k_val_loader_gpu_cpu:\n",
    "    # deeplab_pt_q_hybrid.forward(data)\n",
    "    deeplab_pt_q_hybrid(data)\n",
    "    break\n",
    "\n",
    "# Wait until all operations have completed\n",
    "mx.nd.waitall()\n",
    "# Stop recording\n",
    "mx.profiler.set_state('stop')\n",
    "# Log results\n",
    "mx.profiler.dump()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
