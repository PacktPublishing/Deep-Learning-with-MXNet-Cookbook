{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de6b5fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPUs: 16\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "num_cpus = multiprocessing.cpu_count()\n",
    "\n",
    "print(\"Number of CPUs:\", num_cpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "117850d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import matplotlib.pyplot as plt\n",
    "import mxnet as mx\n",
    "from mxnet.contrib import amp\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import gluoncv as gcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a808af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57f5ac935de442b2979720b5eac8095e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11:01:29] /work/mxnet/src/base.cc:79: cuDNN lib mismatch: linked-against version 8600 != compiled-against version 8204.  Set MXNET_CUDNN_LIB_CHECKING=0 to quiet this warning.\n"
     ]
    }
   ],
   "source": [
    "# Dataset Loading & Transforming\n",
    "image_size = 480\n",
    "\n",
    "input_transform_fn = mx.gluon.data.vision.transforms.Compose([\n",
    "    mx.gluon.data.vision.transforms.Resize(image_size, keep_ratio=True),\n",
    "    mx.gluon.data.vision.transforms.CenterCrop(image_size),\n",
    "    mx.gluon.data.vision.transforms.ToTensor(),\n",
    "    mx.gluon.data.vision.transforms.Normalize([.485, .456, .406], [.229, .224, .225])\n",
    "])\n",
    "\n",
    "to_gpu_fn = lambda x: x.as_in_context(mx.gpu())\n",
    "\n",
    "input_transform_fn_gpu = mx.gluon.data.vision.transforms.Compose([\n",
    "    to_gpu_fn,\n",
    "    input_transform_fn\n",
    "])\n",
    "\n",
    "# Pre-processing in GPU, with transforms\n",
    "# then copying back to CPU memory space\n",
    "\n",
    "# Pre-processing in GPU, with transforms\n",
    "# Unfortunately, we cannot copy directly into GPU the labels\n",
    "# Not supported ty ADE20KSegmentation class\n",
    "\n",
    "to_cpu_fn = lambda x: x.as_in_context(mx.cpu())\n",
    "\n",
    "input_transform_fn_gpu_cpu = mx.gluon.data.vision.transforms.Compose([\n",
    "    input_transform_fn_gpu,\n",
    "    to_cpu_fn\n",
    "])\n",
    "\n",
    "# No need for mask transform changes\n",
    "ade20k_val_cpu = gcv.data.ADE20KSegmentation(split='val')\n",
    "\n",
    "# Limit to 100 samples\n",
    "max_samples = 100\n",
    "samples = range(0, max_samples)\n",
    "\n",
    "ade20k_val_cpu_pre = mx.gluon.data.SimpleDataset([(ade20k_val_cpu[i][0], ade20k_val_cpu[i][1]) for i in tqdm(samples)])\n",
    "ade20k_val_gpu_cpu = ade20k_val_cpu_pre.transform_first(input_transform_fn_gpu_cpu, lazy=False)\n",
    "\n",
    "# Single sample for forward pass (AMP & Quantization requirement)\n",
    "original_shape = ade20k_val_gpu_cpu[0][0].shape[1:]\n",
    "single_sample_cpu = ade20k_val_gpu_cpu[0][0].reshape((1, 3) + original_shape)\n",
    "single_sample_gpu = ade20k_val_gpu_cpu[0][0].reshape((1, 3) + original_shape).as_in_context(mx.gpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1edf4aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 0\n",
    "batch_size = 4\n",
    "\n",
    "# DataLoader for data processed in GPU, loaded in CPU\n",
    "ade20k_val_loader_gpu_cpu = mx.gluon.data.DataLoader(\n",
    "    ade20k_val_gpu_cpu,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    last_batch=\"discard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531c892c",
   "metadata": {},
   "source": [
    "## Hybridize (CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc5608c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97a36f5e63344be6b518a84166bede37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 112.51623106002808\n"
     ]
    }
   ],
   "source": [
    "deeplab_pt_cpu = gcv.model_zoo.get_model('deeplab_resnet101_coco', pretrained=True, ctx=mx.cpu())\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for data, _ in tqdm(ade20k_val_loader_gpu_cpu):\n",
    "    deeplab_pt_cpu.predict(data)\n",
    "\n",
    "mx.nd.waitall()\n",
    "print(\"Time (s):\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15db2b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27a7063111274c7d9c6d696ec63b49ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 68.06627893447876\n"
     ]
    }
   ],
   "source": [
    "deeplab_pt_cpu_hybrid = gcv.model_zoo.get_model('deeplab_resnet101_coco', pretrained=True, ctx=mx.cpu())\n",
    "deeplab_pt_cpu_hybrid.hybridize()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for data, _ in tqdm(ade20k_val_loader_gpu_cpu):\n",
    "    deeplab_pt_cpu_hybrid.predict(data)\n",
    "\n",
    "mx.nd.waitall()\n",
    "print(\"Time (s):\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5584485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afcb136fa19841a3b0ac57008a5ac0f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 64.86776876449585\n"
     ]
    }
   ],
   "source": [
    "deeplab_pt_cpu_hybrid_mkldnn = gcv.model_zoo.get_model('deeplab_resnet101_coco', pretrained=True, ctx=mx.cpu())\n",
    "deeplab_pt_cpu_hybrid_mkldnn.hybridize(backend = \"MKLDNN\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for data, _ in tqdm(ade20k_val_loader_gpu_cpu):\n",
    "    deeplab_pt_cpu_hybrid_mkldnn.predict(data)\n",
    "    \n",
    "mx.nd.waitall()\n",
    "print(\"Time (s):\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba665eb8-502b-46c0-994a-eae46cc9ec61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b2f9f534dcc4e3585c33012169654b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 54.037999868392944\n"
     ]
    }
   ],
   "source": [
    "deeplab_pt_cpu_hybrid_static_alloc = gcv.model_zoo.get_model('deeplab_resnet101_coco', pretrained=True, ctx=mx.cpu())\n",
    "deeplab_pt_cpu_hybrid_static_alloc.hybridize(backend = \"MKLDNN\", static_alloc=True)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for data, _ in tqdm(ade20k_val_loader_gpu_cpu):\n",
    "    deeplab_pt_cpu_hybrid_static_alloc(data)\n",
    "    \n",
    "mx.nd.waitall()\n",
    "print(\"Time (s):\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "955d759a-1e2c-49fa-8843-e858f500489d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2b3d9da2b1f4b73800dd95a662179de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 54.02296566963196\n"
     ]
    }
   ],
   "source": [
    "deeplab_pt_cpu_hybrid_static_alloc_shape = gcv.model_zoo.get_model('deeplab_resnet101_coco', pretrained=True, ctx=mx.cpu())\n",
    "deeplab_pt_cpu_hybrid_static_alloc_shape.hybridize(backend = \"MKLDNN\", static_alloc=True, static_shape=True)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for data, _ in tqdm(ade20k_val_loader_gpu_cpu):\n",
    "    deeplab_pt_cpu_hybrid_static_alloc(data)\n",
    "    \n",
    "mx.nd.waitall()\n",
    "print(\"Time (s):\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc14a00",
   "metadata": {},
   "source": [
    "## Hybridize (GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed30f828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can work with a larger batch size in GPU\n",
    "num_workers = 0\n",
    "batch_size = 16\n",
    "\n",
    "# DataLoader for data processed in GPU, loaded in CPU\n",
    "ade20k_val_loader_gpu_cpu_bs16 = mx.gluon.data.DataLoader(\n",
    "    ade20k_val_gpu_cpu,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    last_batch=\"discard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82ccb02d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf938bb37e694ccd88b4d1a441efb5ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[09:44:01] /work/mxnet/src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:96: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 30.928452253341675\n"
     ]
    }
   ],
   "source": [
    "deeplab_pt_gpu = gcv.model_zoo.get_model('deeplab_resnet101_coco', pretrained=True, ctx=mx.gpu())\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for data, _ in tqdm(ade20k_val_loader_gpu_cpu_bs16):\n",
    "    deeplab_pt_gpu.predict(data.as_in_context(mx.gpu()))\n",
    "    \n",
    "mx.nd.waitall()\n",
    "print(\"Time (s):\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fd8db65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3737eab2c3124c14bb855b9a0bebda13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 11.506299495697021\n"
     ]
    }
   ],
   "source": [
    "deeplab_pt_gpu_hybrid = gcv.model_zoo.get_model('deeplab_resnet101_coco', pretrained=True, ctx=mx.gpu())\n",
    "deeplab_pt_gpu_hybrid.hybridize()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for data, _ in tqdm(ade20k_val_loader_gpu_cpu_bs16):\n",
    "    deeplab_pt_gpu_hybrid.predict(data.as_in_context(mx.gpu()))\n",
    "    \n",
    "mx.nd.waitall()\n",
    "print(\"Time (s):\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17c3fd84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b6c55a6ef944d998c5ab9ffc52b93a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 11.254050970077515\n"
     ]
    }
   ],
   "source": [
    "deeplab_pt_gpu_hybrid_static_alloc = gcv.model_zoo.get_model('deeplab_resnet101_coco', pretrained=True, ctx=mx.gpu())\n",
    "deeplab_pt_gpu_hybrid_static_alloc.hybridize(static_alloc=True)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for data, _ in tqdm(ade20k_val_loader_gpu_cpu_bs16):\n",
    "    deeplab_pt_gpu_hybrid_static_alloc.predict(data.as_in_context(mx.gpu()))\n",
    "    \n",
    "mx.nd.waitall()\n",
    "print(\"Time (s):\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "657cca3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "767084d6ce0641e291b224d4e0b88830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 11.182417869567871\n"
     ]
    }
   ],
   "source": [
    "deeplab_pt_gpu_hybrid_static_alloc_shape = gcv.model_zoo.get_model('deeplab_resnet101_coco', pretrained=True, ctx=mx.gpu())\n",
    "deeplab_pt_gpu_hybrid_static_alloc_shape.hybridize(static_alloc=True, static_shape=True)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for data, _ in tqdm(ade20k_val_loader_gpu_cpu_bs16):\n",
    "    deeplab_pt_gpu_hybrid_static_alloc_shape.predict(data.as_in_context(mx.gpu()))\n",
    "    \n",
    "mx.nd.waitall()\n",
    "print(\"Time (s):\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd98f5d",
   "metadata": {},
   "source": [
    "I can talk about symbolic and imperative programming\n",
    "HybridSequential / HybridBlock / Hybrid_forward\n",
    "\n",
    "https://github.com/awslabs/dynamic-training-with-apache-mxnet-on-aws/blob/master/docs/tutorials/gluon/custom_layer.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443425a9",
   "metadata": {},
   "source": [
    "## Automatic Mixed Precision (AMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "312679db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.contrib import amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8573e7d-a975-4b97-ad7e-bff466168760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single sample for forward pass (AMP requirement)\n",
    "original_shape = ade20k_val_gpu_cpu[0][0].shape[1:]\n",
    "single_sample_cpu = ade20k_val_gpu_cpu[0][0].reshape((1, 3) + original_shape)\n",
    "single_sample_gpu = ade20k_val_gpu_cpu[0][0].reshape((1, 3) + original_shape).as_in_context(mx.gpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2adfc70-13bd-425b-868e-20f99b70215a",
   "metadata": {},
   "source": [
    "### AMP CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "79f96ea1-bf08-4206-8902-5c25aa4a534d",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplab_pt_cpu_hybrid = gcv.model_zoo.get_model('deeplab_resnet101_coco', pretrained=True, ctx=mx.cpu())\n",
    "deeplab_pt_cpu_hybrid.hybridize(backend=\"MKLDNN\", static_alloc=True, static_shape=True)\n",
    "deeplab_pt_cpu_hybrid(single_sample_cpu);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ec7799f4-0ed1-4333-a63d-eb16e8f81f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplab_pt_cpu_hybrid_amp = amp.convert_hybrid_block(deeplab_pt_cpu_hybrid, ctx=mx.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0dae226e-ad10-447a-9c27-94e16646889b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "565c838eeaaa41ec895f221af6a5b6a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 55.70594525337219\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for data, _ in tqdm(ade20k_val_loader_gpu_cpu):\n",
    "    deeplab_pt_cpu_hybrid_amp(data)\n",
    "    \n",
    "mx.nd.waitall()\n",
    "print(\"Time (s):\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2536cb-c4f9-4e45-8772-91eb5f2b5a2b",
   "metadata": {},
   "source": [
    "### AMP GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "62cf8127",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplab_pt_gpu_hybrid = gcv.model_zoo.get_model('deeplab_resnet101_coco', pretrained=True, ctx=mx.gpu())\n",
    "deeplab_pt_gpu_hybrid.hybridize(static_alloc=True, static_shape=True)\n",
    "deeplab_pt_gpu_hybrid(single_sample_gpu);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "10f498c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplab_pt_gpu_hybrid_amp = amp.convert_hybrid_block(deeplab_pt_gpu_hybrid, ctx=mx.gpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7c7f8f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0350d878f3f443cd9052b98e07298144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 3.168325662612915\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for data, _ in tqdm(ade20k_val_loader_gpu_cpu_bs16):\n",
    "    deeplab_pt_gpu_hybrid_amp(data.as_in_context(mx.gpu()))\n",
    "    \n",
    "mx.nd.waitall()\n",
    "print(\"Time (s):\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4e8116",
   "metadata": {},
   "source": [
    "## Quantisation (INT8) - CPU Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00bf3e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.contrib import quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579cd70e",
   "metadata": {},
   "source": [
    "### Calibration Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccb2480b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "371c06dc6b6f4f6bb5d3c9312cc50a2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dataset Loading & Transforming\n",
    "# Limit to 10 samples (last ones)\n",
    "max_samples = 10\n",
    "samples = range(0, max_samples)\n",
    "\n",
    "ade20k_cal_cpu_pre = mx.gluon.data.SimpleDataset([(ade20k_val_cpu[-i][0], ade20k_val_cpu[-i][1]) for i in tqdm(samples)])\n",
    "ade20k_cal_gpu     = ade20k_cal_cpu_pre.transform_first(input_transform_fn_gpu, lazy=False)\n",
    "ade20k_cal_gpu_cpu = ade20k_cal_gpu.transform_first(to_cpu_fn, lazy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "543fca2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader for Calibration\n",
    "# For CPU, Pre-processed in GPU, copied back to CPU memory space)\n",
    "num_workers = 0\n",
    "batch_size = 4\n",
    "\n",
    "# DataLoader for calibration data processed in GPU, loaded in CPU\n",
    "ade20k_cal_loader_gpu_cpu = mx.gluon.data.DataLoader(\n",
    "    ade20k_cal_gpu_cpu,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    last_batch=\"discard\")\n",
    "\n",
    "# For GPU, All done in GPU\n",
    "num_workers = 0\n",
    "batch_size = 16\n",
    "\n",
    "# DataLoader for calibration data processed in GPU, loaded in CPU\n",
    "ade20k_cal_loader_gpu_bs16 = mx.gluon.data.DataLoader(\n",
    "    ade20k_cal_gpu,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    last_batch=\"discard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0657b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplab_pt_cpu = gcv.model_zoo.get_model('deeplab_resnet101_coco', pretrained=True, ctx=mx.cpu())\n",
    "deeplab_pt_cpu(single_sample_cpu);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff520b06-f312-4396-97be-2e4bea80ffe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log Quantization info\n",
    "import logging\n",
    "logging.basicConfig()\n",
    "logger = logging.getLogger('logger')\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f9a3673",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:logger:Export HybridBlock\n",
      "INFO:logger:These layers have been excluded []\n",
      "INFO:logger:Quantizing graph\n",
      "INFO:logger:Create a layer output collector for entropy calibration.\n",
      "INFO:logger:Collector created, please use set_monitor_callback to collect calibration information.\n",
      "INFO:logger:Quantizing parameters\n",
      "[10:37:50] /work/mxnet/src/executor/graph_executor.cc:1991: Subgraph backend MKLDNN is activated.\n",
      "INFO:logger:Collected statistics from 2 batches with batch_size=4\n",
      "INFO:logger:Collected layer output values from FP32 model using 8 examples\n",
      "INFO:logger:Calculating optimal thresholds for quantization\n",
      "INFO:logger:Calculating optimal thresholds for quantization using KL divergence with num_quantized_bins=255\n",
      "INFO:logger:Quantizing parameters\n"
     ]
    }
   ],
   "source": [
    "deeplab_pt_cpu_q_hybrid = quantization.quantize_net_v2(\n",
    "    deeplab_pt_cpu,\n",
    "    quantized_dtype='auto',\n",
    "    exclude_layers=None,\n",
    "    exclude_layers_match=None,\n",
    "    calib_data=ade20k_cal_loader_gpu_cpu,\n",
    "    calib_mode='entropy',\n",
    "    logger=logger,\n",
    "    ctx=mx.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfb66b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplab_pt_cpu_q_hybrid.hybridize(backend=\"MKLDNN\", static_alloc=True, static_shape=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "307e35b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f96eba87dda4b3dae67b89624842c27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 36.085768938064575\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for data, _ in tqdm(ade20k_val_loader_gpu_cpu):\n",
    "    deeplab_pt_cpu_q_hybrid(data)\n",
    "    \n",
    "mx.nd.waitall()\n",
    "print(\"Time (s):\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5662d90d-8b41-4bf5-a876-b4cf46c938f6",
   "metadata": {},
   "source": [
    "## MXNet Profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84c1c5d-073f-4e65-8322-f90915e3b2d8",
   "metadata": {},
   "source": [
    "### CPU Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97364444-9333-4de4-9bca-c02ffc469454",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplab_pt_cpu = gcv.model_zoo.get_model('deeplab_resnet101_coco', pretrained=True, ctx=mx.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98e99ced-a1ec-4c62-9660-670303dac96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mx.profiler.set_config(\n",
    "    profile_all=True,\n",
    "    aggregate_stats=True,\n",
    "    continuous_dump=True,\n",
    "    filename='profile_output_cpu.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "980fb51f-2e26-4023-8441-b38332d8d45b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mx.profiler.set_state('run')\n",
    "\n",
    "deeplab_pt_cpu(single_sample_cpu)\n",
    "\n",
    "# Wait until all operations have completed\n",
    "mx.nd.waitall()\n",
    "# Stop recording\n",
    "mx.profiler.set_state('stop')\n",
    "# Log results\n",
    "mx.profiler.dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ce6cca8-0c9d-4712-875f-3ae996b0cd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplab_pt_cpu_hybrid = gcv.model_zoo.get_model('deeplab_resnet101_coco', pretrained=True, ctx=mx.cpu())\n",
    "deeplab_pt_cpu_hybrid.hybridize(backend=\"MKLDNN\", static_alloc=True, static_shape=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "057ae446-26a6-457f-a2f6-c35cbd407db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mx.profiler.set_config(\n",
    "    profile_all=True,\n",
    "    aggregate_stats=True,\n",
    "    continuous_dump=True,\n",
    "    filename='profile_output_cpu_hybrid.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "346d1d01-cee9-48c4-b649-b006c5bc54ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mx.profiler.set_state('run')\n",
    "\n",
    "deeplab_pt_cpu_hybrid(single_sample_cpu)\n",
    "\n",
    "# Wait until all operations have completed\n",
    "mx.nd.waitall()\n",
    "# Stop recording\n",
    "mx.profiler.set_state('stop')\n",
    "# Log results\n",
    "mx.profiler.dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61094651-009c-450a-b25c-d1bb6824a219",
   "metadata": {},
   "source": [
    "### GPU Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61e45148-96df-4670-a29e-1d27741273ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplab_pt_gpu = gcv.model_zoo.get_model('deeplab_resnet101_coco', pretrained=True, ctx=mx.gpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "685cabaa-1c1f-4b02-a367-2f5fda001509",
   "metadata": {},
   "outputs": [],
   "source": [
    "mx.profiler.set_config(\n",
    "    profile_all=True,\n",
    "    aggregate_stats=True,\n",
    "    continuous_dump=True,\n",
    "    filename='profile_output_gpu.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10e96e77-2d04-460a-8526-14781a68c3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mx.profiler.set_state('run')\n",
    "\n",
    "deeplab_pt_gpu(single_sample_gpu)\n",
    "\n",
    "# Wait until all operations have completed\n",
    "mx.nd.waitall()\n",
    "# Stop recording\n",
    "mx.profiler.set_state('stop')\n",
    "# Log results\n",
    "mx.profiler.dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "888db309-b13d-4e82-ab6f-cf8a38037335",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplab_pt_gpu_hybrid = gcv.model_zoo.get_model('deeplab_resnet101_coco', pretrained=True, ctx=mx.gpu())\n",
    "deeplab_pt_gpu_hybrid.hybridize(static_alloc=True, static_shape=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96099e3d-5575-4758-a9f0-5d5ee5fa1a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mx.profiler.set_config(\n",
    "    profile_all=True,\n",
    "    aggregate_stats=True,\n",
    "    continuous_dump=True,\n",
    "    filename='profile_output_gpu_hybrid.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "025dccd2-087e-4c9c-99f3-5238c6be8cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11:00:02] /work/mxnet/src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:96: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\n"
     ]
    }
   ],
   "source": [
    "mx.profiler.set_state('run')\n",
    "\n",
    "deeplab_pt_gpu_hybrid(single_sample_gpu)\n",
    "\n",
    "# Wait until all operations have completed\n",
    "mx.nd.waitall()\n",
    "# Stop recording\n",
    "mx.profiler.set_state('stop')\n",
    "# Log results\n",
    "mx.profiler.dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a26c87",
   "metadata": {},
   "source": [
    "## ONNX Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de64bafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONNX library must be installed for this\n",
    "# !python3 -m pip install onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed2cc578",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11:03:27] /work/mxnet/src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:96: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\n"
     ]
    }
   ],
   "source": [
    "deeplab_pt_gpu_hybrid = gcv.model_zoo.get_model('deeplab_resnet101_coco', pretrained=True, ctx=mx.gpu())\n",
    "deeplab_pt_gpu_hybrid.hybridize(static_alloc=True, static_shape=True)\n",
    "deeplab_pt_gpu_hybrid(single_sample_gpu)\n",
    "\n",
    "# Need to be exported externally for the symbols to be loaded\n",
    "deeplab_pt_gpu_hybrid_filename = \"deeplab_resnet101_coco_pt_gpu_hybrid\"\n",
    "deeplab_pt_gpu_hybrid.export(deeplab_pt_gpu_hybrid_filename)\n",
    "\n",
    "# Files exported\n",
    "sym_filename = deeplab_pt_gpu_hybrid_filename + \"-symbol.json\"\n",
    "params_filename = deeplab_pt_gpu_hybrid_filename + \"-0000.params\"\n",
    "\n",
    "# Verify generated files\n",
    "assert os.path.exists(sym_filename)\n",
    "assert os.path.exists(params_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1143996a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deeplab_resnet101_coco_pt_gpu_hybrid.onnx'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_file_name = \"deeplab_resnet101_coco_pt_gpu_hybrid.onnx\"\n",
    "in_shapes = [single_sample_gpu.shape]\n",
    "in_types = [mx.np.float32]\n",
    "\n",
    "onnx_model_path = mx.onnx.export_model(\n",
    "    sym_filename,\n",
    "    params_filename,\n",
    "    in_shapes,\n",
    "    in_types,\n",
    "    onnx_file_name)\n",
    "\n",
    "onnx_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09e0dcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Verification\n",
    "import onnx\n",
    "\n",
    "# Load the ONNX model\n",
    "onnx_model = onnx.load_model(onnx_model_path)\n",
    "\n",
    "# Check the ONNX graph\n",
    "onnx.checker.check_graph(onnx_model.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1d167c",
   "metadata": {},
   "source": [
    "## TensorRT Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e22b19c8-e788-4a77-9fce-5cc2a3596311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b86eeaf6-73b6-4d2a-bc34-010d728a81c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trt_file_name = \"deeplab_resnet101_coco_pt_gpu_hybrid.trt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "35f63b69-633c-40b1-8554-f9e51f29c032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/21/2023-11:12:58] [TRT] [I] The logger passed into createInferBuilder differs from one already provided for an existing builder, runtime, or refitter. Uses of the global logger, returned by nvinfer1::getLogger(), will return the existing value.\n",
      "\n",
      "[10/21/2023-11:12:58] [TRT] [I] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 6398, GPU 3186 (MiB)\n",
      "[10/21/2023-11:12:58] [TRT] [W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage. See `CUDA_MODULE_LOADING` in https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#env-vars\n"
     ]
    }
   ],
   "source": [
    "TRT_LOGGER = trt.Logger(trt.Logger.INFO)\n",
    "builder = trt.Builder(TRT_LOGGER)\n",
    "config = builder.create_builder_config()\n",
    "\n",
    "explicit_batch = 1 << (int) (trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
    "deeplab_pt_gpu_hybrid_trt = builder.create_network(explicit_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9939cb2d-4712-4021-a7fd-eeae6ebed5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25908/465619819.py:4: DeprecationWarning: Use build_serialized_network instead.\n",
      "  deeplab_pt_gpu_hybrid_engine = builder.build_engine(deeplab_pt_gpu_hybrid_trt, config=config)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/21/2023-11:13:01] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 6868, GPU 3194 (MiB)\n",
      "[10/21/2023-11:13:01] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 6868, GPU 3202 (MiB)\n",
      "[10/21/2023-11:13:01] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[10/21/2023-11:13:39] [TRT] [I] Total Activation Memory: 16775153152\n",
      "[10/21/2023-11:13:39] [TRT] [I] Detected 1 inputs and 2 output network tensors.\n",
      "[10/21/2023-11:13:39] [TRT] [I] Total Host Persistent Memory: 338096\n",
      "[10/21/2023-11:13:39] [TRT] [I] Total Device Persistent Memory: 2997760\n",
      "[10/21/2023-11:13:39] [TRT] [I] Total Scratch Memory: 134217728\n",
      "[10/21/2023-11:13:39] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 490 MiB, GPU 10873 MiB\n",
      "[10/21/2023-11:13:39] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 124 steps to complete.\n",
      "[10/21/2023-11:13:39] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 2.47506ms to assign 6 blocks to 124 nodes requiring 186130432 bytes.\n",
      "[10/21/2023-11:13:39] [TRT] [I] Total Activation Memory: 186130432\n",
      "[10/21/2023-11:13:39] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 6869, GPU 3456 (MiB)\n",
      "[10/21/2023-11:13:39] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +233, GPU +249, now: CPU 466, GPU 497 (MiB)\n"
     ]
    }
   ],
   "source": [
    "with open(onnx_file_name, 'rb') as model:\n",
    "    with trt.OnnxParser(deeplab_pt_gpu_hybrid_trt, TRT_LOGGER) as parser:\n",
    "        assert parser.parse(model.read()) == True\n",
    "    deeplab_pt_gpu_hybrid_engine = builder.build_engine(deeplab_pt_gpu_hybrid_trt, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3a83db1c-8923-49a4-be7e-99d9b83d2977",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(trt_file_name, 'wb') as f:\n",
    "    f.write(bytearray(deeplab_pt_gpu_hybrid_engine.serialize()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
