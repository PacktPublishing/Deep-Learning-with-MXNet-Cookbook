{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbbe216b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/andreto/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/andreto/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/andreto/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "import gluonnlp as nlp\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import sacremoses\n",
    "import time\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "\n",
    "# Local Libraries\n",
    "import nmt\n",
    "import dataprocessor\n",
    "import utils\n",
    "import nmt.gnmt_hparams\n",
    "\n",
    "# Seeds for reproducibility\n",
    "np.random.seed(100)\n",
    "random.seed(100)\n",
    "mx.random.seed(10000)\n",
    "\n",
    "# CPU setup\n",
    "# ctx = mx.cpu()\n",
    "# Single GPU setup\n",
    "ctx = mx.gpu(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bac926f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andreto/.local/lib/python3.7/site-packages/gluonnlp/vocab/vocab.py:591: UserWarning: Detected a corrupted index in the deserialize vocabulary. For versions before GluonNLP v0.7 the index is corrupted by specifying the same token for different special purposes, for example eos_token == padding_token. Deserializing the vocabulary nevertheless.\n",
      "  'Detected a corrupted index in the deserialize vocabulary. '\n"
     ]
    }
   ],
   "source": [
    "# IWSLT2015 Dataset (Train, Validation and Test)\n",
    "\n",
    "# Dataset Parameters\n",
    "src_lang, tgt_lang = \"vi\", \"en\"\n",
    "src_max_len, tgt_max_len = 50, 50\n",
    "\n",
    "iwslt_train_text = nlp.data.IWSLT2015(\"train\",\n",
    "                                      src_lang=src_lang,\n",
    "                                      tgt_lang=tgt_lang)\n",
    "\n",
    "iwslt_val_text   = nlp.data.IWSLT2015(\"val\",\n",
    "                                      src_lang=src_lang,\n",
    "                                      tgt_lang=tgt_lang)\n",
    "\n",
    "iwslt_test_text  = nlp.data.IWSLT2015(\"test\",\n",
    "                                      src_lang=src_lang,\n",
    "                                      tgt_lang=tgt_lang)\n",
    "\n",
    "\n",
    "iwslt_src_vocab = iwslt_train_text.src_vocab\n",
    "iwslt_tgt_vocab = iwslt_train_text.tgt_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a3383d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train set: 133166\n",
      "Length of val set  : 1553\n",
      "Length of test set : 1268\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of train set:\", len(iwslt_train_text))\n",
    "print(\"Length of val set  :\", len(iwslt_val_text))\n",
    "print(\"Length of test set :\", len(iwslt_test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "075d11ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset processing: clipping, tokenizing, indexing and adding of EOS (src/tgt) / BOS (tgt)\n",
    "iwslt_train_processed = iwslt_train_text.transform(\n",
    "    dataprocessor.TrainValDataTransform(\n",
    "        iwslt_src_vocab,\n",
    "        iwslt_tgt_vocab,\n",
    "        src_max_len,\n",
    "        tgt_max_len),\n",
    "    lazy=False)\n",
    "\n",
    "iwslt_val_processed   = iwslt_val_text.transform(\n",
    "    dataprocessor.TrainValDataTransform(\n",
    "        iwslt_src_vocab,\n",
    "        iwslt_tgt_vocab,\n",
    "        src_max_len,\n",
    "        tgt_max_len),\n",
    "    lazy=False)\n",
    "\n",
    "iwslt_test_processed  = iwslt_test_text.transform(\n",
    "    dataprocessor.TrainValDataTransform(\n",
    "        iwslt_src_vocab,\n",
    "        iwslt_tgt_vocab,\n",
    "        src_max_len,\n",
    "        tgt_max_len),\n",
    "    lazy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3884e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Sequences (Val, Test)\n",
    "fetch_tgt_sentence = lambda src, tgt: tgt.split()\n",
    "val_tgt_sentences = list(iwslt_val_text.transform(fetch_tgt_sentence))\n",
    "test_tgt_sentences = list(iwslt_test_text.transform(fetch_tgt_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c26bf695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Gluon Datasets (not for training, as training data will be sharded)\n",
    "iwslt_train_transformed = iwslt_train_processed.transform(\n",
    "    lambda src, tgt: (src, tgt, len(src), len(tgt)),\n",
    "    lazy=False)\n",
    "\n",
    "iwslt_val_dataset = mx.gluon.data.SimpleDataset(\n",
    "    [(ele[0], ele[1], len(ele[0]), len(ele[1]),i) for i, ele in enumerate(iwslt_val_processed)])\n",
    "\n",
    "iwslt_test_dataset = mx.gluon.data.SimpleDataset(\n",
    "    [(ele[0], ele[1], len(ele[0]), len(ele[1]), i) for i, ele in enumerate(iwslt_test_processed)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0278d19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for Dataloaders and Training\n",
    "hparams = nmt.gnmt_hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32d3a2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andreto/.local/lib/python3.7/site-packages/gluonnlp/data/batchify/batchify.py:235: UserWarning: Padding value is not given and will be set automatically to 0 in data.batchify.Pad(). Please check whether this is intended (e.g. value of padding index in the vocabulary).\n",
      "  'Padding value is not given and will be set automatically to 0 '\n"
     ]
    }
   ],
   "source": [
    "# Create Gluon Samplers and DataLoaders\n",
    "\n",
    "# Helper function for lengths\n",
    "def get_data_lengths(dataset):\n",
    "    get_lengths = lambda *args: (args[2], args[3])\n",
    "    return list(dataset.transform(get_lengths))\n",
    "\n",
    "# Bucket scheme\n",
    "bucket_scheme = nlp.data.ExpWidthBucket(bucket_len_step=1.2)\n",
    "\n",
    "iwslt_train_lengths = get_data_lengths(iwslt_train_transformed)\n",
    "iwslt_val_lengths = get_data_lengths(iwslt_val_dataset)\n",
    "iwslt_test_lengths = get_data_lengths(iwslt_test_dataset)\n",
    "\n",
    "train_batchify_fn = nlp.data.batchify.Tuple(\n",
    "    nlp.data.batchify.Pad(),\n",
    "    nlp.data.batchify.Pad(),\n",
    "    nlp.data.batchify.Stack(dtype='float32'),\n",
    "    nlp.data.batchify.Stack(dtype='float32'))\n",
    "\n",
    "test_batchify_fn = nlp.data.batchify.Tuple(\n",
    "    nlp.data.batchify.Pad(),\n",
    "    nlp.data.batchify.Pad(),\n",
    "    nlp.data.batchify.Stack(dtype='float32'),\n",
    "    nlp.data.batchify.Stack(dtype='float32'),\n",
    "    nlp.data.batchify.Stack())\n",
    "\n",
    "target_val_lengths = list(map(lambda x: x[-1], iwslt_val_lengths))\n",
    "target_test_lengths = list(map(lambda x: x[-1], iwslt_test_lengths))\n",
    "\n",
    "train_batch_sampler = nlp.data.FixedBucketSampler(\n",
    "    lengths=iwslt_train_lengths,\n",
    "    batch_size=hparams.batch_size,\n",
    "    num_buckets=hparams.num_buckets,\n",
    "    ratio=0,\n",
    "    shuffle=True,\n",
    "    use_average_length=False,\n",
    "    num_shards=0,\n",
    "    bucket_scheme=bucket_scheme)\n",
    "    \n",
    "train_data_loader = nlp.data.ShardedDataLoader(\n",
    "    iwslt_train_transformed,\n",
    "    batch_sampler=train_batch_sampler,\n",
    "    batchify_fn=train_batchify_fn,\n",
    "    num_workers=8)\n",
    "\n",
    "val_batch_sampler = nlp.data.FixedBucketSampler(\n",
    "    lengths=iwslt_val_lengths,\n",
    "    batch_size=hparams.test_batch_size,\n",
    "    num_buckets=hparams.num_buckets,\n",
    "    ratio=0,\n",
    "    shuffle=False,\n",
    "    use_average_length=False,\n",
    "    bucket_scheme=bucket_scheme)\n",
    "\n",
    "val_data_loader = mx.gluon.data.DataLoader(\n",
    "    iwslt_val_dataset,\n",
    "    batch_sampler=val_batch_sampler,\n",
    "    batchify_fn=test_batchify_fn,\n",
    "    num_workers=8)\n",
    "\n",
    "test_batch_sampler = nlp.data.FixedBucketSampler(\n",
    "    lengths=iwslt_test_lengths,\n",
    "    batch_size=hparams.test_batch_size,\n",
    "    num_buckets=hparams.num_buckets,\n",
    "    ratio=0,\n",
    "    shuffle=False,\n",
    "    use_average_length=False,\n",
    "    bucket_scheme=bucket_scheme)\n",
    "\n",
    "test_data_loader = mx.gluon.data.DataLoader(\n",
    "    iwslt_test_dataset,\n",
    "    batch_sampler=test_batch_sampler,\n",
    "    batchify_fn=test_batchify_fn,\n",
    "    num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6433aa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GNMT Model\n",
    "gnmt_encoder, gnmt_decoder, gnmt_one_step_ahead_decoder = nmt.gnmt.get_gnmt_encoder_decoder(\n",
    "    hidden_size=hparams.num_hidden,\n",
    "    dropout=hparams.dropout,\n",
    "    num_layers=hparams.num_layers,\n",
    "    num_bi_layers=hparams.num_bi_layers)\n",
    "\n",
    "gnmt_model = nlp.model.translation.NMTModel(\n",
    "    src_vocab=iwslt_src_vocab,\n",
    "    tgt_vocab=iwslt_tgt_vocab,\n",
    "    encoder=gnmt_encoder,\n",
    "    decoder=gnmt_decoder,\n",
    "    one_step_ahead_decoder=gnmt_one_step_ahead_decoder,\n",
    "    embed_size=hparams.num_hidden,\n",
    "    prefix='gnmt_')\n",
    "\n",
    "gnmt_model.initialize(init=mx.init.Uniform(0.1), ctx=ctx)\n",
    "static_alloc = True\n",
    "gnmt_model.hybridize(static_alloc=static_alloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d3ae74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translator (using model defined above)\n",
    "gnmt_translator = nmt.translation.BeamSearchTranslator(\n",
    "    model=gnmt_model,\n",
    "    beam_size=hparams.beam_size,\n",
    "    scorer=nlp.model.BeamSearchScorer(\n",
    "        alpha=hparams.lp_alpha,\n",
    "        K=hparams.lp_k),\n",
    "    max_length=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "076325eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "loss_function = nlp.loss.MaskedSoftmaxCELoss()\n",
    "loss_function.hybridize(static_alloc=static_alloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87e41efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function (used also on training loop for validation)\n",
    "def evaluate(\n",
    "    data_loader,\n",
    "    model,\n",
    "    translator,\n",
    "    loss_function,\n",
    "    tgt_vocab):\n",
    "\n",
    "    translation_out = []\n",
    "    all_inst_ids = []\n",
    "    avg_loss_denom = 0\n",
    "    avg_loss = 0.0\n",
    "    \n",
    "    for _, (src_seq, tgt_seq, src_valid_length, tgt_valid_length, inst_ids) in enumerate(tqdm(data_loader)):\n",
    "        \n",
    "        src_seq = src_seq.as_in_context(ctx)\n",
    "        tgt_seq = tgt_seq.as_in_context(ctx)\n",
    "        src_valid_length = src_valid_length.as_in_context(ctx)\n",
    "        tgt_valid_length = tgt_valid_length.as_in_context(ctx)\n",
    "        \n",
    "        # Calculating Loss\n",
    "        out, _ = model(\n",
    "            src_seq,\n",
    "            tgt_seq[:, :-1],\n",
    "            src_valid_length,\n",
    "            tgt_valid_length - 1)\n",
    "\n",
    "        loss = loss_function(\n",
    "            out,\n",
    "            tgt_seq[:, 1:],\n",
    "            tgt_valid_length - 1).sum().asscalar()\n",
    "        \n",
    "        all_inst_ids.extend(inst_ids.asnumpy().astype(np.int32).tolist())\n",
    "        avg_loss += loss * (tgt_seq.shape[1] - 1)\n",
    "        avg_loss_denom += (tgt_valid_length - 1).sum().asscalar()\n",
    "        \n",
    "        # Translate\n",
    "        samples, _, sample_valid_length = translator.translate(\n",
    "            src_seq=src_seq,\n",
    "            src_valid_length=src_valid_length)\n",
    "        \n",
    "        max_score_sample = samples[:, 0, :].asnumpy()\n",
    "        sample_valid_length = sample_valid_length[:, 0].asnumpy()\n",
    "        \n",
    "        for i in range(max_score_sample.shape[0]):\n",
    "            translation_out.append(\n",
    "                [tgt_vocab.idx_to_token[ele] for ele in\n",
    "                 max_score_sample[i][1:(sample_valid_length[i] - 1)]])\n",
    "    \n",
    "    avg_loss = avg_loss / avg_loss_denom\n",
    "    real_translation_out = [None for _ in range(len(all_inst_ids))]\n",
    "    \n",
    "    for ind, sentence in zip(all_inst_ids, translation_out):\n",
    "        real_translation_out[ind] = sentence\n",
    "    \n",
    "    return avg_loss, real_translation_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0707abf5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e072061de0fb40f397de8301ec67f8fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcb04b5905794945b0b5f5e571ed314a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1043 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extension horovod.torch has not been built: /home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/site-packages/horovod/torch/mpi_lib/_mpi_lib.cpython-37m-x86_64-linux-gnu.so not found\n",
      "If this is not expected, reinstall Horovod with HOROVOD_WITH_PYTORCH=1 to debug the build error.\n",
      "Warning! MPI libs are missing, but python applications are still avaiable.\n",
      "[2022-06-18 14:54:29.964 ip-172-31-28-47:18761 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2022-06-18 14:54:29.994 ip-172-31-28-47:18761 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "[Epoch 0 Batch 100/1043] loss=6.3935, ppl=597.9448, gnorm=0.8397, throughput=33.09K wps, wc=606.57K\n",
      "[Epoch 0 Batch 200/1043] loss=5.7033, ppl=299.8477, gnorm=0.4034, throughput=37.61K wps, wc=584.18K\n",
      "[Epoch 0 Batch 300/1043] loss=5.2848, ppl=197.3192, gnorm=0.3523, throughput=39.15K wps, wc=592.78K\n",
      "[Epoch 0 Batch 400/1043] loss=4.9782, ppl=145.2078, gnorm=0.3300, throughput=38.43K wps, wc=571.26K\n",
      "[Epoch 0 Batch 500/1043] loss=4.8170, ppl=123.5999, gnorm=0.3215, throughput=38.27K wps, wc=554.48K\n",
      "[Epoch 0 Batch 600/1043] loss=4.6780, ppl=107.5592, gnorm=0.2977, throughput=38.14K wps, wc=546.26K\n",
      "[Epoch 0 Batch 700/1043] loss=4.5906, ppl=98.5512, gnorm=0.3021, throughput=37.39K wps, wc=566.96K\n",
      "[Epoch 0 Batch 800/1043] loss=4.4987, ppl=89.8979, gnorm=0.3047, throughput=37.80K wps, wc=551.40K\n",
      "[Epoch 0 Batch 900/1043] loss=4.4447, ppl=85.1737, gnorm=0.3021, throughput=38.54K wps, wc=577.61K\n",
      "[Epoch 0 Batch 1000/1043] loss=4.3756, ppl=79.4855, gnorm=0.2924, throughput=38.11K wps, wc=588.16K\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68f252b28a37458aba4bced9bb5e199f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] valid Loss=4.0851, valid ppl=59.4506, valid bleu=3.64\n",
      "Save best parameters to gnmt_en_de_512.params\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d135aa6af5274f72b5654ec03ef3c87a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1043 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1 Batch 100/1043] loss=4.2704, ppl=71.5530, gnorm=0.3114, throughput=38.23K wps, wc=593.66K\n",
      "[Epoch 1 Batch 200/1043] loss=4.2559, ppl=70.5235, gnorm=0.3018, throughput=38.86K wps, wc=631.62K\n",
      "[Epoch 1 Batch 300/1043] loss=4.1719, ppl=64.8362, gnorm=0.2977, throughput=37.09K wps, wc=599.65K\n",
      "[Epoch 1 Batch 400/1043] loss=4.0967, ppl=60.1445, gnorm=0.3012, throughput=38.61K wps, wc=585.70K\n",
      "[Epoch 1 Batch 500/1043] loss=4.0121, ppl=55.2615, gnorm=0.3049, throughput=37.57K wps, wc=567.14K\n",
      "[Epoch 1 Batch 600/1043] loss=3.9056, ppl=49.6791, gnorm=0.3192, throughput=36.97K wps, wc=521.63K\n",
      "[Epoch 1 Batch 700/1043] loss=3.9479, ppl=51.8274, gnorm=0.3139, throughput=37.18K wps, wc=591.94K\n",
      "[Epoch 1 Batch 800/1043] loss=3.8196, ppl=45.5859, gnorm=0.3272, throughput=37.88K wps, wc=563.74K\n",
      "[Epoch 1 Batch 900/1043] loss=3.7051, ppl=40.6543, gnorm=0.3193, throughput=38.37K wps, wc=578.06K\n",
      "[Epoch 1 Batch 1000/1043] loss=3.5597, ppl=35.1533, gnorm=0.3212, throughput=36.99K wps, wc=523.53K\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab5b89e7585a4050bd874c5cf01649d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] valid Loss=3.3799, valid ppl=29.3692, valid bleu=8.90\n",
      "Save best parameters to gnmt_en_de_512.params\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4024b6f78bb4a45a5deba6b1bba15f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1043 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2 Batch 100/1043] loss=3.3892, ppl=29.6409, gnorm=0.3328, throughput=37.52K wps, wc=542.87K\n",
      "[Epoch 2 Batch 200/1043] loss=3.3729, ppl=29.1625, gnorm=0.3293, throughput=37.78K wps, wc=575.69K\n",
      "[Epoch 2 Batch 300/1043] loss=3.3198, ppl=27.6559, gnorm=0.3309, throughput=38.12K wps, wc=568.29K\n",
      "[Epoch 2 Batch 400/1043] loss=3.2766, ppl=26.4848, gnorm=0.3328, throughput=37.45K wps, wc=578.89K\n",
      "[Epoch 2 Batch 500/1043] loss=3.2317, ppl=25.3215, gnorm=0.3285, throughput=38.29K wps, wc=590.93K\n",
      "[Epoch 2 Batch 600/1043] loss=3.1842, ppl=24.1482, gnorm=0.3325, throughput=38.11K wps, wc=561.47K\n",
      "[Epoch 2 Batch 700/1043] loss=3.1901, ppl=24.2906, gnorm=0.3273, throughput=37.63K wps, wc=624.59K\n",
      "[Epoch 2 Batch 800/1043] loss=3.0813, ppl=21.7870, gnorm=0.3301, throughput=37.75K wps, wc=564.54K\n",
      "[Epoch 2 Batch 900/1043] loss=3.0838, ppl=21.8418, gnorm=0.3297, throughput=38.86K wps, wc=583.36K\n",
      "[Epoch 2 Batch 1000/1043] loss=2.9733, ppl=19.5565, gnorm=0.3351, throughput=37.58K wps, wc=528.11K\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f345b657717b4f4e942fa76e20245706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] valid Loss=2.8992, valid ppl=18.1593, valid bleu=14.70\n",
      "Save best parameters to gnmt_en_de_512.params\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8307593a2bac472cad61693c2cb68086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1043 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3 Batch 100/1043] loss=2.8944, ppl=18.0720, gnorm=0.3200, throughput=39.25K wps, wc=630.11K\n",
      "[Epoch 3 Batch 200/1043] loss=2.8035, ppl=16.5016, gnorm=0.3369, throughput=38.36K wps, wc=572.70K\n",
      "[Epoch 3 Batch 300/1043] loss=2.8324, ppl=16.9856, gnorm=0.3338, throughput=37.64K wps, wc=598.93K\n",
      "[Epoch 3 Batch 400/1043] loss=2.7246, ppl=15.2502, gnorm=0.3417, throughput=36.95K wps, wc=537.22K\n",
      "[Epoch 3 Batch 500/1043] loss=2.6959, ppl=14.8195, gnorm=0.3475, throughput=37.46K wps, wc=529.51K\n",
      "[Epoch 3 Batch 600/1043] loss=2.7686, ppl=15.9368, gnorm=0.3263, throughput=38.42K wps, wc=610.71K\n",
      "[Epoch 3 Batch 700/1043] loss=2.6648, ppl=14.3656, gnorm=0.3419, throughput=37.43K wps, wc=519.76K\n",
      "[Epoch 3 Batch 800/1043] loss=2.6457, ppl=14.0934, gnorm=0.3375, throughput=36.44K wps, wc=539.30K\n",
      "[Epoch 3 Batch 900/1043] loss=2.6764, ppl=14.5321, gnorm=0.3374, throughput=38.31K wps, wc=581.69K\n",
      "[Epoch 3 Batch 1000/1043] loss=2.7022, ppl=14.9123, gnorm=0.3443, throughput=38.54K wps, wc=569.12K\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c09c584a3f94000b1f5057640439883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] valid Loss=2.6615, valid ppl=14.3171, valid bleu=17.49\n",
      "Save best parameters to gnmt_en_de_512.params\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a40e4822074eb39a1f76f7bdfb1658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1043 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4 Batch 100/1043] loss=2.4440, ppl=11.5185, gnorm=0.3227, throughput=37.33K wps, wc=568.46K\n",
      "[Epoch 4 Batch 200/1043] loss=2.4241, ppl=11.2921, gnorm=0.3358, throughput=36.09K wps, wc=542.90K\n",
      "[Epoch 4 Batch 300/1043] loss=2.4502, ppl=11.5910, gnorm=0.3381, throughput=38.11K wps, wc=555.44K\n",
      "[Epoch 4 Batch 400/1043] loss=2.4392, ppl=11.4638, gnorm=0.3409, throughput=37.40K wps, wc=543.93K\n",
      "[Epoch 4 Batch 500/1043] loss=2.4675, ppl=11.7928, gnorm=0.3335, throughput=37.96K wps, wc=579.34K\n",
      "[Epoch 4 Batch 600/1043] loss=2.4729, ppl=11.8571, gnorm=0.3402, throughput=38.24K wps, wc=601.62K\n",
      "[Epoch 4 Batch 700/1043] loss=2.4927, ppl=12.0941, gnorm=0.3301, throughput=38.34K wps, wc=597.87K\n",
      "[Epoch 4 Batch 800/1043] loss=2.3519, ppl=10.5053, gnorm=0.3409, throughput=37.20K wps, wc=507.35K\n",
      "[Epoch 4 Batch 900/1043] loss=2.5161, ppl=12.3808, gnorm=0.3409, throughput=38.35K wps, wc=624.02K\n",
      "[Epoch 4 Batch 1000/1043] loss=2.4486, ppl=11.5719, gnorm=0.3370, throughput=37.45K wps, wc=580.31K\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6352c7cc8fb64195bd87ef5078e0984c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] valid Loss=2.5682, valid ppl=13.0430, valid bleu=19.13\n",
      "Save best parameters to gnmt_en_de_512.params\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e3559ac3a5041d9b60ce39347e39391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1043 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5 Batch 100/1043] loss=2.1533, ppl=8.6129, gnorm=0.3286, throughput=35.87K wps, wc=529.43K\n",
      "[Epoch 5 Batch 200/1043] loss=2.2927, ppl=9.9016, gnorm=0.3291, throughput=39.05K wps, wc=611.54K\n",
      "[Epoch 5 Batch 300/1043] loss=2.2506, ppl=9.4931, gnorm=0.3349, throughput=37.89K wps, wc=582.88K\n",
      "[Epoch 5 Batch 400/1043] loss=2.2460, ppl=9.4497, gnorm=0.3376, throughput=37.93K wps, wc=556.31K\n",
      "[Epoch 5 Batch 500/1043] loss=2.0782, ppl=7.9900, gnorm=0.3456, throughput=36.26K wps, wc=472.55K\n",
      "[Epoch 5 Batch 600/1043] loss=2.2766, ppl=9.7435, gnorm=0.3352, throughput=38.21K wps, wc=586.79K\n",
      "[Epoch 5 Batch 700/1043] loss=2.2373, ppl=9.3678, gnorm=0.3392, throughput=37.30K wps, wc=561.02K\n",
      "[Epoch 5 Batch 800/1043] loss=2.2311, ppl=9.3096, gnorm=0.3385, throughput=37.42K wps, wc=555.63K\n",
      "[Epoch 5 Batch 900/1043] loss=2.3012, ppl=9.9864, gnorm=0.3315, throughput=38.20K wps, wc=600.79K\n",
      "[Epoch 5 Batch 1000/1043] loss=2.3782, ppl=10.7859, gnorm=0.3268, throughput=39.36K wps, wc=659.40K\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cbeb09dcdbf42da8405a8ba3e553f31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] valid Loss=2.4984, valid ppl=12.1624, valid bleu=19.69\n",
      "Save best parameters to gnmt_en_de_512.params\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef64a1571fa341fd8f9867793cb4f46d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1043 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6 Batch 100/1043] loss=2.0759, ppl=7.9716, gnorm=0.3156, throughput=38.33K wps, wc=603.59K\n",
      "[Epoch 6 Batch 200/1043] loss=2.0281, ppl=7.5995, gnorm=0.3301, throughput=36.50K wps, wc=562.11K\n",
      "[Epoch 6 Batch 300/1043] loss=2.1225, ppl=8.3521, gnorm=0.3231, throughput=38.86K wps, wc=624.24K\n",
      "[Epoch 6 Batch 400/1043] loss=2.1139, ppl=8.2808, gnorm=0.3286, throughput=37.41K wps, wc=603.10K\n",
      "[Epoch 6 Batch 500/1043] loss=2.1032, ppl=8.1927, gnorm=0.3376, throughput=37.70K wps, wc=561.10K\n",
      "[Epoch 6 Batch 600/1043] loss=2.1102, ppl=8.2499, gnorm=0.3453, throughput=37.87K wps, wc=565.55K\n",
      "[Epoch 6 Batch 700/1043] loss=2.1177, ppl=8.3118, gnorm=0.3454, throughput=37.70K wps, wc=555.39K\n",
      "[Epoch 6 Batch 800/1043] loss=2.0839, ppl=8.0361, gnorm=0.3456, throughput=36.88K wps, wc=537.32K\n",
      "[Epoch 6 Batch 900/1043] loss=2.1490, ppl=8.5766, gnorm=0.3326, throughput=38.49K wps, wc=591.29K\n",
      "[Epoch 6 Batch 1000/1043] loss=2.1207, ppl=8.3373, gnorm=0.3446, throughput=37.12K wps, wc=554.05K\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71b3b2f73b3046059cf848f7c588a8e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] valid Loss=2.4948, valid ppl=12.1197, valid bleu=20.40\n",
      "Save best parameters to gnmt_en_de_512.params\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6600fc892a74983a9434406782a491c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1043 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7 Batch 100/1043] loss=1.9646, ppl=7.1323, gnorm=0.3205, throughput=38.05K wps, wc=587.59K\n",
      "[Epoch 7 Batch 200/1043] loss=2.0012, ppl=7.3983, gnorm=0.3232, throughput=38.46K wps, wc=622.04K\n",
      "[Epoch 7 Batch 300/1043] loss=1.8897, ppl=6.6177, gnorm=0.3344, throughput=36.51K wps, wc=540.54K\n",
      "[Epoch 7 Batch 400/1043] loss=1.8521, ppl=6.3735, gnorm=0.3431, throughput=36.79K wps, wc=502.07K\n",
      "[Epoch 7 Batch 500/1043] loss=1.9833, ppl=7.2666, gnorm=0.3385, throughput=37.71K wps, wc=583.79K\n",
      "[Epoch 7 Batch 600/1043] loss=2.0343, ppl=7.6466, gnorm=0.3329, throughput=38.40K wps, wc=609.75K\n",
      "[Epoch 7 Batch 700/1043] loss=2.0013, ppl=7.3983, gnorm=0.3395, throughput=38.60K wps, wc=577.30K\n",
      "[Epoch 7 Batch 800/1043] loss=1.8983, ppl=6.6745, gnorm=0.3528, throughput=37.18K wps, wc=505.00K\n",
      "[Epoch 7 Batch 900/1043] loss=2.0041, ppl=7.4196, gnorm=0.3367, throughput=37.96K wps, wc=590.09K\n",
      "[Epoch 7 Batch 1000/1043] loss=2.0490, ppl=7.7599, gnorm=0.3333, throughput=38.07K wps, wc=599.85K\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88d3b2acd01a4be88b04aff470bfcd02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] valid Loss=2.4834, valid ppl=11.9825, valid bleu=20.16\n",
      "Learning rate change to 0.0005\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0f800b4731e435eab626b2ecda39982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1043 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8 Batch 100/1043] loss=1.7350, ppl=5.6687, gnorm=0.3158, throughput=36.66K wps, wc=556.55K\n",
      "[Epoch 8 Batch 200/1043] loss=1.8212, ppl=6.1793, gnorm=0.3118, throughput=38.49K wps, wc=601.04K\n",
      "[Epoch 8 Batch 300/1043] loss=1.8334, ppl=6.2550, gnorm=0.3128, throughput=38.13K wps, wc=614.51K\n",
      "[Epoch 8 Batch 400/1043] loss=1.7186, ppl=5.5769, gnorm=0.3232, throughput=36.81K wps, wc=539.14K\n",
      "[Epoch 8 Batch 500/1043] loss=1.7637, ppl=5.8342, gnorm=0.3206, throughput=38.15K wps, wc=561.68K\n",
      "[Epoch 8 Batch 600/1043] loss=1.7742, ppl=5.8959, gnorm=0.3243, throughput=37.77K wps, wc=567.04K\n",
      "[Epoch 8 Batch 700/1043] loss=1.8346, ppl=6.2629, gnorm=0.3195, throughput=38.46K wps, wc=600.47K\n",
      "[Epoch 8 Batch 800/1043] loss=1.8354, ppl=6.2676, gnorm=0.3190, throughput=38.44K wps, wc=610.25K\n",
      "[Epoch 8 Batch 900/1043] loss=1.7542, ppl=5.7787, gnorm=0.3254, throughput=37.69K wps, wc=562.08K\n",
      "[Epoch 8 Batch 1000/1043] loss=1.7209, ppl=5.5896, gnorm=0.3315, throughput=37.05K wps, wc=530.23K\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1275685d90aa41d99cc8504ab213615e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] valid Loss=2.4890, valid ppl=12.0489, valid bleu=20.65\n",
      "Save best parameters to gnmt_en_de_512.params\n",
      "Learning rate change to 0.00025\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52e442e9d57243619347f20cb8d832e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1043 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9 Batch 100/1043] loss=1.6790, ppl=5.3603, gnorm=0.3064, throughput=38.15K wps, wc=576.48K\n",
      "[Epoch 9 Batch 200/1043] loss=1.6123, ppl=5.0142, gnorm=0.3105, throughput=36.89K wps, wc=550.86K\n",
      "[Epoch 9 Batch 300/1043] loss=1.7651, ppl=5.8420, gnorm=0.3097, throughput=38.99K wps, wc=633.26K\n",
      "[Epoch 9 Batch 400/1043] loss=1.7021, ppl=5.4855, gnorm=0.3172, throughput=37.57K wps, wc=579.86K\n",
      "[Epoch 9 Batch 500/1043] loss=1.6041, ppl=4.9733, gnorm=0.3162, throughput=38.19K wps, wc=543.97K\n",
      "[Epoch 9 Batch 600/1043] loss=1.6346, ppl=5.1275, gnorm=0.3148, throughput=38.20K wps, wc=547.23K\n",
      "[Epoch 9 Batch 700/1043] loss=1.6347, ppl=5.1280, gnorm=0.3203, throughput=37.89K wps, wc=580.76K\n",
      "[Epoch 9 Batch 800/1043] loss=1.5692, ppl=4.8029, gnorm=0.3183, throughput=36.71K wps, wc=533.16K\n",
      "[Epoch 9 Batch 900/1043] loss=1.6586, ppl=5.2520, gnorm=0.3158, throughput=37.72K wps, wc=583.95K\n",
      "[Epoch 9 Batch 1000/1043] loss=1.7123, ppl=5.5418, gnorm=0.3167, throughput=38.32K wps, wc=601.85K\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0da44671606e4e499401ff60d1a51f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] valid Loss=2.4916, valid ppl=12.0812, valid bleu=20.94\n",
      "Save best parameters to gnmt_en_de_512.params\n",
      "Learning rate change to 0.000125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9813f4feb4ff47cbb86a4073cf2167e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1043 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10 Batch 100/1043] loss=1.6974, ppl=5.4595, gnorm=0.3012, throughput=38.65K wps, wc=616.40K\n",
      "[Epoch 10 Batch 200/1043] loss=1.5162, ppl=4.5548, gnorm=0.3158, throughput=36.28K wps, wc=530.46K\n",
      "[Epoch 10 Batch 300/1043] loss=1.4959, ppl=4.4633, gnorm=0.3128, throughput=37.19K wps, wc=528.15K\n",
      "[Epoch 10 Batch 400/1043] loss=1.5305, ppl=4.6205, gnorm=0.3125, throughput=37.75K wps, wc=552.92K\n",
      "[Epoch 10 Batch 500/1043] loss=1.4883, ppl=4.4294, gnorm=0.3150, throughput=36.87K wps, wc=518.86K\n",
      "[Epoch 10 Batch 600/1043] loss=1.6714, ppl=5.3196, gnorm=0.3097, throughput=38.64K wps, wc=630.69K\n",
      "[Epoch 10 Batch 700/1043] loss=1.5638, ppl=4.7771, gnorm=0.3130, throughput=37.57K wps, wc=555.67K\n",
      "[Epoch 10 Batch 800/1043] loss=1.6141, ppl=5.0236, gnorm=0.3115, throughput=37.24K wps, wc=582.86K\n",
      "[Epoch 10 Batch 900/1043] loss=1.6967, ppl=5.4561, gnorm=0.3048, throughput=38.98K wps, wc=647.88K\n",
      "[Epoch 10 Batch 1000/1043] loss=1.6583, ppl=5.2501, gnorm=0.3128, throughput=38.55K wps, wc=611.42K\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "270107906db948eba804846cb8d3b999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10] valid Loss=2.5021, valid ppl=12.2086, valid bleu=20.96\n",
      "Save best parameters to gnmt_en_de_512.params\n",
      "Learning rate change to 6.25e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d80f36d95b6b45c4a801eb0e501fa883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1043 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11 Batch 100/1043] loss=1.5881, ppl=4.8943, gnorm=0.3044, throughput=38.16K wps, wc=594.99K\n",
      "[Epoch 11 Batch 200/1043] loss=1.4950, ppl=4.4594, gnorm=0.3076, throughput=37.12K wps, wc=550.29K\n",
      "[Epoch 11 Batch 300/1043] loss=1.5416, ppl=4.6722, gnorm=0.3092, throughput=37.72K wps, wc=567.04K\n",
      "[Epoch 11 Batch 400/1043] loss=1.5250, ppl=4.5951, gnorm=0.3075, throughput=37.79K wps, wc=535.70K\n",
      "[Epoch 11 Batch 500/1043] loss=1.5593, ppl=4.7555, gnorm=0.3100, throughput=36.70K wps, wc=582.91K\n",
      "[Epoch 11 Batch 600/1043] loss=1.4932, ppl=4.4512, gnorm=0.3127, throughput=36.53K wps, wc=555.74K\n",
      "[Epoch 11 Batch 700/1043] loss=1.5215, ppl=4.5793, gnorm=0.3134, throughput=36.53K wps, wc=553.90K\n",
      "[Epoch 11 Batch 800/1043] loss=1.6580, ppl=5.2487, gnorm=0.3110, throughput=38.79K wps, wc=618.74K\n",
      "[Epoch 11 Batch 900/1043] loss=1.5816, ppl=4.8628, gnorm=0.3091, throughput=38.25K wps, wc=593.70K\n",
      "[Epoch 11 Batch 1000/1043] loss=1.6163, ppl=5.0345, gnorm=0.3148, throughput=36.96K wps, wc=589.68K\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b72c670186014355bbcda0ff88b89cf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11] valid Loss=2.5078, valid ppl=12.2782, valid bleu=20.97\n",
      "Save best parameters to gnmt_en_de_512.params\n",
      "Learning rate change to 3.125e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b1a473570b54430bdd08d6a4bc32427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model valid Loss=2.5078, valid ppl=12.2782, valid bleu=20.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "986a905c96814fd5a745c315bbf26bbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model test Loss=2.3807, test ppl=10.8130, test bleu=23.15'\n"
     ]
    }
   ],
   "source": [
    "# Let's train\n",
    "trainer = mx.gluon.Trainer(gnmt_model.collect_params(), hparams.optimizer, {'learning_rate': hparams.lr})\n",
    "\n",
    "best_valid_bleu = 0.0\n",
    "\n",
    "for epoch_id in tqdm(range(hparams.epochs)):\n",
    "\n",
    "    log_loss = 0\n",
    "    log_denom = 0\n",
    "    log_avg_gnorm = 0\n",
    "    log_wc = 0\n",
    "    log_start_time = time.time()\n",
    "    \n",
    "    for batch_id, (src_seq, tgt_seq, src_valid_length, tgt_valid_length) in enumerate(tqdm(train_data_loader)):\n",
    "        \n",
    "        src_seq = src_seq.as_in_context(ctx)\n",
    "        tgt_seq = tgt_seq.as_in_context(ctx)\n",
    "        src_valid_length = src_valid_length.as_in_context(ctx)\n",
    "        tgt_valid_length = tgt_valid_length.as_in_context(ctx)\n",
    "        \n",
    "        with mx.autograd.record():\n",
    "            out, _ = gnmt_model(\n",
    "                src_seq,\n",
    "                tgt_seq[:, :-1],\n",
    "                src_valid_length,\n",
    "                tgt_valid_length - 1)\n",
    "\n",
    "            loss = loss_function(out, tgt_seq[:, 1:], tgt_valid_length - 1).mean()\n",
    "            loss = loss * (tgt_seq.shape[1] - 1)\n",
    "            log_loss += loss * tgt_seq.shape[0]\n",
    "            log_denom += (tgt_valid_length - 1).sum()\n",
    "            loss = loss / (tgt_valid_length - 1).mean()\n",
    "            loss.backward()\n",
    "        \n",
    "        grads = [p.grad(ctx) for p in gnmt_model.collect_params().values()]\n",
    "        gnorm = mx.gluon.utils.clip_global_norm(grads, hparams.clip)\n",
    "        trainer.step(1)\n",
    "        \n",
    "        src_wc = src_valid_length.sum().asscalar()\n",
    "        tgt_wc = (tgt_valid_length - 1).sum().asscalar()\n",
    "        log_loss = log_loss.asscalar()\n",
    "        log_denom = log_denom.asscalar()\n",
    "        log_avg_gnorm += gnorm\n",
    "        log_wc += src_wc + tgt_wc\n",
    "        \n",
    "        if (batch_id + 1) % hparams.log_interval == 0:\n",
    "            wps = log_wc / (time.time() - log_start_time)\n",
    "            print(\"[Epoch {} Batch {}/{}] loss={:.4f}, ppl={:.4f}, gnorm={:.4f}, \"\n",
    "                         \"throughput={:.2f}K wps, wc={:.2f}K\"\n",
    "                         .format(epoch_id, batch_id + 1, len(train_data_loader),\n",
    "                                 log_loss / log_denom,\n",
    "                                 np.exp(log_loss / log_denom),\n",
    "                                 log_avg_gnorm / hparams.log_interval,\n",
    "                                 wps / 1000, log_wc / 1000))\n",
    "            \n",
    "            log_start_time = time.time()\n",
    "            log_loss = 0\n",
    "            log_denom = 0\n",
    "            log_avg_gnorm = 0\n",
    "            log_wc = 0\n",
    "    \n",
    "    valid_loss, valid_translation_out = evaluate(\n",
    "        val_data_loader,\n",
    "        gnmt_model,\n",
    "        gnmt_translator,\n",
    "        loss_function,\n",
    "        iwslt_tgt_vocab)\n",
    "\n",
    "    valid_bleu_score, _, _, _, _ = nmt.bleu.compute_bleu([val_tgt_sentences], valid_translation_out)\n",
    "    print(\"[Epoch {}] valid Loss={:.4f}, valid ppl={:.4f}, valid bleu={:.2f}\"\n",
    "          .format(epoch_id, valid_loss, np.exp(valid_loss), valid_bleu_score * 100))\n",
    "\n",
    "    if valid_bleu_score > best_valid_bleu:\n",
    "        best_valid_bleu = valid_bleu_score\n",
    "        print(\"Save best parameters to {}\".format(hparams.file_name))\n",
    "        gnmt_model.save_parameters(hparams.file_name)\n",
    "    \n",
    "    if epoch_id + 1 >= (hparams.epochs * 2) // 3:\n",
    "        new_lr = trainer.learning_rate * hparams.lr_update_factor\n",
    "        print(\"Learning rate change to {}\".format(new_lr))\n",
    "        trainer.set_learning_rate(new_lr)\n",
    "\n",
    "if os.path.exists(hparams.file_name):\n",
    "    gnmt_model.load_parameters(hparams.file_name)\n",
    "\n",
    "valid_loss, valid_translation_out = evaluate(\n",
    "    val_data_loader,\n",
    "    gnmt_model,\n",
    "    gnmt_translator,\n",
    "    loss_function,\n",
    "    iwslt_tgt_vocab)\n",
    "\n",
    "valid_bleu_score, _, _, _, _ = nmt.bleu.compute_bleu([val_tgt_sentences], valid_translation_out)\n",
    "print(\"Best model valid Loss={:.4f}, valid ppl={:.4f}, valid bleu={:.2f}\"\n",
    "      .format(valid_loss, np.exp(valid_loss), valid_bleu_score * 100))\n",
    "\n",
    "test_loss, test_translation_out = evaluate(\n",
    "    test_data_loader,\n",
    "    gnmt_model,\n",
    "    gnmt_translator,\n",
    "    loss_function,\n",
    "    iwslt_tgt_vocab)\n",
    "\n",
    "test_bleu_score, _, _, _, _ = nmt.bleu.compute_bleu([test_tgt_sentences], test_translation_out)\n",
    "print(\"Best model test Loss={:.4f}, test ppl={:.4f}, test bleu={:.2f}'\"\n",
    "      .format(test_loss, np.exp(test_loss), test_bleu_score * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2fe7107c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qualitative Evaluation: Translating from Vietnamese to English\n",
      "Expected translation:\n",
      "I like to read books.\n",
      "In Vietnamese (from Google Translate):\n",
      "Tôi thích đọc sách kỹ thuật.\n",
      "The English translation is:\n",
      "I like to read books .\n"
     ]
    }
   ],
   "source": [
    "print(\"Qualitative Evaluation: Translating from Vietnamese to English\")\n",
    "\n",
    "expected_tgt_seq = \"I like to read books.\"\n",
    "print(\"Expected translation:\")\n",
    "print(expected_tgt_seq)\n",
    "# From Google Translate\n",
    "src_seq = \"Tôi thích đọc sách kỹ thuật.\"\n",
    "print(\"In Vietnamese (from Google Translate):\")\n",
    "print(src_seq)\n",
    "\n",
    "src_sentence = iwslt_src_vocab[src_seq.split()]\n",
    "src_sentence.append(iwslt_src_vocab[iwslt_src_vocab.eos_token])\n",
    "src_npy = np.array(src_sentence, dtype=np.int32)\n",
    "src_nd = mx.nd.array(src_npy)\n",
    "src_nd = src_nd.reshape((1, -1)).as_in_context(ctx)\n",
    "src_valid_length = mx.nd.array([src_nd.shape[1] - 2]).as_in_context(ctx)\n",
    "\n",
    "samples, _, sample_valid_length = gnmt_translator.translate(\n",
    "    src_seq=src_nd,\n",
    "    src_valid_length=src_valid_length)\n",
    "\n",
    "max_score_sample = samples[:, 0, :].asnumpy()\n",
    "sample_valid_length = sample_valid_length[:, 0].asnumpy()\n",
    "\n",
    "translation_out = []\n",
    "for i in range(max_score_sample.shape[0]):\n",
    "    translation_out.append(\n",
    "        [iwslt_tgt_vocab.idx_to_token[ele] for ele in\n",
    "         max_score_sample[i][1:(sample_valid_length[i] - 1)]])\n",
    "\n",
    "print(\"The English translation is:\")\n",
    "print(\" \".join(translation_out[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
