{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Machine Translation with Transformer\n",
    "\n",
    "In this notebook, you will understand how to use Transformers introduced in [Vaswani et al., 2017]  You will learn how to load a pretrained Transformer model and evaluate it on `newstest2016`. In addition, you are able to translate a few sentences youself with the `BeamSearchTranslator`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Preparation\n",
    "\n",
    "We start with some usual preparation such as importing libraries and setting the environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "import gluonnlp as nlp\n",
    "import sacremoses\n",
    "\n",
    "np.random.seed(100)\n",
    "random.seed(100)\n",
    "mx.random.seed(10000)\n",
    "ctx = mx.gpu(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Use the Pretrained Transformer model\n",
    "\n",
    "Next, we load the Transformer model in GluonNLP model zoo, which returns the model + the source and target vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Source Vocab: 36794 , #Target Vocab: 36794\n"
     ]
    }
   ],
   "source": [
    "import nmt\n",
    "\n",
    "wmt_transformer_model, wmt_src_vocab, wmt_tgt_vocab = \\\n",
    "    nlp.model.get_model('transformer_en_de_512',\n",
    "                        dataset_name='WMT2014',\n",
    "                        pretrained=True,\n",
    "                        ctx=ctx)\n",
    "# we are using mixed vocab of EN-DE, so the source and target language vocab are the same\n",
    "print('#Source Vocab:', len(wmt_src_vocab), ', #Target Vocab:', len(wmt_tgt_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMTModel(\n",
      "  (encoder): TransformerEncoder(\n",
      "    (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "    (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "    (transformer_cells): HybridSequential(\n",
      "      (0): TransformerEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (proj): Dense(512 -> 512, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(512 -> 2048, linear)\n",
      "          (activation): Activation(relu)\n",
      "          (ffn_2): Dense(2048 -> 512, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "      )\n",
      "      (1): TransformerEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (proj): Dense(512 -> 512, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(512 -> 2048, linear)\n",
      "          (activation): Activation(relu)\n",
      "          (ffn_2): Dense(2048 -> 512, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "      )\n",
      "      (2): TransformerEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (proj): Dense(512 -> 512, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(512 -> 2048, linear)\n",
      "          (activation): Activation(relu)\n",
      "          (ffn_2): Dense(2048 -> 512, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "      )\n",
      "      (3): TransformerEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (proj): Dense(512 -> 512, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(512 -> 2048, linear)\n",
      "          (activation): Activation(relu)\n",
      "          (ffn_2): Dense(2048 -> 512, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "      )\n",
      "      (4): TransformerEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (proj): Dense(512 -> 512, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(512 -> 2048, linear)\n",
      "          (activation): Activation(relu)\n",
      "          (ffn_2): Dense(2048 -> 512, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "      )\n",
      "      (5): TransformerEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (proj): Dense(512 -> 512, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(512 -> 2048, linear)\n",
      "          (activation): Activation(relu)\n",
      "          (ffn_2): Dense(2048 -> 512, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "    (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "    (transformer_cells): HybridSequential(\n",
      "      (0): TransformerDecoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell_in): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (attention_cell_inter): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (proj_in): Dense(512 -> 512, linear)\n",
      "        (proj_inter): Dense(512 -> 512, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(512 -> 2048, linear)\n",
      "          (activation): Activation(relu)\n",
      "          (ffn_2): Dense(2048 -> 512, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        )\n",
      "        (layer_norm_in): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        (layer_norm_inter): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "      )\n",
      "      (1): TransformerDecoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell_in): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (attention_cell_inter): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (proj_in): Dense(512 -> 512, linear)\n",
      "        (proj_inter): Dense(512 -> 512, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(512 -> 2048, linear)\n",
      "          (activation): Activation(relu)\n",
      "          (ffn_2): Dense(2048 -> 512, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        )\n",
      "        (layer_norm_in): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        (layer_norm_inter): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "      )\n",
      "      (2): TransformerDecoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell_in): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (attention_cell_inter): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (proj_in): Dense(512 -> 512, linear)\n",
      "        (proj_inter): Dense(512 -> 512, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(512 -> 2048, linear)\n",
      "          (activation): Activation(relu)\n",
      "          (ffn_2): Dense(2048 -> 512, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        )\n",
      "        (layer_norm_in): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        (layer_norm_inter): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "      )\n",
      "      (3): TransformerDecoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell_in): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (attention_cell_inter): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (proj_in): Dense(512 -> 512, linear)\n",
      "        (proj_inter): Dense(512 -> 512, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(512 -> 2048, linear)\n",
      "          (activation): Activation(relu)\n",
      "          (ffn_2): Dense(2048 -> 512, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        )\n",
      "        (layer_norm_in): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        (layer_norm_inter): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "      )\n",
      "      (4): TransformerDecoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell_in): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (attention_cell_inter): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (proj_in): Dense(512 -> 512, linear)\n",
      "        (proj_inter): Dense(512 -> 512, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(512 -> 2048, linear)\n",
      "          (activation): Activation(relu)\n",
      "          (ffn_2): Dense(2048 -> 512, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        )\n",
      "        (layer_norm_in): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        (layer_norm_inter): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "      )\n",
      "      (5): TransformerDecoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell_in): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (attention_cell_inter): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (proj_in): Dense(512 -> 512, linear)\n",
      "        (proj_inter): Dense(512 -> 512, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(512 -> 2048, linear)\n",
      "          (activation): Activation(relu)\n",
      "          (ffn_2): Dense(2048 -> 512, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        )\n",
      "        (layer_norm_in): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        (layer_norm_inter): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (one_step_ahead_decoder): TransformerOneStepDecoder(\n",
      "    (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "    (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "    (transformer_cells): HybridSequential(\n",
      "      (0): TransformerDecoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell_in): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (attention_cell_inter): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (proj_in): Dense(512 -> 512, linear)\n",
      "        (proj_inter): Dense(512 -> 512, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(512 -> 2048, linear)\n",
      "          (activation): Activation(relu)\n",
      "          (ffn_2): Dense(2048 -> 512, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        )\n",
      "        (layer_norm_in): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        (layer_norm_inter): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "      )\n",
      "      (1): TransformerDecoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell_in): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (attention_cell_inter): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (proj_in): Dense(512 -> 512, linear)\n",
      "        (proj_inter): Dense(512 -> 512, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(512 -> 2048, linear)\n",
      "          (activation): Activation(relu)\n",
      "          (ffn_2): Dense(2048 -> 512, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        )\n",
      "        (layer_norm_in): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        (layer_norm_inter): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "      )\n",
      "      (2): TransformerDecoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell_in): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (attention_cell_inter): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (proj_in): Dense(512 -> 512, linear)\n",
      "        (proj_inter): Dense(512 -> 512, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(512 -> 2048, linear)\n",
      "          (activation): Activation(relu)\n",
      "          (ffn_2): Dense(2048 -> 512, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        )\n",
      "        (layer_norm_in): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        (layer_norm_inter): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "      )\n",
      "      (3): TransformerDecoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell_in): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (attention_cell_inter): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (proj_in): Dense(512 -> 512, linear)\n",
      "        (proj_inter): Dense(512 -> 512, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(512 -> 2048, linear)\n",
      "          (activation): Activation(relu)\n",
      "          (ffn_2): Dense(2048 -> 512, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        )\n",
      "        (layer_norm_in): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        (layer_norm_inter): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "      )\n",
      "      (4): TransformerDecoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell_in): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (attention_cell_inter): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (proj_in): Dense(512 -> 512, linear)\n",
      "        (proj_inter): Dense(512 -> 512, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(512 -> 2048, linear)\n",
      "          (activation): Activation(relu)\n",
      "          (ffn_2): Dense(2048 -> 512, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        )\n",
      "        (layer_norm_in): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        (layer_norm_inter): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "      )\n",
      "      (5): TransformerDecoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell_in): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (attention_cell_inter): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (proj_in): Dense(512 -> 512, linear)\n",
      "        (proj_inter): Dense(512 -> 512, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(512 -> 2048, linear)\n",
      "          (activation): Activation(relu)\n",
      "          (ffn_2): Dense(2048 -> 512, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        )\n",
      "        (layer_norm_in): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        (layer_norm_inter): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (src_embed): HybridSequential(\n",
      "    (0): Embedding(36794 -> 512, float32)\n",
      "    (1): Dropout(p = 0.0, axes=())\n",
      "  )\n",
      "  (tgt_embed): HybridSequential(\n",
      "    (0): Embedding(36794 -> 512, float32)\n",
      "    (1): Dropout(p = 0.0, axes=())\n",
      "  )\n",
      "  (tgt_proj): Dense(512 -> 36794, linear)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(wmt_transformer_model) # Print the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Load and Preprocess WMT 2016 Dataset\n",
    "\n",
    "We then load the newstest2016 segment in WMT 2016 English-German test dataset for evaluation purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Firstly, look at the WMT 2016 corpus. `GluonNLP` provides [WMT2016BPE](../../api/modules/data.rst#gluonnlp.data.WMT2016BPE)\n",
    "and [WMT2016](../../api/modules/data.rst#gluonnlp.data.WMT2016) classes. The former contains a BPE-tokenized dataset, while the later contains the raw text. Here, we use the former for scoring, and the latter for\n",
    "demonstrating actual translation.\n",
    "\n",
    "For the BPE, it is one way to convert words to sub-words. E.g, the word **cheapest** will be converted to **cheap@@** and **est**, and **sunnyvale** will be converted to **sunny@@** and **vale**. The representational ability of the vocabulary is greatly improved by using sub-words. This is a common trick in NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source language en, Target language de\n",
      "Sample BPE tokens: \"('Delta State University police chief L@@ ynn Bu@@ ford said university officials heard about the shooting at 10 : 18 a.m.', 'Delta State University Poli@@ zeich@@ ef L@@ ynn Bu@@ ford sagte , dass Universitäts@@ -@@ Mitarbeiter das Sch@@ ießen um 10 : 18 Uhr gehört haben .')\"\n",
      "Sample raw text: \"('By the end of the day, there would be one more death: Lamb took his own life as police closed in on him.', 'Bis zum Ende des Tages gab es einen weiteren Tod: Lamm nahm sich das Leben, als die Polizei ihn einkesselte.')\"\n"
     ]
    }
   ],
   "source": [
    "import hyperparameters as hparams\n",
    "\n",
    "#wmt_data_text = nlp.data.WMT2014BPE('newstest2014', # BPE: cheapest --> cheap@@, est\n",
    "wmt_data_text = nlp.data.WMT2016BPE('newstest2016', # BPE: cheapest --> cheap@@, est\n",
    "                                    src_lang=hparams.src_lang,\n",
    "                                    tgt_lang=hparams.tgt_lang)\n",
    "print('Source language %s, Target language %s' % (hparams.src_lang, hparams.tgt_lang))\n",
    "print('Sample BPE tokens: \"{}\"'.format(wmt_data_text[14]))\n",
    "\n",
    "#wmt_test_text = nlp.data.WMT2014('newstest2014',\n",
    "wmt_test_text = nlp.data.WMT2016('newstest2016',\n",
    "                                 src_lang=hparams.src_lang,\n",
    "                                 tgt_lang=hparams.tgt_lang)\n",
    "# For demo process, will only evaluate the prediction of the first 50 sentences\n",
    "wmt_data_text, wmt_test_text = gluon.data.SimpleDataset([wmt_data_text[i] for i in range(18)]), gluon.data.SimpleDataset([wmt_test_text[i] for i in range(18)])\n",
    "\n",
    "print('Sample raw text: \"{}\"'.format(wmt_test_text[16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample target sentence: \"Bis zum Ende des Tages gab es einen weiteren Tod: Lamm nahm sich das Leben, als die Polizei ihn einkesselte.\"\n"
     ]
    }
   ],
   "source": [
    "# Slice the target part of the dataset using .transform\n",
    "wmt_test_tgt_sentences = wmt_test_text.transform(lambda src, tgt: tgt)\n",
    "print('Sample target sentence: \"{}\"'.format(wmt_test_tgt_sentences[16]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We further process the dataset using the `.transform()` API. The preprocessing have the following 4 steps:\n",
    "\n",
    "1) Clip the source and target sequences\n",
    "\n",
    "2) Split the string input to a list of tokens\n",
    "\n",
    "3) Map the string token into its index in the vocabulary\n",
    "\n",
    "4) Append EOS token to source sentence and add BOS and EOS tokens to target sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7224 25657  7048 12057 11496 29502     3] \n",
      " [    2  7224 16715  7048 12057 11496 29502     3]\n"
     ]
    }
   ],
   "source": [
    "import dataprocessor\n",
    "\n",
    "# wmt_transform_fn includes the four preprocessing steps mentioned above.\n",
    "wmt_transform_fn = dataprocessor.TrainValDataTransform(wmt_src_vocab, wmt_tgt_vocab)\n",
    "wmt_dataset_processed = wmt_data_text.transform(wmt_transform_fn, lazy=False)\n",
    "\n",
    "def get_length_index_fn():\n",
    "    global idx\n",
    "    idx = 0\n",
    "    def transform(src, tgt):\n",
    "        global idx\n",
    "        result = (src, tgt, len(src), len(tgt), idx)\n",
    "        idx += 1\n",
    "        return result\n",
    "    return transform\n",
    "\n",
    "wmt_data_text_with_len = wmt_dataset_processed.transform(get_length_index_fn(), lazy=False)\n",
    "# Five elements: Source Token Ids, Target Token Ids, Source Seq Length, Target Seq length, Index\n",
    "print(wmt_data_text_with_len[0][0], '\\n', wmt_data_text_with_len[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Creating `Sampler` and `DataLoader` for the `WMT 2016` Dataset\n",
    "\n",
    "Now, we have obtained the transformed datasets. The next step is to construct sampler and DataLoader. First, we need to construct batchify function, which pads and stacks sequences to form mini-batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "wmt_test_batchify_fn = nlp.data.batchify.Tuple(\n",
    "    nlp.data.batchify.Pad(),                   # Source Token IDs\n",
    "    nlp.data.batchify.Pad(),                   # Target Token IDs\n",
    "    nlp.data.batchify.Stack(dtype='float32'),  # Source Sequence Length\n",
    "    nlp.data.batchify.Stack(dtype='float32'),  # Target Sequence Length\n",
    "    nlp.data.batchify.Stack())                 # Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* [Tuple](https://gluon-nlp.mxnet.io/api/modules/data.batchify.html?highlight=batchify#gluonnlp.data.batchify.Tuple) is the GluonNLP way of applying different batchify functions to each element of a dataset item. In this case, we are applying `Pad` to `src` and `tgt`, `Stack` to `len(src)` and `len(tgt)` with conversion to float32, and simple `Stack` to `idx` without type conversion.\n",
    "* [Pad](https://gluon-nlp.mxnet.io/api/modules/data.batchify.html?highlight=batchify#gluonnlp.data.batchify.Pad) takes the elements from all dataset items in a batch, and pad them according to the item of maximum length to form a padded matrix/tensor.\n",
    "* [Stack](https://gluon-nlp.mxnet.io/api/modules/data.batchify.html?highlight=batchify#gluonnlp.data.batchify.Stack) simply stacks all elements in a batch, and requires all elements to be of the same length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can then construct bucketing samplers, which generate batches by grouping sequences with similar lengths. Here, we use [FixedBucketSampler](https://gluon-nlp.mxnet.io/api/modules/data.html?highlight=fixedbucketsampler#gluonnlp.data.FixedBucketSampler). `FixedBucketSampler` aims to assign each data sample to a bucket based on its length. The buckets are determined automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    " Please refer to [BucketSampler](https://gluon-nlp.mxnet.io/api/notes/data_api.html) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FixedBucketSampler:\n",
      "  sample_num=18, batch_num=10\n",
      "  key=[(28, 36), (49, 63), (70, 90)]\n",
      "  cnt=[11, 5, 2]\n",
      "  batch_size=[2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "wmt_test_batch_sampler = nlp.data.FixedBucketSampler(\n",
    "    lengths=wmt_data_text_with_len.transform(lambda src, tgt, src_len, tgt_len, idx: (src_len, tgt_len)), #(src, tgt)\n",
    "    num_buckets=3,\n",
    "    batch_size=2)\n",
    "print(wmt_test_batch_sampler.stats())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Given the samplers, we can use [DataLoader](https://mxnet.apache.org/versions/master/api/python/gluon/data.html#mxnet.gluon.data.DataLoader) to sample the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of testing batches: 10\n"
     ]
    }
   ],
   "source": [
    "wmt_test_data_loader = gluon.data.DataLoader(\n",
    "    wmt_data_text_with_len,\n",
    "    batch_sampler=wmt_test_batch_sampler,\n",
    "    batchify_fn=wmt_test_batchify_fn,\n",
    "    num_workers=8)  # Note that we can use multi-processing\n",
    "print('Number of testing batches:', len(wmt_test_data_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Evaluate Transformer\n",
    "\n",
    "Next, we evaluate the performance of the model on the `newstest2016` dataset. We first define the `BeamSearchTranslator` to generate the translations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beam Size = 4 , Lengh penalty Alpha= 0.6 , Length penalty K= 5\n"
     ]
    }
   ],
   "source": [
    "print('Beam Size =', hparams.beam_size, ', Lengh penalty Alpha=', hparams.lp_alpha, ', Length penalty K=', hparams.lp_k)\n",
    "wmt_translator = nmt.translation.BeamSearchTranslator(\n",
    "    model=wmt_transformer_model,\n",
    "    beam_size=hparams.beam_size,\n",
    "    scorer=nlp.model.BeamSearchScorer(alpha=hparams.lp_alpha, K=hparams.lp_k),\n",
    "    max_length=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Then we caculate the `loss` as well as the `bleu` score on the newstest2016 WMT 2016 English-German test dataset. This may take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/andreto/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/andreto/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/andreto/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c838fb828864cce87638bb7b6156c93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extension horovod.torch has not been built: /home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/site-packages/horovod/torch/mpi_lib/_mpi_lib.cpython-37m-x86_64-linux-gnu.so not found\n",
      "If this is not expected, reinstall Horovod with HOROVOD_WITH_PYTORCH=1 to debug the build error.\n",
      "Warning! MPI libs are missing, but python applications are still avaiable.\n",
      "[2022-06-05 21:12:46.698 ip-172-31-28-47:15718 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2022-06-05 21:12:46.727 ip-172-31-28-47:15718 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "WMT16 EN-DE SOTA model test loss: 1.37; test bleu score: 24.29; time cost 14.72s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import utils\n",
    "\n",
    "eval_start_time = time.time()\n",
    "wmt_test_loss_function = nlp.loss.MaskedSoftmaxCELoss()\n",
    "wmt_test_loss_function.hybridize()\n",
    "wmt_detokenizer = nlp.data.SacreMosesDetokenizer()\n",
    "wmt_test_loss, wmt_test_translation_out = nmt.utils.evaluate(\n",
    "    wmt_transformer_model,\n",
    "    wmt_test_data_loader,\n",
    "    wmt_test_loss_function,\n",
    "    wmt_translator,\n",
    "    wmt_tgt_vocab,\n",
    "    wmt_detokenizer,\n",
    "    ctx)\n",
    "\n",
    "wmt_test_bleu_score, _, _, _, _ = nmt.bleu.compute_bleu(\n",
    "    [wmt_test_tgt_sentences],\n",
    "    wmt_test_translation_out,\n",
    "    tokenized=False,\n",
    "    tokenizer=hparams.bleu,\n",
    "    split_compound_word=False,\n",
    "    bpe=False)\n",
    "\n",
    "print('WMT16 EN-DE SOTA model test loss: %.2f; test bleu score: %.2f; time cost %.2fs' %(wmt_test_loss, wmt_test_bleu_score * 100, (time.time() - eval_start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample translations:\n",
      "EN:\n",
      "Obama receives Netanyahu\n",
      "DE-Candidate:\n",
      "Obama erhält Netanjahu\n",
      "DE-Reference:\n",
      "Obama empfängt Netanyahu\n",
      "========\n"
     ]
    }
   ],
   "source": [
    "print('Sample translations:')\n",
    "num_pairs = 1\n",
    "\n",
    "for i in range(num_pairs):\n",
    "    print('EN:')\n",
    "    print(wmt_test_text[i][0])\n",
    "    print('DE-Candidate:')\n",
    "    print(wmt_test_translation_out[i])\n",
    "    print('DE-Reference:')\n",
    "    print(wmt_test_tgt_sentences[i])\n",
    "    print('========')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Translation Inference\n",
    "\n",
    "We herein show the actual translation example (EN-DE) when given a source language using the SOTA Transformer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the following English sentence into German:\n",
      "['We love language.']\n",
      "The German translation is:\n",
      "['Wir sind erfreut darüber, dass']\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "print('Translate the following English sentence into German:')\n",
    "\n",
    "sample_src_seq = 'We love language.'\n",
    "print('[\\'' + sample_src_seq + '\\']')\n",
    "sample_tgt_seq = nmt.utils.translate(wmt_translator, sample_src_seq, wmt_src_vocab, wmt_tgt_vocab, wmt_detokenizer,\n",
    "                                 ctx)\n",
    "print('The German translation is:')\n",
    "print(sample_tgt_seq)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
