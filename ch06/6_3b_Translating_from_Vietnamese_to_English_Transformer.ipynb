{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbbe216b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/andreto/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/andreto/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/andreto/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "import gluonnlp as nlp\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import sacremoses\n",
    "import time\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "\n",
    "# Local Libraries\n",
    "import nmt\n",
    "import dataprocessor\n",
    "import utils\n",
    "import nmt.transformer_hparams\n",
    "\n",
    "# Seeds for reproducibility\n",
    "np.random.seed(100)\n",
    "random.seed(100)\n",
    "mx.random.seed(10000)\n",
    "\n",
    "# CPU setup\n",
    "# ctx = mx.cpu()\n",
    "# Single GPU setup\n",
    "ctx = mx.gpu(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bac926f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andreto/.local/lib/python3.7/site-packages/gluonnlp/vocab/vocab.py:591: UserWarning: Detected a corrupted index in the deserialize vocabulary. For versions before GluonNLP v0.7 the index is corrupted by specifying the same token for different special purposes, for example eos_token == padding_token. Deserializing the vocabulary nevertheless.\n",
      "  'Detected a corrupted index in the deserialize vocabulary. '\n"
     ]
    }
   ],
   "source": [
    "# IWSLT2015 Dataset (Train, Validation and Test)\n",
    "\n",
    "# Dataset Parameters\n",
    "src_lang, tgt_lang = \"vi\", \"en\"\n",
    "src_max_len, tgt_max_len = 50, 50\n",
    "\n",
    "iwslt_train_text = nlp.data.IWSLT2015(\"train\",\n",
    "                                      src_lang=src_lang,\n",
    "                                      tgt_lang=tgt_lang)\n",
    "\n",
    "iwslt_val_text   = nlp.data.IWSLT2015(\"val\",\n",
    "                                      src_lang=src_lang,\n",
    "                                      tgt_lang=tgt_lang)\n",
    "\n",
    "iwslt_test_text  = nlp.data.IWSLT2015(\"test\",\n",
    "                                      src_lang=src_lang,\n",
    "                                      tgt_lang=tgt_lang)\n",
    "\n",
    "\n",
    "iwslt_src_vocab = iwslt_train_text.src_vocab\n",
    "iwslt_tgt_vocab = iwslt_train_text.tgt_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a3383d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train set: 133166\n",
      "Length of val set  : 1553\n",
      "Length of test set : 1268\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of train set:\", len(iwslt_train_text))\n",
    "print(\"Length of val set  :\", len(iwslt_val_text))\n",
    "print(\"Length of test set :\", len(iwslt_test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "075d11ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset processing: clipping, tokenizing, indexing and adding of EOS (src/tgt) / BOS (tgt)\n",
    "iwslt_train_processed = iwslt_train_text.transform(\n",
    "    dataprocessor.TrainValDataTransform(\n",
    "        iwslt_src_vocab,\n",
    "        iwslt_tgt_vocab,\n",
    "        src_max_len,\n",
    "        tgt_max_len),\n",
    "    lazy=False)\n",
    "\n",
    "iwslt_val_processed   = iwslt_val_text.transform(\n",
    "    dataprocessor.TrainValDataTransform(\n",
    "        iwslt_src_vocab,\n",
    "        iwslt_tgt_vocab,\n",
    "        src_max_len,\n",
    "        tgt_max_len),\n",
    "    lazy=False)\n",
    "\n",
    "iwslt_test_processed  = iwslt_test_text.transform(\n",
    "    dataprocessor.TrainValDataTransform(\n",
    "        iwslt_src_vocab,\n",
    "        iwslt_tgt_vocab,\n",
    "        src_max_len,\n",
    "        tgt_max_len),\n",
    "    lazy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3884e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Sequences (Val, Test)\n",
    "fetch_tgt_sentence = lambda src, tgt: tgt.split()\n",
    "val_tgt_sentences = list(iwslt_val_text.transform(fetch_tgt_sentence))\n",
    "test_tgt_sentences = list(iwslt_test_text.transform(fetch_tgt_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c26bf695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Gluon Datasets\n",
    "# Not needed for training, as training data will be sharded later\n",
    "iwslt_train_transformed = iwslt_train_processed.transform(\n",
    "    lambda src, tgt: (src, tgt, len(src), len(tgt)),\n",
    "    lazy=False)\n",
    "\n",
    "iwslt_val_dataset = mx.gluon.data.SimpleDataset(\n",
    "    [(ele[0], ele[1], len(ele[0]), len(ele[1]),i) for i, ele in enumerate(iwslt_val_processed)])\n",
    "\n",
    "iwslt_test_dataset = mx.gluon.data.SimpleDataset(\n",
    "    [(ele[0], ele[1], len(ele[0]), len(ele[1]), i) for i, ele in enumerate(iwslt_test_processed)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0278d19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for Dataloaders and Training\n",
    "hparams = nmt.transformer_hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5703956b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams.num_hidden = 1024\n",
    "hparams.num_layers = 2\n",
    "hparams.dropout = 0.2\n",
    "hparams.num_buckets = 5\n",
    "hparams.lr = 0.0002\n",
    "#hparams.lr = 0.0003 achieves 21.44 test_bleu: qualitative evaluation didn't work\n",
    "#hparams.lr = 0.0001 achieves 19.66 test_bleu: qualitative evaluation worked\n",
    "hparams.clip = 5\n",
    "hparams.epochs = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32d3a2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andreto/.local/lib/python3.7/site-packages/gluonnlp/data/batchify/batchify.py:235: UserWarning: Padding value is not given and will be set automatically to 0 in data.batchify.Pad(). Please check whether this is intended (e.g. value of padding index in the vocabulary).\n",
      "  'Padding value is not given and will be set automatically to 0 '\n"
     ]
    }
   ],
   "source": [
    "# Create Gluon Samplers and DataLoaders\n",
    "\n",
    "# Helper function for lengths\n",
    "def get_data_lengths(dataset):\n",
    "    get_lengths = lambda *args: (args[2], args[3])\n",
    "    return list(dataset.transform(get_lengths))\n",
    "\n",
    "# Bucket scheme\n",
    "bucket_scheme = nlp.data.ExpWidthBucket(bucket_len_step=1.2)\n",
    "\n",
    "iwslt_train_lengths = get_data_lengths(iwslt_train_transformed)\n",
    "iwslt_val_lengths = get_data_lengths(iwslt_val_dataset)\n",
    "iwslt_test_lengths = get_data_lengths(iwslt_test_dataset)\n",
    "\n",
    "train_batchify_fn = nlp.data.batchify.Tuple(\n",
    "    nlp.data.batchify.Pad(),\n",
    "    nlp.data.batchify.Pad(),\n",
    "    nlp.data.batchify.Stack(dtype='float32'),\n",
    "    nlp.data.batchify.Stack(dtype='float32'))\n",
    "\n",
    "test_batchify_fn = nlp.data.batchify.Tuple(\n",
    "    nlp.data.batchify.Pad(),\n",
    "    nlp.data.batchify.Pad(),\n",
    "    nlp.data.batchify.Stack(dtype='float32'),\n",
    "    nlp.data.batchify.Stack(dtype='float32'),\n",
    "    nlp.data.batchify.Stack())\n",
    "\n",
    "target_val_lengths = list(map(lambda x: x[-1], iwslt_val_lengths))\n",
    "target_test_lengths = list(map(lambda x: x[-1], iwslt_test_lengths))\n",
    "\n",
    "train_batch_sampler = nlp.data.FixedBucketSampler(\n",
    "    lengths=iwslt_train_lengths,\n",
    "    batch_size=hparams.batch_size,\n",
    "    num_buckets=hparams.num_buckets,\n",
    "    ratio=0,\n",
    "    shuffle=True,\n",
    "    use_average_length=False,\n",
    "    num_shards=0,\n",
    "    bucket_scheme=bucket_scheme)\n",
    "    \n",
    "train_data_loader = nlp.data.ShardedDataLoader(\n",
    "    iwslt_train_transformed,\n",
    "    batch_sampler=train_batch_sampler,\n",
    "    batchify_fn=train_batchify_fn,\n",
    "    num_workers=8)\n",
    "\n",
    "val_batch_sampler = nlp.data.FixedBucketSampler(\n",
    "    lengths=iwslt_val_lengths,\n",
    "    batch_size=hparams.test_batch_size,\n",
    "    num_buckets=hparams.num_buckets,\n",
    "    ratio=0,\n",
    "    shuffle=False,\n",
    "    use_average_length=False,\n",
    "    bucket_scheme=bucket_scheme)\n",
    "\n",
    "val_data_loader = mx.gluon.data.DataLoader(\n",
    "    iwslt_val_dataset,\n",
    "    batch_sampler=val_batch_sampler,\n",
    "    batchify_fn=test_batchify_fn,\n",
    "    num_workers=8)\n",
    "\n",
    "test_batch_sampler = nlp.data.FixedBucketSampler(\n",
    "    lengths=iwslt_test_lengths,\n",
    "    batch_size=hparams.test_batch_size,\n",
    "    num_buckets=hparams.num_buckets,\n",
    "    ratio=0,\n",
    "    shuffle=False,\n",
    "    use_average_length=False,\n",
    "    bucket_scheme=bucket_scheme)\n",
    "\n",
    "test_data_loader = mx.gluon.data.DataLoader(\n",
    "    iwslt_test_dataset,\n",
    "    batch_sampler=test_batch_sampler,\n",
    "    batchify_fn=test_batchify_fn,\n",
    "    num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6433aa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer Model\n",
    "transformer_encoder, transformer_decoder, transformer_one_step_ahead_decoder = nlp.model.transformer.get_transformer_encoder_decoder(\n",
    "    hidden_size=hparams.num_hidden,\n",
    "    dropout=hparams.dropout,\n",
    "    num_layers=hparams.num_layers)\n",
    "\n",
    "transformer_model = nlp.model.translation.NMTModel(\n",
    "    src_vocab=iwslt_src_vocab,\n",
    "    tgt_vocab=iwslt_tgt_vocab,\n",
    "    encoder=transformer_encoder,\n",
    "    decoder=transformer_decoder,\n",
    "    one_step_ahead_decoder=transformer_one_step_ahead_decoder,\n",
    "    #embed_size=hparams.num_hidden,\n",
    "    embed_size=hparams.num_units,\n",
    "    prefix='transformer_')\n",
    "\n",
    "transformer_model.initialize(init=mx.init.Xavier(magnitude=1.0), ctx=ctx)\n",
    "static_alloc = True\n",
    "transformer_model.hybridize(static_alloc=static_alloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d3ae74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translator (using model defined above)\n",
    "transformer_translator = nmt.translation.BeamSearchTranslator(\n",
    "    model=transformer_model,\n",
    "    beam_size=hparams.beam_size,\n",
    "    scorer=nlp.model.BeamSearchScorer(\n",
    "        alpha=hparams.lp_alpha,\n",
    "        K=hparams.lp_k),\n",
    "    max_length=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "076325eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "loss_function = nlp.loss.MaskedSoftmaxCELoss()\n",
    "loss_function.hybridize(static_alloc=static_alloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87e41efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function (used also on training loop for validation)\n",
    "def evaluate(\n",
    "    data_loader,\n",
    "    model,\n",
    "    translator,\n",
    "    loss_function,\n",
    "    tgt_vocab):\n",
    "\n",
    "    translation_out = []\n",
    "    all_inst_ids = []\n",
    "    avg_loss_denom = 0\n",
    "    avg_loss = 0.0\n",
    "    \n",
    "    for _, (src_seq, tgt_seq, src_valid_length, tgt_valid_length, inst_ids) in enumerate(tqdm(data_loader)):\n",
    "        \n",
    "        src_seq = src_seq.as_in_context(ctx)\n",
    "        tgt_seq = tgt_seq.as_in_context(ctx)\n",
    "        src_valid_length = src_valid_length.as_in_context(ctx)\n",
    "        tgt_valid_length = tgt_valid_length.as_in_context(ctx)\n",
    "        \n",
    "        # Calculating Loss\n",
    "        out, _ = model(\n",
    "            src_seq,\n",
    "            tgt_seq[:, :-1],\n",
    "            src_valid_length,\n",
    "            tgt_valid_length - 1)\n",
    "\n",
    "        loss = loss_function(\n",
    "            out,\n",
    "            tgt_seq[:, 1:],\n",
    "            tgt_valid_length - 1).sum().asscalar()\n",
    "        \n",
    "        all_inst_ids.extend(inst_ids.asnumpy().astype(np.int32).tolist())\n",
    "        avg_loss += loss * (tgt_seq.shape[1] - 1)\n",
    "        avg_loss_denom += (tgt_valid_length - 1).sum().asscalar()\n",
    "        \n",
    "        # Translate\n",
    "        samples, _, sample_valid_length = translator.translate(\n",
    "            src_seq=src_seq,\n",
    "            src_valid_length=src_valid_length)\n",
    "        \n",
    "        max_score_sample = samples[:, 0, :].asnumpy()\n",
    "        sample_valid_length = sample_valid_length[:, 0].asnumpy()\n",
    "        \n",
    "        for i in range(max_score_sample.shape[0]):\n",
    "            translation_out.append(\n",
    "                [tgt_vocab.idx_to_token[ele] for ele in\n",
    "                 max_score_sample[i][1:(sample_valid_length[i] - 1)]])\n",
    "    \n",
    "    avg_loss = avg_loss / avg_loss_denom\n",
    "    real_translation_out = [None for _ in range(len(all_inst_ids))]\n",
    "    \n",
    "    for ind, sentence in zip(all_inst_ids, translation_out):\n",
    "        real_translation_out[ind] = sentence\n",
    "    \n",
    "    return avg_loss, real_translation_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0707abf5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8f8b7583dd44a51b9cf6eaaf211b8c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7229008e3774494fbff5d725dff8eb01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1043 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extension horovod.torch has not been built: /home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/site-packages/horovod/torch/mpi_lib/_mpi_lib.cpython-37m-x86_64-linux-gnu.so not found\n",
      "If this is not expected, reinstall Horovod with HOROVOD_WITH_PYTORCH=1 to debug the build error.\n",
      "Warning! MPI libs are missing, but python applications are still avaiable.\n",
      "[2022-06-19 14:06:32.626 ip-172-31-28-47:4312 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2022-06-19 14:06:32.654 ip-172-31-28-47:4312 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "[Epoch 0 Batch 100/1043] loss=6.7084, ppl=819.2355, gnorm=1.8441, throughput=66.23K wps, wc=606.57K\n",
      "[Epoch 0 Batch 200/1043] loss=5.4545, ppl=233.7993, gnorm=0.8658, throughput=78.02K wps, wc=584.18K\n",
      "[Epoch 0 Batch 300/1043] loss=5.0439, ppl=155.0811, gnorm=0.7771, throughput=79.05K wps, wc=592.78K\n",
      "[Epoch 0 Batch 400/1043] loss=4.7569, ppl=116.3892, gnorm=0.7737, throughput=77.17K wps, wc=571.26K\n",
      "[Epoch 0 Batch 500/1043] loss=4.5697, ppl=96.5154, gnorm=0.8034, throughput=76.70K wps, wc=554.48K\n",
      "[Epoch 0 Batch 600/1043] loss=4.4209, ppl=83.1675, gnorm=0.8039, throughput=76.39K wps, wc=546.26K\n",
      "[Epoch 0 Batch 700/1043] loss=4.2975, ppl=73.5136, gnorm=0.8287, throughput=77.18K wps, wc=566.96K\n",
      "[Epoch 0 Batch 800/1043] loss=4.1896, ppl=65.9942, gnorm=0.8222, throughput=76.36K wps, wc=551.40K\n",
      "[Epoch 0 Batch 900/1043] loss=4.1185, ppl=61.4684, gnorm=0.8415, throughput=78.30K wps, wc=577.61K\n",
      "[Epoch 0 Batch 1000/1043] loss=4.0372, ppl=56.6664, gnorm=0.8391, throughput=78.20K wps, wc=588.16K\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e49bdd3ab5f84cc2a6eb253d479357f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] valid Loss=3.6623, valid ppl=38.9501, valid bleu=8.60\n",
      "Save best parameters to transformer_vi_en_512.params\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bff2ffa90a4546ba9b6ce096acdfae18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1043 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1 Batch 100/1043] loss=3.9303, ppl=50.9234, gnorm=0.9466, throughput=78.88K wps, wc=593.66K\n",
      "[Epoch 1 Batch 200/1043] loss=3.8821, ppl=48.5280, gnorm=0.8841, throughput=80.44K wps, wc=631.62K\n",
      "[Epoch 1 Batch 300/1043] loss=3.7671, ppl=43.2557, gnorm=0.8781, throughput=78.21K wps, wc=599.65K\n",
      "[Epoch 1 Batch 400/1043] loss=3.6893, ppl=40.0150, gnorm=0.9162, throughput=77.84K wps, wc=585.70K\n",
      "[Epoch 1 Batch 500/1043] loss=3.5871, ppl=36.1288, gnorm=0.9167, throughput=74.58K wps, wc=567.14K\n",
      "[Epoch 1 Batch 600/1043] loss=3.5016, ppl=33.1693, gnorm=0.9948, throughput=74.13K wps, wc=521.63K\n",
      "[Epoch 1 Batch 700/1043] loss=3.5757, ppl=35.7195, gnorm=0.9630, throughput=78.12K wps, wc=591.94K\n",
      "[Epoch 1 Batch 800/1043] loss=3.4869, ppl=32.6842, gnorm=0.9859, throughput=76.83K wps, wc=563.74K\n",
      "[Epoch 1 Batch 900/1043] loss=3.4072, ppl=30.1794, gnorm=0.9480, throughput=77.68K wps, wc=578.06K\n",
      "[Epoch 1 Batch 1000/1043] loss=3.3057, ppl=27.2668, gnorm=0.9951, throughput=73.23K wps, wc=523.53K\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7256e4f8477d4cbcbf1e6c1242cb2951",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] valid Loss=3.1175, valid ppl=22.5907, valid bleu=12.38\n",
      "Save best parameters to transformer_vi_en_512.params\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68f0ab6f38934e739bc344ca2ad5a6fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1043 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2 Batch 100/1043] loss=3.2211, ppl=25.0565, gnorm=1.0404, throughput=75.46K wps, wc=542.87K\n",
      "[Epoch 2 Batch 200/1043] loss=3.2101, ppl=24.7816, gnorm=1.0168, throughput=77.13K wps, wc=575.69K\n",
      "[Epoch 2 Batch 300/1043] loss=3.1919, ppl=24.3334, gnorm=1.0130, throughput=77.58K wps, wc=568.29K\n",
      "[Epoch 2 Batch 400/1043] loss=3.1759, ppl=23.9478, gnorm=1.0601, throughput=77.36K wps, wc=578.89K\n",
      "[Epoch 2 Batch 500/1043] loss=3.1396, ppl=23.0946, gnorm=1.0487, throughput=77.97K wps, wc=590.93K\n",
      "[Epoch 2 Batch 600/1043] loss=3.1260, ppl=22.7835, gnorm=1.1220, throughput=76.77K wps, wc=561.47K\n",
      "[Epoch 2 Batch 700/1043] loss=3.1379, ppl=23.0560, gnorm=1.0278, throughput=79.60K wps, wc=624.59K\n",
      "[Epoch 2 Batch 800/1043] loss=3.0243, ppl=20.5802, gnorm=1.0761, throughput=76.45K wps, wc=564.54K\n",
      "[Epoch 2 Batch 900/1043] loss=3.0408, ppl=20.9211, gnorm=1.0561, throughput=77.88K wps, wc=583.36K\n",
      "[Epoch 2 Batch 1000/1043] loss=2.9381, ppl=18.8802, gnorm=1.1090, throughput=74.20K wps, wc=528.11K\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4c8aac632f44c1181adb0263c446dd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] valid Loss=2.8164, valid ppl=16.7168, valid bleu=15.07\n",
      "Save best parameters to transformer_vi_en_512.params\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7db40508af054aa1b949c5901f699f1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1043 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3 Batch 100/1043] loss=2.9372, ppl=18.8634, gnorm=1.0504, throughput=80.26K wps, wc=630.11K\n",
      "[Epoch 3 Batch 200/1043] loss=2.8474, ppl=17.2424, gnorm=1.1350, throughput=77.10K wps, wc=572.70K\n",
      "[Epoch 3 Batch 300/1043] loss=2.8795, ppl=17.8057, gnorm=1.1045, throughput=76.46K wps, wc=598.93K\n",
      "[Epoch 3 Batch 400/1043] loss=2.7426, ppl=15.5277, gnorm=1.1372, throughput=74.76K wps, wc=537.22K\n",
      "[Epoch 3 Batch 500/1043] loss=2.7151, ppl=15.1064, gnorm=1.1466, throughput=73.82K wps, wc=529.51K\n",
      "[Epoch 3 Batch 600/1043] loss=2.8010, ppl=16.4608, gnorm=1.0932, throughput=78.91K wps, wc=610.71K\n",
      "[Epoch 3 Batch 700/1043] loss=2.6975, ppl=14.8428, gnorm=1.1676, throughput=73.69K wps, wc=519.76K\n",
      "[Epoch 3 Batch 800/1043] loss=2.6737, ppl=14.4930, gnorm=1.1357, throughput=74.42K wps, wc=539.30K\n",
      "[Epoch 3 Batch 900/1043] loss=2.7145, ppl=15.0971, gnorm=1.1404, throughput=76.50K wps, wc=581.69K\n",
      "[Epoch 3 Batch 1000/1043] loss=2.7309, ppl=15.3462, gnorm=1.1503, throughput=76.93K wps, wc=569.12K\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b45e335b0c654381984b2d621b46b07a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] valid Loss=2.6274, valid ppl=13.8376, valid bleu=17.55\n",
      "Save best parameters to transformer_vi_en_512.params\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83ea97c2d4b242ec97a7f0ba79d3f3a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1043 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4 Batch 100/1043] loss=2.5427, ppl=12.7137, gnorm=1.1242, throughput=73.01K wps, wc=568.46K\n",
      "[Epoch 4 Batch 200/1043] loss=2.5178, ppl=12.4007, gnorm=1.1387, throughput=75.09K wps, wc=542.90K\n",
      "[Epoch 4 Batch 300/1043] loss=2.5404, ppl=12.6849, gnorm=1.1521, throughput=75.18K wps, wc=555.44K\n",
      "[Epoch 4 Batch 400/1043] loss=2.5353, ppl=12.6207, gnorm=1.1682, throughput=75.14K wps, wc=543.93K\n",
      "[Epoch 4 Batch 500/1043] loss=2.5616, ppl=12.9569, gnorm=1.1864, throughput=77.47K wps, wc=579.34K\n",
      "[Epoch 4 Batch 600/1043] loss=2.5642, ppl=12.9904, gnorm=1.1868, throughput=78.87K wps, wc=601.62K\n",
      "[Epoch 4 Batch 700/1043] loss=2.5646, ppl=12.9956, gnorm=1.1445, throughput=78.02K wps, wc=597.87K\n",
      "[Epoch 4 Batch 800/1043] loss=2.4197, ppl=11.2420, gnorm=1.1771, throughput=72.84K wps, wc=507.35K\n",
      "[Epoch 4 Batch 900/1043] loss=2.5877, ppl=13.2992, gnorm=1.1411, throughput=80.15K wps, wc=624.02K\n",
      "[Epoch 4 Batch 1000/1043] loss=2.5248, ppl=12.4888, gnorm=1.2029, throughput=77.75K wps, wc=580.31K\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf752daae9f548a69f960644eaa16f3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] valid Loss=2.5413, valid ppl=12.6965, valid bleu=18.59\n",
      "Save best parameters to transformer_vi_en_512.params\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df5d1b577cec423b9e92116668c6eb2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1043 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5 Batch 100/1043] loss=2.2943, ppl=9.9173, gnorm=1.1877, throughput=70.90K wps, wc=529.43K\n",
      "[Epoch 5 Batch 200/1043] loss=2.4243, ppl=11.2946, gnorm=1.1439, throughput=78.70K wps, wc=611.54K\n",
      "[Epoch 5 Batch 300/1043] loss=2.3747, ppl=10.7475, gnorm=1.1691, throughput=77.44K wps, wc=582.88K\n",
      "[Epoch 5 Batch 400/1043] loss=2.3706, ppl=10.7039, gnorm=1.2060, throughput=75.52K wps, wc=556.31K\n",
      "[Epoch 5 Batch 500/1043] loss=2.1880, ppl=8.9173, gnorm=1.2242, throughput=69.79K wps, wc=472.55K\n",
      "[Epoch 5 Batch 600/1043] loss=2.3917, ppl=10.9321, gnorm=1.1742, throughput=77.69K wps, wc=586.79K\n",
      "[Epoch 5 Batch 700/1043] loss=2.3410, ppl=10.3916, gnorm=1.2015, throughput=75.84K wps, wc=561.02K\n",
      "[Epoch 5 Batch 800/1043] loss=2.3298, ppl=10.2760, gnorm=1.1815, throughput=75.56K wps, wc=555.63K\n",
      "[Epoch 5 Batch 900/1043] loss=2.4026, ppl=11.0523, gnorm=1.1827, throughput=79.09K wps, wc=600.79K\n",
      "[Epoch 5 Batch 1000/1043] loss=2.4892, ppl=12.0520, gnorm=1.1765, throughput=81.92K wps, wc=659.40K\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "677d4890b17b4a4f9032ed8698a171c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] valid Loss=2.4685, valid ppl=11.8044, valid bleu=19.57\n",
      "Save best parameters to transformer_vi_en_512.params\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffaae73a8bee4c369cf362f9963b87e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1043 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6 Batch 100/1043] loss=2.2380, ppl=9.3742, gnorm=1.1522, throughput=77.89K wps, wc=603.59K\n",
      "[Epoch 6 Batch 200/1043] loss=2.1875, ppl=8.9132, gnorm=1.1880, throughput=76.24K wps, wc=562.11K\n",
      "[Epoch 6 Batch 300/1043] loss=2.2740, ppl=9.7180, gnorm=1.1601, throughput=79.83K wps, wc=624.24K\n",
      "[Epoch 6 Batch 400/1043] loss=2.2598, ppl=9.5811, gnorm=1.2093, throughput=78.05K wps, wc=603.10K\n",
      "[Epoch 6 Batch 500/1043] loss=2.2568, ppl=9.5524, gnorm=1.2441, throughput=76.24K wps, wc=561.10K\n",
      "[Epoch 6 Batch 600/1043] loss=2.2465, ppl=9.4548, gnorm=1.2140, throughput=76.14K wps, wc=565.55K\n",
      "[Epoch 6 Batch 700/1043] loss=2.2451, ppl=9.4411, gnorm=1.2296, throughput=76.12K wps, wc=555.39K\n",
      "[Epoch 6 Batch 800/1043] loss=2.2161, ppl=9.1716, gnorm=1.2531, throughput=71.75K wps, wc=537.32K\n",
      "[Epoch 6 Batch 900/1043] loss=2.2698, ppl=9.6774, gnorm=1.2136, throughput=77.77K wps, wc=591.29K\n",
      "[Epoch 6 Batch 1000/1043] loss=2.2374, ppl=9.3689, gnorm=1.2336, throughput=75.75K wps, wc=554.05K\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e43943eab494564bcd904c02e5a69da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] valid Loss=2.4405, valid ppl=11.4787, valid bleu=19.49\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddfabb98dd0d4ec8b01feb9f2860a8be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1043 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7 Batch 100/1043] loss=2.1473, ppl=8.5616, gnorm=1.1758, throughput=74.77K wps, wc=587.59K\n",
      "[Epoch 7 Batch 200/1043] loss=2.1825, ppl=8.8688, gnorm=1.1932, throughput=79.83K wps, wc=622.04K\n",
      "[Epoch 7 Batch 300/1043] loss=2.0657, ppl=7.8909, gnorm=1.2132, throughput=73.69K wps, wc=540.54K\n",
      "[Epoch 7 Batch 400/1043] loss=2.0335, ppl=7.6411, gnorm=1.2544, throughput=71.88K wps, wc=502.07K\n",
      "[Epoch 7 Batch 500/1043] loss=2.1515, ppl=8.5977, gnorm=1.2361, throughput=76.74K wps, wc=583.79K\n",
      "[Epoch 7 Batch 600/1043] loss=2.1973, ppl=9.0004, gnorm=1.2101, throughput=78.78K wps, wc=609.75K\n",
      "[Epoch 7 Batch 700/1043] loss=2.1568, ppl=8.6438, gnorm=1.2432, throughput=75.91K wps, wc=577.30K\n",
      "[Epoch 7 Batch 800/1043] loss=2.0550, ppl=7.8065, gnorm=1.2672, throughput=72.33K wps, wc=505.00K\n",
      "[Epoch 7 Batch 900/1043] loss=2.1399, ppl=8.4989, gnorm=1.2154, throughput=77.48K wps, wc=590.09K\n",
      "[Epoch 7 Batch 1000/1043] loss=2.1901, ppl=8.9359, gnorm=1.2096, throughput=78.45K wps, wc=599.85K\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "932c741d767547f8834542d3b338d562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] valid Loss=2.4142, valid ppl=11.1805, valid bleu=20.13\n",
      "Save best parameters to transformer_vi_en_512.params\n",
      "Learning rate change to 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0049cbe8f0024ed696fca85f53aa4be5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1043 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8 Batch 100/1043] loss=1.9423, ppl=6.9748, gnorm=1.1630, throughput=75.39K wps, wc=556.55K\n",
      "[Epoch 8 Batch 200/1043] loss=2.0301, ppl=7.6145, gnorm=1.1573, throughput=78.74K wps, wc=601.04K\n",
      "[Epoch 8 Batch 300/1043] loss=2.0363, ppl=7.6622, gnorm=1.1539, throughput=79.10K wps, wc=614.51K\n",
      "[Epoch 8 Batch 400/1043] loss=1.9333, ppl=6.9120, gnorm=1.2045, throughput=74.46K wps, wc=539.14K\n",
      "[Epoch 8 Batch 500/1043] loss=1.9802, ppl=7.2445, gnorm=1.1950, throughput=76.23K wps, wc=561.68K\n",
      "[Epoch 8 Batch 600/1043] loss=1.9891, ppl=7.3091, gnorm=1.2018, throughput=73.70K wps, wc=567.04K\n",
      "[Epoch 8 Batch 700/1043] loss=2.0401, ppl=7.6916, gnorm=1.1765, throughput=78.33K wps, wc=600.47K\n",
      "[Epoch 8 Batch 800/1043] loss=2.0376, ppl=7.6720, gnorm=1.1732, throughput=79.50K wps, wc=610.25K\n",
      "[Epoch 8 Batch 900/1043] loss=1.9602, ppl=7.1007, gnorm=1.1951, throughput=75.80K wps, wc=562.08K\n",
      "[Epoch 8 Batch 1000/1043] loss=1.9308, ppl=6.8950, gnorm=1.2208, throughput=73.77K wps, wc=530.23K\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7548cc73ed52421eb2b689ff7d4488d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] valid Loss=2.3786, valid ppl=10.7895, valid bleu=20.54\n",
      "Save best parameters to transformer_vi_en_512.params\n",
      "Learning rate change to 5e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad81da02257f4048ad2e54421da7f696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1043 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9 Batch 100/1043] loss=1.9284, ppl=6.8782, gnorm=1.1618, throughput=73.38K wps, wc=576.48K\n",
      "[Epoch 9 Batch 200/1043] loss=1.8704, ppl=6.4907, gnorm=1.1736, throughput=75.75K wps, wc=550.86K\n",
      "[Epoch 9 Batch 300/1043] loss=2.0102, ppl=7.4649, gnorm=1.1480, throughput=80.92K wps, wc=633.26K\n",
      "[Epoch 9 Batch 400/1043] loss=1.9573, ppl=7.0804, gnorm=1.1929, throughput=76.97K wps, wc=579.86K\n",
      "[Epoch 9 Batch 500/1043] loss=1.8593, ppl=6.4192, gnorm=1.1888, throughput=75.05K wps, wc=543.97K\n",
      "[Epoch 9 Batch 600/1043] loss=1.8956, ppl=6.6567, gnorm=1.1880, throughput=75.21K wps, wc=547.23K\n",
      "[Epoch 9 Batch 700/1043] loss=1.8804, ppl=6.5562, gnorm=1.1867, throughput=76.76K wps, wc=580.76K\n",
      "[Epoch 9 Batch 800/1043] loss=1.8278, ppl=6.2201, gnorm=1.1924, throughput=73.34K wps, wc=533.16K\n",
      "[Epoch 9 Batch 900/1043] loss=1.9034, ppl=6.7089, gnorm=1.1740, throughput=77.18K wps, wc=583.95K\n",
      "[Epoch 9 Batch 1000/1043] loss=1.9554, ppl=7.0671, gnorm=1.1755, throughput=78.62K wps, wc=601.85K\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c19377a6be2c4e5bb26c566437cdd60d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] valid Loss=2.3591, valid ppl=10.5811, valid bleu=20.73\n",
      "Save best parameters to transformer_vi_en_512.params\n",
      "Learning rate change to 2.5e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36bad3e089ad4333959b8dc36b768558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1043 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10 Batch 100/1043] loss=1.9649, ppl=7.1339, gnorm=1.1642, throughput=79.40K wps, wc=616.40K\n",
      "[Epoch 10 Batch 200/1043] loss=1.8010, ppl=6.0560, gnorm=1.1976, throughput=73.72K wps, wc=530.46K\n",
      "[Epoch 10 Batch 300/1043] loss=1.7824, ppl=5.9442, gnorm=1.1884, throughput=74.01K wps, wc=528.15K\n",
      "[Epoch 10 Batch 400/1043] loss=1.8086, ppl=6.1018, gnorm=1.1734, throughput=75.41K wps, wc=552.92K\n",
      "[Epoch 10 Batch 500/1043] loss=1.7766, ppl=5.9097, gnorm=1.1915, throughput=73.25K wps, wc=518.86K\n",
      "[Epoch 10 Batch 600/1043] loss=1.9344, ppl=6.9196, gnorm=1.1462, throughput=80.35K wps, wc=630.69K\n",
      "[Epoch 10 Batch 700/1043] loss=1.8438, ppl=6.3204, gnorm=1.1790, throughput=75.78K wps, wc=555.67K\n",
      "[Epoch 10 Batch 800/1043] loss=1.8859, ppl=6.5924, gnorm=1.1687, throughput=77.33K wps, wc=582.86K\n",
      "[Epoch 10 Batch 900/1043] loss=1.9531, ppl=7.0504, gnorm=1.1451, throughput=81.08K wps, wc=647.88K\n",
      "[Epoch 10 Batch 1000/1043] loss=1.9252, ppl=6.8563, gnorm=1.1675, throughput=78.71K wps, wc=611.42K\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2365df481774ec68a664620d7b7c9a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10] valid Loss=2.3550, valid ppl=10.5381, valid bleu=21.05\n",
      "Save best parameters to transformer_vi_en_512.params\n",
      "Learning rate change to 1.25e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce00826872014101b48dfa3d90188aed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1043 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11 Batch 100/1043] loss=1.8764, ppl=6.5302, gnorm=1.1583, throughput=74.52K wps, wc=594.99K\n",
      "[Epoch 11 Batch 200/1043] loss=1.7861, ppl=5.9664, gnorm=1.1738, throughput=75.36K wps, wc=550.29K\n",
      "[Epoch 11 Batch 300/1043] loss=1.8272, ppl=6.2166, gnorm=1.1700, throughput=76.28K wps, wc=567.04K\n",
      "[Epoch 11 Batch 400/1043] loss=1.8277, ppl=6.2198, gnorm=1.1865, throughput=74.99K wps, wc=535.70K\n",
      "[Epoch 11 Batch 500/1043] loss=1.8415, ppl=6.3062, gnorm=1.1643, throughput=76.84K wps, wc=582.91K\n",
      "[Epoch 11 Batch 600/1043] loss=1.7840, ppl=5.9537, gnorm=1.1722, throughput=75.41K wps, wc=555.74K\n",
      "[Epoch 11 Batch 700/1043] loss=1.8103, ppl=6.1121, gnorm=1.1841, throughput=74.93K wps, wc=553.90K\n",
      "[Epoch 11 Batch 800/1043] loss=1.9372, ppl=6.9392, gnorm=1.1759, throughput=79.58K wps, wc=618.74K\n",
      "[Epoch 11 Batch 900/1043] loss=1.8652, ppl=6.4573, gnorm=1.1608, throughput=77.92K wps, wc=593.70K\n",
      "[Epoch 11 Batch 1000/1043] loss=1.8979, ppl=6.6716, gnorm=1.1896, throughput=77.66K wps, wc=589.68K\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c33e9cb81747db89fd36769b6d5411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11] valid Loss=2.3541, valid ppl=10.5284, valid bleu=20.95\n",
      "Learning rate change to 6.25e-06\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d317fbff43c14e4886582c8cb8beeeee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model valid Loss=2.3550, valid ppl=10.5381, valid bleu=21.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56594e2546754bd1be6f7aeb1a7540b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model test Loss=2.2326, test ppl=9.3240, test bleu=22.87'\n"
     ]
    }
   ],
   "source": [
    "# Let's train\n",
    "trainer = mx.gluon.Trainer(transformer_model.collect_params(), hparams.optimizer, {'learning_rate': hparams.lr})\n",
    "\n",
    "best_valid_bleu = 0.0\n",
    "\n",
    "for epoch_id in tqdm(range(hparams.epochs)):\n",
    "\n",
    "    log_loss = 0\n",
    "    log_denom = 0\n",
    "    log_avg_gnorm = 0\n",
    "    log_wc = 0\n",
    "    log_start_time = time.time()\n",
    "    \n",
    "    for batch_id, (src_seq, tgt_seq, src_valid_length, tgt_valid_length) in enumerate(tqdm(train_data_loader)):\n",
    "        \n",
    "        src_seq = src_seq.as_in_context(ctx)\n",
    "        tgt_seq = tgt_seq.as_in_context(ctx)\n",
    "        src_valid_length = src_valid_length.as_in_context(ctx)\n",
    "        tgt_valid_length = tgt_valid_length.as_in_context(ctx)\n",
    "        \n",
    "        with mx.autograd.record():\n",
    "            out, _ = transformer_model(\n",
    "                src_seq,\n",
    "                tgt_seq[:, :-1],\n",
    "                src_valid_length,\n",
    "                tgt_valid_length - 1)\n",
    "\n",
    "            loss = loss_function(out, tgt_seq[:, 1:], tgt_valid_length - 1).mean()\n",
    "            loss = loss * (tgt_seq.shape[1] - 1)\n",
    "            log_loss += loss * tgt_seq.shape[0]\n",
    "            log_denom += (tgt_valid_length - 1).sum()\n",
    "            loss = loss / (tgt_valid_length - 1).mean()\n",
    "            loss.backward()\n",
    "        \n",
    "        grads = [p.grad(ctx) for p in transformer_model.collect_params().values() if p.grad_req != \"null\"]\n",
    "        gnorm = mx.gluon.utils.clip_global_norm(grads, hparams.clip)\n",
    "        trainer.step(1)\n",
    "        \n",
    "        src_wc = src_valid_length.sum().asscalar()\n",
    "        tgt_wc = (tgt_valid_length - 1).sum().asscalar()\n",
    "        log_loss = log_loss.asscalar()\n",
    "        log_denom = log_denom.asscalar()\n",
    "        log_avg_gnorm += gnorm\n",
    "        log_wc += src_wc + tgt_wc\n",
    "        \n",
    "        if (batch_id + 1) % hparams.log_interval == 0:\n",
    "            wps = log_wc / (time.time() - log_start_time)\n",
    "            print(\"[Epoch {} Batch {}/{}] loss={:.4f}, ppl={:.4f}, gnorm={:.4f}, \"\n",
    "                         \"throughput={:.2f}K wps, wc={:.2f}K\"\n",
    "                         .format(epoch_id, batch_id + 1, len(train_data_loader),\n",
    "                                 log_loss / log_denom,\n",
    "                                 np.exp(log_loss / log_denom),\n",
    "                                 log_avg_gnorm / hparams.log_interval,\n",
    "                                 wps / 1000, log_wc / 1000))\n",
    "            \n",
    "            log_start_time = time.time()\n",
    "            log_loss = 0\n",
    "            log_denom = 0\n",
    "            log_avg_gnorm = 0\n",
    "            log_wc = 0\n",
    "    \n",
    "    valid_loss, valid_translation_out = evaluate(\n",
    "        val_data_loader,\n",
    "        transformer_model,\n",
    "        transformer_translator,\n",
    "        loss_function,\n",
    "        iwslt_tgt_vocab)\n",
    "\n",
    "    valid_bleu_score, _, _, _, _ = nmt.bleu.compute_bleu([val_tgt_sentences], valid_translation_out)\n",
    "    print(\"[Epoch {}] valid Loss={:.4f}, valid ppl={:.4f}, valid bleu={:.2f}\"\n",
    "          .format(epoch_id, valid_loss, np.exp(valid_loss), valid_bleu_score * 100))\n",
    "\n",
    "    if valid_bleu_score > best_valid_bleu:\n",
    "        best_valid_bleu = valid_bleu_score\n",
    "        print(\"Save best parameters to {}\".format(hparams.file_name))\n",
    "        transformer_model.save_parameters(hparams.file_name)\n",
    "    \n",
    "    if epoch_id + 1 >= (hparams.epochs * 2) // 3:\n",
    "        new_lr = trainer.learning_rate * hparams.lr_update_factor\n",
    "        print(\"Learning rate change to {}\".format(new_lr))\n",
    "        trainer.set_learning_rate(new_lr)\n",
    "\n",
    "if os.path.exists(hparams.file_name):\n",
    "    transformer_model.load_parameters(hparams.file_name)\n",
    "\n",
    "valid_loss, valid_translation_out = evaluate(\n",
    "    val_data_loader,\n",
    "    transformer_model,\n",
    "    transformer_translator,\n",
    "    loss_function,\n",
    "    iwslt_tgt_vocab)\n",
    "\n",
    "valid_bleu_score, _, _, _, _ = nmt.bleu.compute_bleu([val_tgt_sentences], valid_translation_out)\n",
    "print(\"Best model valid Loss={:.4f}, valid ppl={:.4f}, valid bleu={:.2f}\"\n",
    "      .format(valid_loss, np.exp(valid_loss), valid_bleu_score * 100))\n",
    "\n",
    "test_loss, test_translation_out = evaluate(\n",
    "    test_data_loader,\n",
    "    transformer_model,\n",
    "    transformer_translator,\n",
    "    loss_function,\n",
    "    iwslt_tgt_vocab)\n",
    "\n",
    "test_bleu_score, _, _, _, _ = nmt.bleu.compute_bleu([test_tgt_sentences], test_translation_out)\n",
    "print(\"Best model test Loss={:.4f}, test ppl={:.4f}, test bleu={:.2f}'\"\n",
    "      .format(test_loss, np.exp(test_loss), test_bleu_score * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2fe7107c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qualitative Evaluation: Translating from Vietnamese to English\n",
      "Expected translation:\n",
      "I like to read books.\n",
      "In Vietnamese (from Google Translate):\n",
      "Tôi thích đọc sách kỹ thuật.\n",
      "The English translation is:\n",
      "I love reading books .\n"
     ]
    }
   ],
   "source": [
    "print(\"Qualitative Evaluation: Translating from Vietnamese to English\")\n",
    "\n",
    "expected_tgt_seq = \"I like to read books.\"\n",
    "print(\"Expected translation:\")\n",
    "print(expected_tgt_seq)\n",
    "# From Google Translate\n",
    "src_seq = \"Tôi thích đọc sách kỹ thuật.\"\n",
    "print(\"In Vietnamese (from Google Translate):\")\n",
    "print(src_seq)\n",
    "\n",
    "src_sentence = iwslt_src_vocab[src_seq.split()]\n",
    "src_sentence.append(iwslt_src_vocab[iwslt_src_vocab.eos_token])\n",
    "src_npy = np.array(src_sentence, dtype=np.int32)\n",
    "src_nd = mx.nd.array(src_npy)\n",
    "src_nd = src_nd.reshape((1, -1)).as_in_context(ctx)\n",
    "src_valid_length = mx.nd.array([src_nd.shape[1]]).as_in_context(ctx)\n",
    "\n",
    "samples, _, sample_valid_length = transformer_translator.translate(\n",
    "    src_seq=src_nd,\n",
    "    src_valid_length=src_valid_length)\n",
    "\n",
    "max_score_sample = samples[:, 0, :].asnumpy()\n",
    "sample_valid_length = sample_valid_length[:, 0].asnumpy()\n",
    "\n",
    "translation_out = []\n",
    "for i in range(max_score_sample.shape[0]):\n",
    "    translation_out.append(\n",
    "        [iwslt_tgt_vocab.idx_to_token[ele] for ele in\n",
    "         max_score_sample[i][1:(sample_valid_length[i] - 1)]])\n",
    "\n",
    "print(\"The English translation is:\")\n",
    "print(\" \".join(translation_out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fcfecb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
