{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbbe216b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/andreto/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/andreto/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/andreto/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "import gluonnlp as nlp\n",
    "\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import sacremoses\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "# Local Libraries\n",
    "import nmt\n",
    "import dataprocessor\n",
    "import utils\n",
    "import nmt.gnmt_hparams\n",
    "\n",
    "# Seeds for reproducibility\n",
    "np.random.seed(100)\n",
    "random.seed(100)\n",
    "mx.random.seed(10000)\n",
    "\n",
    "# CPU setup\n",
    "# ctx = mx.cpu()\n",
    "# Single GPU setup\n",
    "ctx = mx.gpu(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f17f9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Parameters\n",
    "src_lang, tgt_lang = 'en', 'de'\n",
    "# No limit on sentences length\n",
    "src_max_len, tgt_max_len = -1, -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bac926f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andreto/.local/lib/python3.7/site-packages/gluonnlp/vocab/vocab.py:591: UserWarning: Detected a corrupted index in the deserialize vocabulary. For versions before GluonNLP v0.7 the index is corrupted by specifying the same token for different special purposes, for example eos_token == padding_token. Deserializing the vocabulary nevertheless.\n",
      "  'Detected a corrupted index in the deserialize vocabulary. '\n"
     ]
    }
   ],
   "source": [
    "# WMT2016 Dataset (Train and Evaluation)\n",
    "wmt_train_text_bpe = nlp.data.WMT2016BPE(\"train\", # BPE: cheapest --> cheap@@, est\n",
    "                                         src_lang=src_lang,\n",
    "                                         tgt_lang=tgt_lang)\n",
    "\n",
    "wmt_train_text     = nlp.data.WMT2016(\"train\",\n",
    "                                      src_lang=src_lang,\n",
    "                                      tgt_lang=tgt_lang)\n",
    "\n",
    "wmt_test_text_bpe  = nlp.data.WMT2016BPE(\"newstest2016\", # BPE: cheapest --> cheap@@, est\n",
    "                                         src_lang=src_lang,\n",
    "                                         tgt_lang=tgt_lang)\n",
    "\n",
    "wmt_test_text      = nlp.data.WMT2016(\"newstest2016\",\n",
    "                                     src_lang=src_lang,\n",
    "                                     tgt_lang=tgt_lang)\n",
    "\n",
    "wmt_src_vocab = wmt_train_text_bpe.src_vocab\n",
    "wmt_tgt_vocab = wmt_train_text_bpe.tgt_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6aa0bda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing datasets\n",
    "# Filtering training data to a maximum number of samples,\n",
    "# so that training can be handled in a reasonable time (~8 hrs)\n",
    "# in single GPU setups\n",
    "max_samples = int(1e4)\n",
    "wmt_train_text_bpe = mx.gluon.data.SimpleDataset([wmt_train_text_bpe[i] for i in range(max_samples)])\n",
    "wmt_train_text     = mx.gluon.data.SimpleDataset([wmt_train_text[i] for i in range(max_samples)])\n",
    "wmt_test_text_bpe  = mx.gluon.data.SimpleDataset(wmt_test_text_bpe)\n",
    "wmt_test_text      = mx.gluon.data.SimpleDataset(wmt_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1f77292",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By the end of the day, there would be one more death: Lamb took his own life as police closed in on him.\n",
      "Bis zum Ende des Tages gab es einen weiteren Tod: Lamm nahm sich das Leben, als die Polizei ihn einkesselte.\n"
     ]
    }
   ],
   "source": [
    "# Dataset example (human-readable): English and German\n",
    "print(wmt_test_text[16][0])\n",
    "print(wmt_test_text[16][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "237ae7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample target sentence:\n",
      "Bis zum Ende des Tages gab es einen weiteren Tod: Lamm nahm sich das Leben, als die Polizei ihn einkesselte.\n"
     ]
    }
   ],
   "source": [
    "# Retrieve (split) translated sequences (target)\n",
    "wmt_train_tgt_sentences = wmt_train_text.transform(lambda src, tgt: tgt)\n",
    "wmt_test_tgt_sentences  = wmt_test_text.transform(lambda src, tgt: tgt)\n",
    "print(\"Sample target sentence:\")\n",
    "print(wmt_test_tgt_sentences[16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd74a96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2083 28753 16760 23875 28753 15230    28 28783 31223 12931 24017 23247\n",
      " 15259   569  5971 12813 29083 20097 24348 22312 12290 24829 14439 20585\n",
      " 24004 20061    62     3]\n",
      "[    2  1897 31601  3259 15535  9414 18646 17382 16407 30851  9629   569\n",
      "  5971 22642 23439 27119 15199  6041    28 11681 15681  7670 20454 16394\n",
      " 21488 26868 28535    62     3]\n"
     ]
    }
   ],
   "source": [
    "# Dataset processing: clipping, tokenizing, indexing and adding of EOS (src/tgt) / BOS (tgt)\n",
    "wmt_transform_fn = dataprocessor.TrainValDataTransform(wmt_src_vocab, wmt_tgt_vocab)\n",
    "\n",
    "wmt_train_processed = wmt_train_text_bpe.transform(wmt_transform_fn, lazy=False)\n",
    "wmt_test_processed  = wmt_test_text_bpe.transform(wmt_transform_fn, lazy=False)\n",
    "\n",
    "wmt_train_text_with_len = wmt_train_processed.transform(nmt.utils.get_length_index_fn(), lazy=False)\n",
    "wmt_test_text_with_len  = wmt_test_processed.transform(nmt.utils.get_length_index_fn(), lazy=False)\n",
    "\n",
    "print(wmt_test_text_with_len[16][0])\n",
    "print(wmt_test_text_with_len[16][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b817d057",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andreto/.local/lib/python3.7/site-packages/gluonnlp/data/batchify/batchify.py:235: UserWarning: Padding value is not given and will be set automatically to 0 in data.batchify.Pad(). Please check whether this is intended (e.g. value of padding index in the vocabulary).\n",
      "  'Padding value is not given and will be set automatically to 0 '\n"
     ]
    }
   ],
   "source": [
    "# Batcher\n",
    "wmt_batchify_fn = nlp.data.batchify.Tuple(\n",
    "    nlp.data.batchify.Pad(),                   # Source Token IDs\n",
    "    nlp.data.batchify.Pad(),                   # Target Token IDs\n",
    "    nlp.data.batchify.Stack(dtype='float32'),  # Source Sequence Length\n",
    "    nlp.data.batchify.Stack(dtype='float32'),  # Target Sequence Length\n",
    "    nlp.data.batchify.Stack())                 # Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d10c420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "hparams = nmt.gnmt_hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f3c4dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FixedBucketSampler:\n",
      "  sample_num=10000, batch_num=159\n",
      "  key=[(21, 25), (39, 44), (57, 63), (75, 82), (93, 101)]\n",
      "  cnt=[3409, 3991, 1797, 622, 181]\n",
      "  batch_size=[64, 64, 64, 64, 64]\n",
      "FixedBucketSampler:\n",
      "  sample_num=2999, batch_num=97\n",
      "  key=[(23, 26), (43, 48), (63, 70), (83, 92), (103, 114)]\n",
      "  cnt=[1417, 1191, 329, 56, 6]\n",
      "  batch_size=[32, 32, 32, 32, 32]\n"
     ]
    }
   ],
   "source": [
    "# Samplers\n",
    "wmt_train_batch_sampler = nlp.data.FixedBucketSampler(\n",
    "    lengths=wmt_train_text_with_len.transform(lambda src, tgt, src_len, tgt_len, idx: (src_len, tgt_len)),\n",
    "    num_buckets=hparams.num_buckets,\n",
    "    batch_size=hparams.batch_size)\n",
    "print(wmt_train_batch_sampler.stats())\n",
    "\n",
    "wmt_test_batch_sampler = nlp.data.FixedBucketSampler(\n",
    "    lengths=wmt_test_text_with_len.transform(lambda src, tgt, src_len, tgt_len, idx: (src_len, tgt_len)),\n",
    "    num_buckets=hparams.num_buckets,\n",
    "    batch_size=hparams.test_batch_size)\n",
    "print(wmt_test_batch_sampler.stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec987736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training batches: 159\n",
      "Number of testing batches: 97\n"
     ]
    }
   ],
   "source": [
    "# DataLoaders\n",
    "wmt_train_data_loader = mx.gluon.data.DataLoader(\n",
    "    wmt_train_text_with_len,\n",
    "    batch_sampler=wmt_train_batch_sampler,\n",
    "    batchify_fn=wmt_batchify_fn,\n",
    "    num_workers=8)\n",
    "print('Number of training batches:', len(wmt_train_data_loader))\n",
    "\n",
    "wmt_test_data_loader = mx.gluon.data.DataLoader(\n",
    "    wmt_test_text_with_len,\n",
    "    batch_sampler=wmt_test_batch_sampler,\n",
    "    batchify_fn=wmt_batchify_fn,\n",
    "    num_workers=8)\n",
    "print('Number of testing batches:', len(wmt_test_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af12498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "encoder, decoder, one_step_ahead_decoder = nmt.gnmt.get_gnmt_encoder_decoder(\n",
    "    hidden_size=hparams.num_hidden,\n",
    "    dropout=hparams.dropout,\n",
    "    num_layers=hparams.num_layers,\n",
    "    num_bi_layers=hparams.num_bi_layers)\n",
    "\n",
    "gnmt_model = nlp.model.translation.NMTModel(\n",
    "    src_vocab=wmt_src_vocab,\n",
    "    tgt_vocab=wmt_tgt_vocab,\n",
    "    encoder=encoder,\n",
    "    decoder=decoder,\n",
    "    one_step_ahead_decoder=one_step_ahead_decoder,\n",
    "    embed_size=hparams.num_hidden,\n",
    "    prefix='gnmt_')\n",
    "\n",
    "gnmt_model.initialize(init=mx.init.Uniform(0.1), ctx=ctx)\n",
    "static_alloc = True\n",
    "gnmt_model.hybridize(static_alloc=static_alloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d4dbb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use beam_size=10, alpha=1.0, K=5\n"
     ]
    }
   ],
   "source": [
    "scorer=nlp.model.BeamSearchScorer(\n",
    "    alpha=hparams.lp_alpha,\n",
    "    K=hparams.lp_k)\n",
    "\n",
    "gnmt_translator = nmt.translation.BeamSearchTranslator(\n",
    "    model=gnmt_model,\n",
    "    beam_size=hparams.beam_size,\n",
    "    scorer=scorer,\n",
    "    max_length=tgt_max_len + 100)\n",
    "\n",
    "print(\"Use beam_size={}, alpha={}, K={}\".format(hparams.beam_size, hparams.lp_alpha, hparams.lp_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84aaecde",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2640f55b57e54138a9356e37d814f127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extension horovod.torch has not been built: /home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/site-packages/horovod/torch/mpi_lib/_mpi_lib.cpython-37m-x86_64-linux-gnu.so not found\n",
      "If this is not expected, reinstall Horovod with HOROVOD_WITH_PYTORCH=1 to debug the build error.\n",
      "Warning! MPI libs are missing, but python applications are still avaiable.\n",
      "[2022-06-05 12:17:37.605 ip-172-31-28-47:9936 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2022-06-05 12:17:37.636 ip-172-31-28-47:9936 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "WMT16 EN-DE SOTA model test loss: 7.75; test bleu score: 0.00; time cost 125.61s\n"
     ]
    }
   ],
   "source": [
    "# Evaluation (Baseline)\n",
    "eval_start_time = time.time()\n",
    "wmt_loss_function = nlp.loss.MaskedSoftmaxCELoss()\n",
    "wmt_loss_function.hybridize()\n",
    "wmt_detokenizer = nlp.data.SacreMosesDetokenizer()\n",
    "\n",
    "gnmt_test_loss, gnmt_test_translation_out = nmt.utils.evaluate(\n",
    "    gnmt_model,\n",
    "    wmt_test_data_loader,\n",
    "    wmt_loss_function,\n",
    "    gnmt_translator,\n",
    "    wmt_tgt_vocab,\n",
    "    wmt_detokenizer,\n",
    "    ctx)\n",
    "\n",
    "gnmt_test_bleu_score, _, _, _, _ = nmt.bleu.compute_bleu(\n",
    "    [wmt_test_tgt_sentences],\n",
    "    gnmt_test_translation_out,\n",
    "    tokenized=False,\n",
    "    tokenizer=hparams.bleu,\n",
    "    split_compound_word=False,\n",
    "    bpe=False)\n",
    "\n",
    "print('WMT16 EN-DE GNMT model test loss: %.2f; test bleu score: %.2f; time cost %.2fs' %(gnmt_test_loss, gnmt_test_bleu_score * 100, (time.time() - eval_start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8b75217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "trainer = mx.gluon.Trainer(gnmt_model.collect_params(), 'adam', {'learning_rate': hparams.lr})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59d38bb4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc54fdfdc8834ae1abedb79143412375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7966f62e1b2047a0a95d3b48a49d925f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 100/159] loss=6.3304, ppl=561.3720, gnorm=0.3461, throughput=20.05K wps, wc=486.77K\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef06fa2f049e4b09a631d072be3a719f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] valid Loss=5.7555, valid ppl=315.9161, valid bleu=0.12\n",
      "Save best parameters to gnmt_en_de_512.params\n",
      "Learning rate change to 0.0005\n"
     ]
    }
   ],
   "source": [
    "hparams.epochs = 1\n",
    "\n",
    "nmt.utils.train(\n",
    "    gnmt_model,\n",
    "    wmt_train_data_loader,\n",
    "    wmt_test_data_loader,\n",
    "    wmt_loss_function,\n",
    "    trainer,\n",
    "    gnmt_translator,\n",
    "    wmt_tgt_vocab,\n",
    "    wmt_test_tgt_sentences,\n",
    "    wmt_detokenizer,\n",
    "    hparams.file_name,\n",
    "    hparams,\n",
    "    ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba712ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Qualitative Evaluation: Translating from English to German:\")\n",
    "\n",
    "sample_src_seq = \"I love reading technical books from Packt.\"\n",
    "print(\"[\\'\" + sample_src_seq + \"\\']\")\n",
    "\n",
    "sample_tgt_seq = nmt.utils.translate(\n",
    "    transformer_translator,\n",
    "    sample_src_seq,\n",
    "    wmt_src_vocab,\n",
    "    wmt_tgt_vocab,\n",
    "    wmt_detokenizer,\n",
    "    ctx)\n",
    "\n",
    "print(\"The German translation is:\")\n",
    "print(sample_tgt_seq)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
