{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbbe216b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/andreto/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/andreto/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/andreto/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "import gluonnlp as nlp\n",
    "\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import sacremoses\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "# Local Libraries\n",
    "import nmt\n",
    "import dataprocessor\n",
    "import utils\n",
    "import nmt.gnmt_hparams\n",
    "\n",
    "# Seeds for reproducibility\n",
    "np.random.seed(100)\n",
    "random.seed(100)\n",
    "mx.random.seed(10000)\n",
    "\n",
    "# CPU setup\n",
    "# ctx = mx.cpu()\n",
    "# Single GPU setup\n",
    "ctx = mx.gpu(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bac926f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andreto/.local/lib/python3.7/site-packages/gluonnlp/vocab/vocab.py:591: UserWarning: Detected a corrupted index in the deserialize vocabulary. For versions before GluonNLP v0.7 the index is corrupted by specifying the same token for different special purposes, for example eos_token == padding_token. Deserializing the vocabulary nevertheless.\n",
      "  'Detected a corrupted index in the deserialize vocabulary. '\n"
     ]
    }
   ],
   "source": [
    "# WMT2016 Dataset (Train and Evaluation)\n",
    "\n",
    "# Dataset Parameters\n",
    "src_lang, tgt_lang = \"en\", \"de\"\n",
    "\n",
    "wmt_train_text_bpe = nlp.data.WMT2016BPE(\"train\", # BPE: cheapest --> cheap@@, est\n",
    "                                         src_lang=src_lang,\n",
    "                                         tgt_lang=tgt_lang)\n",
    "\n",
    "wmt_train_text     = nlp.data.WMT2016(\"train\",\n",
    "                                      src_lang=src_lang,\n",
    "                                      tgt_lang=tgt_lang)\n",
    "\n",
    "wmt_test_text_bpe  = nlp.data.WMT2016BPE(\"newstest2016\", # BPE: cheapest --> cheap@@, est\n",
    "                                         src_lang=src_lang,\n",
    "                                         tgt_lang=tgt_lang)\n",
    "\n",
    "wmt_test_text      = nlp.data.WMT2016(\"newstest2016\",\n",
    "                                     src_lang=src_lang,\n",
    "                                     tgt_lang=tgt_lang)\n",
    "\n",
    "wmt_src_vocab = wmt_train_text_bpe.src_vocab\n",
    "wmt_tgt_vocab = wmt_train_text_bpe.tgt_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aa0bda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing datasets\n",
    "# Filtering training data to a maximum number of samples,\n",
    "# so that training can be handled in a reasonable time (~8 hrs)\n",
    "# in single GPU setups\n",
    "max_samples = int(1e4)\n",
    "wmt_train_text_bpe = mx.gluon.data.SimpleDataset([wmt_train_text_bpe[i] for i in range(max_samples)])\n",
    "wmt_train_text     = mx.gluon.data.SimpleDataset([wmt_train_text[i] for i in range(max_samples)])\n",
    "wmt_test_text_bpe  = mx.gluon.data.SimpleDataset(wmt_test_text_bpe)\n",
    "wmt_test_text      = mx.gluon.data.SimpleDataset(wmt_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1f77292",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By the end of the day, there would be one more death: Lamb took his own life as police closed in on him.\n",
      "Bis zum Ende des Tages gab es einen weiteren Tod: Lamm nahm sich das Leben, als die Polizei ihn einkesselte.\n"
     ]
    }
   ],
   "source": [
    "# Dataset example (human-readable): English and German\n",
    "print(wmt_test_text[16][0])\n",
    "print(wmt_test_text[16][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "237ae7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample target sentence:\n",
      "Bis zum Ende des Tages gab es einen weiteren Tod: Lamm nahm sich das Leben, als die Polizei ihn einkesselte.\n"
     ]
    }
   ],
   "source": [
    "# Retrieve (split) translated sequences (target)\n",
    "wmt_train_tgt_sentences = wmt_train_text.transform(lambda src, tgt: tgt)\n",
    "wmt_test_tgt_sentences  = wmt_test_text.transform(lambda src, tgt: tgt)\n",
    "print(\"Sample target sentence:\")\n",
    "print(wmt_test_tgt_sentences[16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd74a96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2083 28753 16760 23875 28753 15230    28 28783 31223 12931 24017 23247\n",
      " 15259   569  5971 12813 29083 20097 24348 22312 12290 24829 14439 20585\n",
      " 24004 20061    62     3]\n",
      "[    2  1897 31601  3259 15535  9414 18646 17382 16407 30851  9629   569\n",
      "  5971 22642 23439 27119 15199  6041    28 11681 15681  7670 20454 16394\n",
      " 21488 26868 28535    62     3]\n"
     ]
    }
   ],
   "source": [
    "# Dataset processing: clipping, tokenizing, indexing and adding of EOS (src/tgt) / BOS (tgt)\n",
    "wmt_transform_fn = dataprocessor.TrainValDataTransform(wmt_src_vocab, wmt_tgt_vocab)\n",
    "\n",
    "wmt_train_processed = wmt_train_text_bpe.transform(wmt_transform_fn, lazy=False)\n",
    "wmt_test_processed  = wmt_test_text_bpe.transform(wmt_transform_fn, lazy=False)\n",
    "\n",
    "wmt_train_text_with_len = wmt_train_processed.transform(nmt.utils.get_length_index_fn(), lazy=False)\n",
    "wmt_test_text_with_len  = wmt_test_processed.transform(nmt.utils.get_length_index_fn(), lazy=False)\n",
    "\n",
    "print(wmt_test_text_with_len[16][0])\n",
    "print(wmt_test_text_with_len[16][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b817d057",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andreto/.local/lib/python3.7/site-packages/gluonnlp/data/batchify/batchify.py:235: UserWarning: Padding value is not given and will be set automatically to 0 in data.batchify.Pad(). Please check whether this is intended (e.g. value of padding index in the vocabulary).\n",
      "  'Padding value is not given and will be set automatically to 0 '\n"
     ]
    }
   ],
   "source": [
    "# Batcher\n",
    "wmt_batchify_fn = nlp.data.batchify.Tuple(\n",
    "    nlp.data.batchify.Pad(),                   # Source Token IDs\n",
    "    nlp.data.batchify.Pad(),                   # Target Token IDs\n",
    "    nlp.data.batchify.Stack(dtype='float32'),  # Source Sequence Length\n",
    "    nlp.data.batchify.Stack(dtype='float32'),  # Target Sequence Length\n",
    "    nlp.data.batchify.Stack())                 # Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d10c420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "hparams = nmt.gnmt_hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f3c4dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FixedBucketSampler:\n",
      "  sample_num=10000, batch_num=159\n",
      "  key=[(21, 25), (39, 44), (57, 63), (75, 82), (93, 101)]\n",
      "  cnt=[3409, 3991, 1797, 622, 181]\n",
      "  batch_size=[64, 64, 64, 64, 64]\n",
      "FixedBucketSampler:\n",
      "  sample_num=2999, batch_num=50\n",
      "  key=[(23, 26), (43, 48), (63, 70), (83, 92), (103, 114)]\n",
      "  cnt=[1417, 1191, 329, 56, 6]\n",
      "  batch_size=[64, 64, 64, 64, 64]\n"
     ]
    }
   ],
   "source": [
    "# Samplers\n",
    "wmt_train_batch_sampler = nlp.data.FixedBucketSampler(\n",
    "    lengths=wmt_train_text_with_len.transform(lambda src, tgt, src_len, tgt_len, idx: (src_len, tgt_len)),\n",
    "    num_buckets=hparams.num_buckets,\n",
    "    batch_size=hparams.batch_size)\n",
    "print(wmt_train_batch_sampler.stats())\n",
    "\n",
    "wmt_test_batch_sampler = nlp.data.FixedBucketSampler(\n",
    "    lengths=wmt_test_text_with_len.transform(lambda src, tgt, src_len, tgt_len, idx: (src_len, tgt_len)),\n",
    "    num_buckets=hparams.num_buckets,\n",
    "    batch_size=hparams.test_batch_size)\n",
    "print(wmt_test_batch_sampler.stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec987736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training batches: 159\n",
      "Number of testing batches: 50\n"
     ]
    }
   ],
   "source": [
    "# DataLoaders\n",
    "wmt_train_data_loader = mx.gluon.data.DataLoader(\n",
    "    wmt_train_text_with_len,\n",
    "    batch_sampler=wmt_train_batch_sampler,\n",
    "    batchify_fn=wmt_batchify_fn,\n",
    "    num_workers=8)\n",
    "print('Number of training batches:', len(wmt_train_data_loader))\n",
    "\n",
    "wmt_test_data_loader = mx.gluon.data.DataLoader(\n",
    "    wmt_test_text_with_len,\n",
    "    batch_sampler=wmt_test_batch_sampler,\n",
    "    batchify_fn=wmt_batchify_fn,\n",
    "    num_workers=8)\n",
    "print('Number of testing batches:', len(wmt_test_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af12498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "encoder, decoder, one_step_ahead_decoder = nmt.gnmt.get_gnmt_encoder_decoder(\n",
    "    hidden_size=hparams.num_hidden,\n",
    "    dropout=hparams.dropout,\n",
    "    num_layers=hparams.num_layers,\n",
    "    num_bi_layers=hparams.num_bi_layers)\n",
    "\n",
    "gnmt_model = nlp.model.translation.NMTModel(\n",
    "    src_vocab=wmt_src_vocab,\n",
    "    tgt_vocab=wmt_tgt_vocab,\n",
    "    encoder=encoder,\n",
    "    decoder=decoder,\n",
    "    one_step_ahead_decoder=one_step_ahead_decoder,\n",
    "    embed_size=hparams.num_hidden,\n",
    "    prefix='gnmt_')\n",
    "\n",
    "gnmt_model.initialize(init=mx.init.Uniform(0.1), ctx=ctx)\n",
    "static_alloc = True\n",
    "gnmt_model.hybridize(static_alloc=static_alloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d4dbb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use beam_size=10, alpha=1.0, K=5\n"
     ]
    }
   ],
   "source": [
    "# For Evaluation\n",
    "scorer=nlp.model.BeamSearchScorer(\n",
    "    alpha=hparams.lp_alpha,\n",
    "    K=hparams.lp_k)\n",
    "\n",
    "gnmt_translator = nmt.translation.BeamSearchTranslator(\n",
    "    model=gnmt_model,\n",
    "    beam_size=hparams.beam_size,\n",
    "    scorer=scorer,\n",
    "    max_length=hparams.max_length)\n",
    "\n",
    "print(\"Use beam_size={}, alpha={}, K={}\".format(hparams.beam_size, hparams.lp_alpha, hparams.lp_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84aaecde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe81c79f787e48418abc23da3596536b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extension horovod.torch has not been built: /home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/site-packages/horovod/torch/mpi_lib/_mpi_lib.cpython-37m-x86_64-linux-gnu.so not found\n",
      "If this is not expected, reinstall Horovod with HOROVOD_WITH_PYTORCH=1 to debug the build error.\n",
      "Warning! MPI libs are missing, but python applications are still avaiable.\n",
      "[2022-06-11 12:26:32.704 ip-172-31-28-47:26385 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2022-06-11 12:26:32.736 ip-172-31-28-47:26385 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "WMT16 EN-DE GNMT model test loss: 7.71; test bleu score: 0.00; time cost 161.43s\n"
     ]
    }
   ],
   "source": [
    "# Evaluation (Baseline)\n",
    "eval_start_time = time.time()\n",
    "wmt_loss_function = nlp.loss.MaskedSoftmaxCELoss()\n",
    "wmt_loss_function.hybridize()\n",
    "wmt_detokenizer = nlp.data.SacreMosesDetokenizer()\n",
    "\n",
    "gnmt_test_loss, gnmt_test_translation_out = nmt.utils.evaluate(\n",
    "    gnmt_model,\n",
    "    wmt_test_data_loader,\n",
    "    wmt_loss_function,\n",
    "    gnmt_translator,\n",
    "    wmt_tgt_vocab,\n",
    "    wmt_detokenizer,\n",
    "    ctx)\n",
    "\n",
    "gnmt_test_bleu_score, _, _, _, _ = nmt.bleu.compute_bleu(\n",
    "    [wmt_test_tgt_sentences],\n",
    "    gnmt_test_translation_out,\n",
    "    tokenized=False,\n",
    "    tokenizer=hparams.bleu,\n",
    "    split_compound_word=False,\n",
    "    bpe=False)\n",
    "\n",
    "print('WMT16 EN-DE GNMT model test loss: %.2f; test bleu score: %.2f; time cost %.2fs' %(gnmt_test_loss, gnmt_test_bleu_score * 100, (time.time() - eval_start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8b75217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "trainer = mx.gluon.Trainer(gnmt_model.collect_params(), 'adam', {'learning_rate': hparams.lr})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59d38bb4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd7ce69f342145e68b43d2c05e602663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80ca24bb98b24a8091cf7aff03129f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 100/159] loss=8.4424, ppl=4639.7932, gnorm=1.0026, throughput=8.14K wps, wc=486.77K\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f6d0bbc1f1a4b39acab40aa5d34aa70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] valid Loss=6.2321, valid ppl=508.8374, valid bleu=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c2a843faea94134910b194f85fdedcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1 Batch 100/159] loss=7.1713, ppl=1301.5054, gnorm=0.8104, throughput=7.94K wps, wc=486.77K\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c331866db004dc4aadba70b808df64b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] valid Loss=6.0615, valid ppl=429.0079, valid bleu=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7830af3c5b6946f1b7fdd4d293181aac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2 Batch 100/159] loss=7.0036, ppl=1100.6375, gnorm=0.6355, throughput=8.08K wps, wc=486.77K\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82515e149d4e4094bb5b9997dfe1e00e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] valid Loss=6.0291, valid ppl=415.3392, valid bleu=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e29ad6f64f7c4995a90c12178ec50f74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3 Batch 100/159] loss=6.8593, ppl=952.7396, gnorm=0.6081, throughput=7.95K wps, wc=486.77K\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42d765ba276041fcba167caca7877210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] valid Loss=5.9389, valid ppl=379.5139, valid bleu=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f91e0dd421ca4f3f81aefa3b51c645e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4 Batch 100/159] loss=6.6325, ppl=759.3499, gnorm=0.7096, throughput=8.03K wps, wc=486.77K\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9434b4799174193a9e15fd85d0cd4e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] valid Loss=5.8941, valid ppl=362.8813, valid bleu=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e58f54cc79e415c9d990f4728b8cc17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5 Batch 100/159] loss=6.4951, ppl=661.8865, gnorm=0.8268, throughput=7.98K wps, wc=486.77K\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c723b6dbcd76403e972ad24fe31133e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] valid Loss=5.8570, valid ppl=349.6849, valid bleu=0.00\n",
      "Learning rate change to 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "932c54802c9140a7b2aba97f0629cea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6 Batch 100/159] loss=6.3812, ppl=590.6293, gnorm=0.7062, throughput=7.89K wps, wc=486.77K\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2567150238d4253bf915bd239e051cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] valid Loss=5.8464, valid ppl=345.9941, valid bleu=0.00\n",
      "Learning rate change to 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "226321cbbf124b2e87f2288d20788779",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7 Batch 100/159] loss=6.2929, ppl=540.6979, gnorm=0.7863, throughput=8.07K wps, wc=486.77K\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "524bf9ad21ed48079e086bc4d4d4da7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] valid Loss=5.8328, valid ppl=341.3225, valid bleu=0.00\n",
      "Learning rate change to 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31ac390ef0d7470d8738421702f3ec70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8 Batch 100/159] loss=6.2194, ppl=502.3839, gnorm=0.7103, throughput=8.04K wps, wc=486.77K\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdaa180869e54057819a38211024d0b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] valid Loss=5.8446, valid ppl=345.3778, valid bleu=0.00\n",
      "Learning rate change to 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0efd813f68084f9594f4a91f3c3830a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9 Batch 100/159] loss=6.1489, ppl=468.2164, gnorm=0.8006, throughput=8.13K wps, wc=486.77K\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfccd9af8c5542eca39fb0d1a43acfb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] valid Loss=5.8319, valid ppl=341.0082, valid bleu=0.00\n",
      "Learning rate change to 0.0001\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "encoder, decoder, one_step_ahead_decoder = nmt.gnmt.get_gnmt_encoder_decoder(\n",
    "    hidden_size=hparams.num_hidden,\n",
    "    dropout=hparams.dropout,\n",
    "    num_layers=hparams.num_layers,\n",
    "    num_bi_layers=hparams.num_bi_layers)\n",
    "\n",
    "gnmt_model = nlp.model.translation.NMTModel(\n",
    "    src_vocab=wmt_src_vocab,\n",
    "    tgt_vocab=wmt_tgt_vocab,\n",
    "    encoder=encoder,\n",
    "    decoder=decoder,\n",
    "    one_step_ahead_decoder=one_step_ahead_decoder,\n",
    "    embed_size=hparams.num_hidden,\n",
    "    prefix='gnmt_')\n",
    "\n",
    "gnmt_model.initialize(init=mx.init.Uniform(0.1), ctx=ctx)\n",
    "\n",
    "hparams.epochs = 10\n",
    "hparams.lr = 0.0001\n",
    "hparams.clip = 50\n",
    "hparams.lr_update_factor = 1.0\n",
    "\n",
    "# Training\n",
    "trainer = mx.gluon.Trainer(gnmt_model.collect_params(), 'adam', {'learning_rate': hparams.lr})\n",
    "\n",
    "test_loss, test_translation_out = nmt.utils.train(\n",
    "    gnmt_model,\n",
    "    wmt_train_data_loader,\n",
    "    wmt_test_data_loader,\n",
    "    wmt_loss_function,\n",
    "    trainer,\n",
    "    wmt_tgt_vocab,\n",
    "    wmt_test_tgt_sentences,\n",
    "    wmt_detokenizer,\n",
    "    hparams.file_name,\n",
    "    hparams,\n",
    "    ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba712ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Qualitative Evaluation: Translating from English to German:\")\n",
    "\n",
    "sample_src_seq = \"I love reading technical books.\"\n",
    "print(\"[\\'\" + sample_src_seq + \"\\']\")\n",
    "\n",
    "gnmt_translator = nmt.translation.BeamSearchTranslator(\n",
    "    model=gnmt_model,\n",
    "    beam_size=hparams.beam_size,\n",
    "    scorer=scorer,\n",
    "    max_length=hparams.max_length)\n",
    "\n",
    "sample_tgt_seq = nmt.utils.translate(\n",
    "    gnmt_translator,\n",
    "    sample_src_seq,\n",
    "    wmt_src_vocab,\n",
    "    wmt_tgt_vocab,\n",
    "    wmt_detokenizer,\n",
    "    ctx)\n",
    "\n",
    "print(\"The German translation is:\")\n",
    "print(sample_tgt_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9dad57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
