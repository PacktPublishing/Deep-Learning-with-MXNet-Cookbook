{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbe216b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import gluonnlp as nlp\n",
    "\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "import io\n",
    "import logging\n",
    "import numpy as np\n",
    "import sacremoses\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Local Libraries\n",
    "import nmt\n",
    "import dataprocessor\n",
    "import utils\n",
    "import nmt.gnmt_hparams\n",
    "\n",
    "# Seeds for reproducibility\n",
    "np.random.seed(100)\n",
    "random.seed(100)\n",
    "mx.random.seed(10000)\n",
    "\n",
    "# CPU setup\n",
    "# ctx = mx.cpu()\n",
    "# Single GPU setup\n",
    "ctx = mx.gpu(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f17f9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Parameters\n",
    "src_lang, tgt_lang = 'en', 'de'\n",
    "# No limit on sentences length\n",
    "src_max_len, tgt_max_len = -1, -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bac926f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading /home/andreto/.mxnet/datasets/wmt2016/de_en/wmt2016bpe_de_en-8cf0dbf6.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/wmt2016/wmt2016bpe_de_en-8cf0dbf6.zip...\n",
      "Downloading /home/andreto/.mxnet/datasets/wmt2016/de_en/wmt2016_de_en-88767407.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/wmt2016/wmt2016_de_en-88767407.zip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andreto/.local/lib/python3.7/site-packages/gluonnlp/vocab/vocab.py:591: UserWarning: Detected a corrupted index in the deserialize vocabulary. For versions before GluonNLP v0.7 the index is corrupted by specifying the same token for different special purposes, for example eos_token == padding_token. Deserializing the vocabulary nevertheless.\n",
      "  'Detected a corrupted index in the deserialize vocabulary. '\n"
     ]
    }
   ],
   "source": [
    "# WMT2016 Dataset (Train and Evaluation)\n",
    "wmt_train_text_bpe = nlp.data.WMT2016BPE(\"train\", # BPE: cheapest --> cheap@@, est\n",
    "                                         src_lang=src_lang,\n",
    "                                         tgt_lang=tgt_lang)\n",
    "\n",
    "wmt_train_text     = nlp.data.WMT2016(\"train\",\n",
    "                                      src_lang=src_lang,\n",
    "                                      tgt_lang=tgt_lang)\n",
    "\n",
    "wmt_test_text_bpe  = nlp.data.WMT2016BPE(\"newstest2016\", # BPE: cheapest --> cheap@@, est\n",
    "                                         src_lang=src_lang,\n",
    "                                         tgt_lang=tgt_lang)\n",
    "\n",
    "wmt_test_text      = nlp.data.WMT2016(\"newstest2016\",\n",
    "                                     src_lang=src_lang,\n",
    "                                     tgt_lang=tgt_lang)\n",
    "\n",
    "wmt_src_vocab = wmt_train_text_bpe.src_vocab\n",
    "wmt_tgt_vocab = wmt_train_text_bpe.tgt_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6aa0bda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing datasets\n",
    "wmt_train_text_bpe = mx.gluon.data.SimpleDataset(wmt_train_text_bpe)\n",
    "wmt_train_text     = mx.gluon.data.SimpleDataset(wmt_train_text)\n",
    "wmt_test_text_bpe  = mx.gluon.data.SimpleDataset(wmt_test_text_bpe)\n",
    "wmt_test_text      = mx.gluon.data.SimpleDataset(wmt_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1f77292",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By the end of the day, there would be one more death: Lamb took his own life as police closed in on him.\n",
      "Bis zum Ende des Tages gab es einen weiteren Tod: Lamm nahm sich das Leben, als die Polizei ihn einkesselte.\n"
     ]
    }
   ],
   "source": [
    "# Dataset example (human-readable): English and German\n",
    "print(wmt_test_text[16][0])\n",
    "print(wmt_test_text[16][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "237ae7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample target sentence:\n",
      "Bis zum Ende des Tages gab es einen weiteren Tod: Lamm nahm sich das Leben, als die Polizei ihn einkesselte.\n"
     ]
    }
   ],
   "source": [
    "# Retrieve (split) translated sequences (target)\n",
    "wmt_train_tgt_sentences = wmt_train_text.transform(lambda src, tgt: tgt)\n",
    "wmt_test_tgt_sentences  = wmt_test_text.transform(lambda src, tgt: tgt)\n",
    "print(\"Sample target sentence:\")\n",
    "print(wmt_test_tgt_sentences[16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd74a96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2083 28753 16760 23875 28753 15230    28 28783 31223 12931 24017 23247\n",
      " 15259   569  5971 12813 29083 20097 24348 22312 12290 24829 14439 20585\n",
      " 24004 20061    62     3]\n",
      "[    2  1897 31601  3259 15535  9414 18646 17382 16407 30851  9629   569\n",
      "  5971 22642 23439 27119 15199  6041    28 11681 15681  7670 20454 16394\n",
      " 21488 26868 28535    62     3]\n"
     ]
    }
   ],
   "source": [
    "# Dataset processing: clipping, tokenizing, indexing and adding of EOS (src/tgt) / BOS (tgt)\n",
    "wmt_transform_fn = dataprocessor.TrainValDataTransform(wmt_src_vocab, wmt_tgt_vocab)\n",
    "\n",
    "wmt_train_processed = wmt_train_text_bpe.transform(wmt_transform_fn, lazy=False)\n",
    "wmt_test_processed  = wmt_test_text_bpe.transform(wmt_transform_fn, lazy=False)\n",
    "\n",
    "wmt_train_text_with_len = wmt_train_processed.transform(nmt.utils.get_length_index_fn(), lazy=False)\n",
    "wmt_test_text_with_len  = wmt_test_processed.transform(nmt.utils.get_length_index_fn(), lazy=False)\n",
    "\n",
    "print(wmt_test_text_with_len[16][0])\n",
    "print(wmt_test_text_with_len[16][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b817d057",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andreto/.local/lib/python3.7/site-packages/gluonnlp/data/batchify/batchify.py:235: UserWarning: Padding value is not given and will be set automatically to 0 in data.batchify.Pad(). Please check whether this is intended (e.g. value of padding index in the vocabulary).\n",
      "  'Padding value is not given and will be set automatically to 0 '\n"
     ]
    }
   ],
   "source": [
    "# Batcher\n",
    "wmt_batchify_fn = nlp.data.batchify.Tuple(\n",
    "    nlp.data.batchify.Pad(),                   # Source Token IDs\n",
    "    nlp.data.batchify.Pad(),                   # Target Token IDs\n",
    "    nlp.data.batchify.Stack(dtype='float32'),  # Source Sequence Length\n",
    "    nlp.data.batchify.Stack(dtype='float32'),  # Target Sequence Length\n",
    "    nlp.data.batchify.Stack())                 # Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d10c420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "hparams = nmt.gnmt_hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f3c4dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FixedBucketSampler:\n",
      "  sample_num=4500966, batch_num=35166\n",
      "  key=[(101, 71), (197, 138), (293, 205), (389, 272), (485, 339)]\n",
      "  cnt=[4376388, 123496, 948, 114, 20]\n",
      "  batch_size=[128, 128, 128, 128, 128]\n",
      "FixedBucketSampler:\n",
      "  sample_num=2999, batch_num=97\n",
      "  key=[(23, 26), (43, 48), (63, 70), (83, 92), (103, 114)]\n",
      "  cnt=[1417, 1191, 329, 56, 6]\n",
      "  batch_size=[32, 32, 32, 32, 32]\n"
     ]
    }
   ],
   "source": [
    "# Samplers\n",
    "wmt_train_batch_sampler = nlp.data.FixedBucketSampler(\n",
    "    lengths=wmt_train_text_with_len.transform(lambda src, tgt, src_len, tgt_len, idx: (src_len, tgt_len)),\n",
    "    num_buckets=hparams.num_buckets,\n",
    "    batch_size=hparams.batch_size)\n",
    "print(wmt_train_batch_sampler.stats())\n",
    "\n",
    "wmt_test_batch_sampler = nlp.data.FixedBucketSampler(\n",
    "    lengths=wmt_test_text_with_len.transform(lambda src, tgt, src_len, tgt_len, idx: (src_len, tgt_len)),\n",
    "    num_buckets=hparams.num_buckets,\n",
    "    batch_size=hparams.test_batch_size)\n",
    "print(wmt_test_batch_sampler.stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec987736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training batches: 35166\n",
      "Number of testing batches: 97\n"
     ]
    }
   ],
   "source": [
    "# DataLoaders\n",
    "wmt_train_data_loader = mx.gluon.data.DataLoader(\n",
    "    wmt_train_text_with_len,\n",
    "    batch_sampler=wmt_train_batch_sampler,\n",
    "    batchify_fn=wmt_batchify_fn,\n",
    "    num_workers=8)\n",
    "print('Number of training batches:', len(wmt_train_data_loader))\n",
    "\n",
    "wmt_test_data_loader = mx.gluon.data.DataLoader(\n",
    "    wmt_test_text_with_len,\n",
    "    batch_sampler=wmt_test_batch_sampler,\n",
    "    batchify_fn=wmt_batchify_fn,\n",
    "    num_workers=8)\n",
    "print('Number of testing batches:', len(wmt_test_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af12498b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nmt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fc7e96aa8481>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m encoder, decoder, one_step_ahead_decoder = nmt.gnmt.get_gnmt_encoder_decoder(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnum_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nmt' is not defined"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "encoder, decoder, one_step_ahead_decoder = nmt.gnmt.get_gnmt_encoder_decoder(\n",
    "    hidden_size=hparams.num_hidden,\n",
    "    dropout=hparams.dropout,\n",
    "    num_layers=hparams.num_layers,\n",
    "    num_bi_layers=hparams.num_bi_layers)\n",
    "\n",
    "gnmt_model = nlp.model.translation.NMTModel(\n",
    "    src_vocab=wmt_src_vocab,\n",
    "    tgt_vocab=wmt_tgt_vocab,\n",
    "    encoder=encoder,\n",
    "    decoder=decoder,\n",
    "    one_step_ahead_decoder=one_step_ahead_decoder,\n",
    "    embed_size=hparams.num_hidden,\n",
    "    prefix='gnmt_')\n",
    "\n",
    "gnmt_model.initialize(init=mx.init.Uniform(0.1), ctx=ctx)\n",
    "static_alloc = True\n",
    "gnmt_model.hybridize(static_alloc=static_alloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d4dbb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use beam_size=10, alpha=1.0, K=5\n"
     ]
    }
   ],
   "source": [
    "scorer=nlp.model.BeamSearchScorer(\n",
    "    alpha=hparams.lp_alpha,\n",
    "    K=hparams.lp_k)\n",
    "\n",
    "gnmt_translator = nmt.translation.BeamSearchTranslator(\n",
    "    model=gnmt_model,\n",
    "    beam_size=hparams.beam_size,\n",
    "    scorer=scorer,\n",
    "    max_length=tgt_max_len + 100)\n",
    "\n",
    "print(\"Use beam_size={}, alpha={}, K={}\".format(hparams.beam_size, hparams.lp_alpha, hparams.lp_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84aaecde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [01:55<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WMT16 EN-DE SOTA model test loss: 7.75; test bleu score: 0.00; time cost 122.16s\n"
     ]
    }
   ],
   "source": [
    "# Evaluation (Baseline)\n",
    "eval_start_time = time.time()\n",
    "wmt_loss_function = nlp.loss.MaskedSoftmaxCELoss()\n",
    "wmt_loss_function.hybridize()\n",
    "wmt_detokenizer = nlp.data.SacreMosesDetokenizer()\n",
    "\n",
    "gnmt_test_loss, gnmt_test_translation_out = nmt.utils.evaluate(\n",
    "    gnmt_model,\n",
    "    wmt_test_data_loader,\n",
    "    wmt_loss_function,\n",
    "    gnmt_translator,\n",
    "    wmt_tgt_vocab,\n",
    "    wmt_detokenizer,\n",
    "    ctx)\n",
    "\n",
    "gnmt_test_bleu_score, _, _, _, _ = nmt.bleu.compute_bleu(\n",
    "    [wmt_test_tgt_sentences],\n",
    "    gnmt_test_translation_out,\n",
    "    tokenized=False,\n",
    "    tokenizer=hparams.bleu,\n",
    "    split_compound_word=False,\n",
    "    bpe=False)\n",
    "\n",
    "print('WMT16 EN-DE SOTA model test loss: %.2f; test bleu score: %.2f; time cost %.2fs' %(gnmt_test_loss, gnmt_test_bleu_score * 100, (time.time() - eval_start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8b75217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "trainer = mx.gluon.Trainer(gnmt_model.collect_params(), 'adam', {'learning_rate': hparams.lr})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "59d38bb4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/35166 [00:12<?, ?it/s]\u001b[A\n",
      "  0%|          | 0/1 [00:12<?, ?it/s]\n"
     ]
    },
    {
     "ename": "MXNetError",
     "evalue": "Traceback (most recent call last):\n  File \"../src/storage/./pooled_storage_manager.h\", line 161\nMXNetError: cudaMalloc retry failed: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMXNetError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-16ac600c9c93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mhparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     ctx)\n\u001b[0m",
      "\u001b[0;32m~/code/packt/Deep-Learning-with-MXNet-Cookbook/ch06/nmt/utils.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_data_loader, valid_data_loader, loss_function, trainer, translator, tgt_vocab, detokenizer, save_dir, hparams, ctx)\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_valid_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_valid_length\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_valid_length\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtgt_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtgt_valid_length\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/mxnet_p37/gpu_cuda11.0/lib/python3.7/site-packages/mxnet/gluon/utils.py\u001b[0m in \u001b[0;36mclip_global_norm\u001b[0;34m(arrays, max_norm, check_isfinite)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mndarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcheck_isfinite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m             warnings.warn(\n\u001b[1;32m    152\u001b[0m                 UserWarning('nan or inf is detected. '\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/mxnet_p37/gpu_cuda11.0/lib/python3.7/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masscalar\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2583\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The current array is not a scalar\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2585\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2586\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2587\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/mxnet_p37/gpu_cuda11.0/lib/python3.7/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2564\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2565\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2566\u001b[0;31m             ctypes.c_size_t(data.size)))\n\u001b[0m\u001b[1;32m   2567\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/mxnet_p37/gpu_cuda11.0/lib/python3.7/site-packages/mxnet/base.py\u001b[0m in \u001b[0;36mcheck_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \"\"\"\n\u001b[1;32m    245\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mget_last_ffi_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMXNetError\u001b[0m: Traceback (most recent call last):\n  File \"../src/storage/./pooled_storage_manager.h\", line 161\nMXNetError: cudaMalloc retry failed: out of memory"
     ]
    }
   ],
   "source": [
    "nmt.utils.train(\n",
    "    gnmt_model,\n",
    "    wmt_train_data_loader,\n",
    "    wmt_test_data_loader,\n",
    "    wmt_loss_function,\n",
    "    trainer,\n",
    "    gnmt_translator,\n",
    "    wmt_tgt_vocab,\n",
    "    wmt_detokenizer,\n",
    "    hparams.save_dir,\n",
    "    hparams,\n",
    "    ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb827da3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
