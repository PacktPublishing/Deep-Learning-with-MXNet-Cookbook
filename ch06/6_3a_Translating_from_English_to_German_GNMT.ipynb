{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fbbe216b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import gluonnlp as nlp\n",
    "\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "import io\n",
    "import logging\n",
    "import numpy as np\n",
    "import sacremoses\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Local Libraries\n",
    "import nmt\n",
    "import dataprocessor\n",
    "import utils\n",
    "import nmt.gnmt_hparams\n",
    "\n",
    "# Seeds for reproducibility\n",
    "np.random.seed(100)\n",
    "random.seed(100)\n",
    "mx.random.seed(10000)\n",
    "\n",
    "ctx = mx.gpu(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f17f9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Parameters\n",
    "dataset = 'WMT2014'\n",
    "src_lang, tgt_lang = 'en', 'de'\n",
    "# No limit on sentences length\n",
    "src_max_len, tgt_max_len = -1, -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bac926f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andreto/.local/lib/python3.7/site-packages/gluonnlp/vocab/vocab.py:591: UserWarning: Detected a corrupted index in the deserialize vocabulary. For versions before GluonNLP v0.7 the index is corrupted by specifying the same token for different special purposes, for example eos_token == padding_token. Deserializing the vocabulary nevertheless.\n",
      "  'Detected a corrupted index in the deserialize vocabulary. '\n"
     ]
    }
   ],
   "source": [
    "# WMT2016 Dataset (Train and Evaluation)\n",
    "wmt_train_text_bpe = nlp.data.WMT2016BPE(\"train\", # BPE: cheapest --> cheap@@, est\n",
    "                                         src_lang=src_lang,\n",
    "                                         tgt_lang=tgt_lang)\n",
    "\n",
    "wmt_train_text     = nlp.data.WMT2016(\"train\",\n",
    "                                      src_lang=src_lang,\n",
    "                                      tgt_lang=tgt_lang)\n",
    "\n",
    "wmt_test_text_bpe  = nlp.data.WMT2016BPE(\"newstest2016\", # BPE: cheapest --> cheap@@, est\n",
    "                                         src_lang=src_lang,\n",
    "                                         tgt_lang=tgt_lang)\n",
    "\n",
    "wmt_test_text      = nlp.data.WMT2016(\"newstest2016\",\n",
    "                                     src_lang=src_lang,\n",
    "                                     tgt_lang=tgt_lang)\n",
    "\n",
    "wmt_src_vocab = wmt_train_text_bpe.src_vocab\n",
    "wmt_tgt_vocab = wmt_train_text_bpe.tgt_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6aa0bda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing datasets\n",
    "wmt_train_text_bpe = mx.gluon.data.SimpleDataset(wmt_train_text_bpe)\n",
    "wmt_train_text     = mx.gluon.data.SimpleDataset(wmt_train_text)\n",
    "wmt_test_text_bpe  = mx.gluon.data.SimpleDataset(wmt_test_text_bpe)\n",
    "wmt_test_text      = mx.gluon.data.SimpleDataset(wmt_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1f77292",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By the end of the day, there would be one more death: Lamb took his own life as police closed in on him.\n",
      "Bis zum Ende des Tages gab es einen weiteren Tod: Lamm nahm sich das Leben, als die Polizei ihn einkesselte.\n"
     ]
    }
   ],
   "source": [
    "# Dataset example (human-readable): English and German\n",
    "print(wmt_test_text[16][0])\n",
    "print(wmt_test_text[16][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "237ae7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample target sentence:\n",
      "Bis zum Ende des Tages gab es einen weiteren Tod: Lamm nahm sich das Leben, als die Polizei ihn einkesselte.\n"
     ]
    }
   ],
   "source": [
    "# Retrieve (split) translated sequences (target)\n",
    "wmt_train_tgt_sentences = wmt_train_text.transform(lambda src, tgt: tgt)\n",
    "wmt_test_tgt_sentences  = wmt_test_text.transform(lambda src, tgt: tgt)\n",
    "print(\"Sample target sentence:\")\n",
    "print(wmt_test_tgt_sentences[16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd74a96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2083 28753 16760 23875 28753 15230    28 28783 31223 12931 24017 23247\n",
      " 15259   569  5971 12813 29083 20097 24348 22312 12290 24829 14439 20585\n",
      " 24004 20061    62     3]\n",
      "[    2  1897 31601  3259 15535  9414 18646 17382 16407 30851  9629   569\n",
      "  5971 22642 23439 27119 15199  6041    28 11681 15681  7670 20454 16394\n",
      " 21488 26868 28535    62     3]\n"
     ]
    }
   ],
   "source": [
    "# Dataset processing: clipping, tokenizing, indexing and adding of EOS (src/tgt) / BOS (tgt)\n",
    "wmt_transform_fn = dataprocessor.TrainValDataTransform(wmt_src_vocab, wmt_tgt_vocab)\n",
    "\n",
    "wmt_train_processed = wmt_train_text_bpe.transform(wmt_transform_fn, lazy=False)\n",
    "wmt_test_processed  = wmt_test_text_bpe.transform(wmt_transform_fn, lazy=False)\n",
    "\n",
    "wmt_train_text_with_len = wmt_train_processed.transform(nmt.utils.get_length_index_fn(), lazy=False)\n",
    "wmt_test_text_with_len  = wmt_test_processed.transform(nmt.utils.get_length_index_fn(), lazy=False)\n",
    "\n",
    "print(wmt_test_text_with_len[16][0])\n",
    "print(wmt_test_text_with_len[16][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b817d057",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andreto/.local/lib/python3.7/site-packages/gluonnlp/data/batchify/batchify.py:235: UserWarning: Padding value is not given and will be set automatically to 0 in data.batchify.Pad(). Please check whether this is intended (e.g. value of padding index in the vocabulary).\n",
      "  'Padding value is not given and will be set automatically to 0 '\n"
     ]
    }
   ],
   "source": [
    "# Batcher\n",
    "wmt_batchify_fn = nlp.data.batchify.Tuple(\n",
    "    nlp.data.batchify.Pad(),                   # Source Token IDs\n",
    "    nlp.data.batchify.Pad(),                   # Target Token IDs\n",
    "    nlp.data.batchify.Stack(dtype='float32'),  # Source Sequence Length\n",
    "    nlp.data.batchify.Stack(dtype='float32'),  # Target Sequence Length\n",
    "    nlp.data.batchify.Stack())                 # Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d10c420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "hparams = nmt.gnmt_hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f3c4dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FixedBucketSampler:\n",
      "  sample_num=4500966, batch_num=2250484\n",
      "  key=[(163, 115), (324, 227), (485, 339)]\n",
      "  cnt=[4497590, 3303, 73]\n",
      "  batch_size=[2, 2, 2]\n",
      "FixedBucketSampler:\n",
      "  sample_num=2999, batch_num=1501\n",
      "  key=[(37, 42), (70, 78), (103, 114)]\n",
      "  cnt=[2353, 619, 27]\n",
      "  batch_size=[2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "# Samplers\n",
    "wmt_train_batch_sampler = nlp.data.FixedBucketSampler(\n",
    "    lengths=wmt_train_text_with_len.transform(lambda src, tgt, src_len, tgt_len, idx: (src_len, tgt_len)),\n",
    "    num_buckets=hparams.num_buckets,\n",
    "    batch_size=hparams.batch_size)\n",
    "print(wmt_train_batch_sampler.stats())\n",
    "\n",
    "wmt_test_batch_sampler = nlp.data.FixedBucketSampler(\n",
    "    lengths=wmt_test_text_with_len.transform(lambda src, tgt, src_len, tgt_len, idx: (src_len, tgt_len)),\n",
    "    num_buckets=hparams.num_buckets,\n",
    "    batch_size=hparams.test_batch_size)\n",
    "print(wmt_test_batch_sampler.stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec987736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training batches: 2250484\n",
      "Number of testing batches: 1501\n"
     ]
    }
   ],
   "source": [
    "# DataLoaders\n",
    "wmt_train_data_loader = mx.gluon.data.DataLoader(\n",
    "    wmt_train_text_with_len,\n",
    "    batch_sampler=wmt_train_batch_sampler,\n",
    "    batchify_fn=wmt_batchify_fn,\n",
    "    num_workers=8)\n",
    "print('Number of training batches:', len(wmt_train_data_loader))\n",
    "\n",
    "wmt_test_data_loader = mx.gluon.data.DataLoader(\n",
    "    wmt_test_text_with_len,\n",
    "    batch_sampler=wmt_test_batch_sampler,\n",
    "    batchify_fn=wmt_batchify_fn,\n",
    "    num_workers=8)\n",
    "print('Number of testing batches:', len(wmt_test_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af12498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "encoder, decoder, one_step_ahead_decoder = nmt.gnmt.get_gnmt_encoder_decoder(\n",
    "    hidden_size=hparams.num_hidden,\n",
    "    dropout=hparams.dropout,\n",
    "    num_layers=hparams.num_layers,\n",
    "    num_bi_layers=hparams.num_bi_layers)\n",
    "\n",
    "gnmt_model = nlp.model.translation.NMTModel(\n",
    "    src_vocab=wmt_src_vocab,\n",
    "    tgt_vocab=wmt_tgt_vocab,\n",
    "    encoder=encoder,\n",
    "    decoder=decoder,\n",
    "    one_step_ahead_decoder=one_step_ahead_decoder,\n",
    "    embed_size=hparams.num_hidden,\n",
    "    prefix='gnmt_')\n",
    "\n",
    "gnmt_model.initialize(init=mx.init.Uniform(0.1), ctx=ctx)\n",
    "static_alloc = True\n",
    "gnmt_model.hybridize(static_alloc=static_alloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d4dbb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use beam_size=10, alpha=1.0, K=5\n"
     ]
    }
   ],
   "source": [
    "scorer=nlp.model.BeamSearchScorer(\n",
    "    alpha=hparams.lp_alpha,\n",
    "    K=hparams.lp_k)\n",
    "\n",
    "gnmt_translator = nmt.translation.BeamSearchTranslator(\n",
    "    model=gnmt_model,\n",
    "    beam_size=hparams.beam_size,\n",
    "    scorer=scorer,\n",
    "    max_length=tgt_max_len + 100)\n",
    "\n",
    "print(\"Use beam_size={}, alpha={}, K={}\".format(hparams.beam_size, hparams.lp_alpha, hparams.lp_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84aaecde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1501/1501 [11:40<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WMT16 EN-DE SOTA model test loss: 9.06; test bleu score: 0.00; time cost 706.79s\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "eval_start_time = time.time()\n",
    "wmt_loss_function = nlp.loss.MaskedSoftmaxCELoss()\n",
    "wmt_loss_function.hybridize()\n",
    "wmt_detokenizer = nlp.data.SacreMosesDetokenizer()\n",
    "\n",
    "gnmt_test_loss, gnmt_test_translation_out = nmt.utils.evaluate(\n",
    "    gnmt_model,\n",
    "    wmt_test_data_loader,\n",
    "    wmt_test_loss_function,\n",
    "    gnmt_translator,\n",
    "    wmt_tgt_vocab,\n",
    "    wmt_detokenizer,\n",
    "    ctx)\n",
    "\n",
    "gnmt_test_bleu_score, _, _, _, _ = nmt.bleu.compute_bleu(\n",
    "    [wmt_test_tgt_sentences],\n",
    "    gnmt_test_translation_out,\n",
    "    tokenized=False,\n",
    "    tokenizer=hparams.bleu,\n",
    "    split_compound_word=False,\n",
    "    bpe=False)\n",
    "\n",
    "print('WMT16 EN-DE SOTA model test loss: %.2f; test bleu score: %.2f; time cost %.2fs' %(gnmt_test_loss, gnmt_test_bleu_score * 100, (time.time() - eval_start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec8fd4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdaf122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1ef150",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aac02d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e297027f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8e854ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmt.gnmt_hparams.beam_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c6921ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c8b75217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "trainer = mx.gluon.Trainer(gnmt_model.collect_params(), 'adam', {'learning_rate': hparams.lr})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "59d38bb4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/2250484 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1/2250484 [00:00<575:43:48,  1.09it/s]\u001b[A\n",
      "  0%|          | 2/2250484 [00:01<557:02:56,  1.12it/s]\u001b[A\n",
      "  0%|          | 3/2250484 [00:02<544:16:26,  1.15it/s]\u001b[A\n",
      "  0%|          | 4/2250484 [00:03<616:59:25,  1.01it/s]\u001b[A\n",
      "  0%|          | 5/2250484 [00:04<589:11:21,  1.06it/s]\u001b[A\n",
      "  0%|          | 6/2250484 [00:05<576:37:46,  1.08it/s]\u001b[A\n",
      "  0%|          | 7/2250484 [00:06<581:55:56,  1.07it/s]\u001b[A\n",
      "  0%|          | 8/2250484 [00:07<558:54:41,  1.12it/s]\u001b[A\n",
      "  0%|          | 9/2250484 [00:08<569:11:28,  1.10it/s]\u001b[A\n",
      "  0%|          | 10/2250484 [00:09<728:36:31,  1.17s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 10/2250484] loss=6.4054, ppl=605.0831, gnorm=3.6659, throughput=0.79K wps, wc=7.86K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 11/2250484 [00:11<706:14:03,  1.13s/it]\u001b[A\n",
      "  0%|          | 12/2250484 [00:11<641:25:10,  1.03s/it]\u001b[A\n",
      "  0%|          | 13/2250484 [00:12<627:00:11,  1.00s/it]\u001b[A\n",
      "  0%|          | 14/2250484 [00:13<666:49:31,  1.07s/it]\u001b[A\n",
      "  0%|          | 15/2250484 [00:14<571:59:33,  1.09it/s]\u001b[A\n",
      "  0%|          | 16/2250484 [00:15<565:26:34,  1.11it/s]\u001b[A\n",
      "  0%|          | 17/2250484 [00:16<516:20:33,  1.21it/s]\u001b[A\n",
      "  0%|          | 18/2250484 [00:16<502:13:12,  1.24it/s]\u001b[A\n",
      "  0%|          | 19/2250484 [00:18<656:43:13,  1.05s/it]\u001b[A\n",
      "  0%|          | 20/2250484 [00:19<647:04:45,  1.04s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 20/2250484] loss=9.5011, ppl=13375.0654, gnorm=2.5180, throughput=0.81K wps, wc=7.71K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 21/2250484 [00:20<634:29:45,  1.01s/it]\u001b[A\n",
      "  0%|          | 22/2250484 [00:21<576:49:35,  1.08it/s]\u001b[A\n",
      "  0%|          | 23/2250484 [00:21<548:19:09,  1.14it/s]\u001b[A\n",
      "  0%|          | 24/2250484 [00:22<566:49:05,  1.10it/s]\u001b[A\n",
      "  0%|          | 25/2250484 [00:23<504:04:58,  1.24it/s]\u001b[A\n",
      "  0%|          | 26/2250484 [00:24<490:05:28,  1.28it/s]\u001b[A\n",
      "  0%|          | 27/2250484 [00:24<459:24:13,  1.36it/s]\u001b[A\n",
      "  0%|          | 28/2250484 [00:25<442:25:32,  1.41it/s]\u001b[A\n",
      "  0%|          | 29/2250484 [00:26<436:56:30,  1.43it/s]\u001b[A\n",
      "  0%|          | 30/2250484 [00:26<465:20:26,  1.34it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 30/2250484] loss=7.1100, ppl=1224.1965, gnorm=1.7908, throughput=0.93K wps, wc=7.03K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 31/2250484 [00:28<546:15:55,  1.14it/s]\u001b[A\n",
      "  0%|          | 32/2250484 [00:28<507:22:06,  1.23it/s]\u001b[A\n",
      "  0%|          | 33/2250484 [00:30<596:23:22,  1.05it/s]\u001b[A\n",
      "  0%|          | 34/2250484 [00:31<587:52:41,  1.06it/s]\u001b[A\n",
      "  0%|          | 35/2250484 [00:31<538:50:01,  1.16it/s]\u001b[A\n",
      "  0%|          | 36/2250484 [00:34<898:49:12,  1.44s/it]\u001b[A\n",
      "  0%|          | 37/2250484 [00:35<842:09:10,  1.35s/it]\u001b[A\n",
      "  0%|          | 38/2250484 [00:36<697:56:01,  1.12s/it]\u001b[A\n",
      "  0%|          | 39/2250484 [00:36<587:43:24,  1.06it/s]\u001b[A\n",
      "  0%|          | 40/2250484 [00:37<495:15:36,  1.26it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 40/2250484] loss=8.4313, ppl=4588.3653, gnorm=1.8762, throughput=0.67K wps, wc=6.87K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 41/2250484 [00:37<458:12:51,  1.36it/s]\u001b[A\n",
      "  0%|          | 42/2250484 [00:38<407:40:15,  1.53it/s]\u001b[A\n",
      "  0%|          | 43/2250484 [00:38<369:38:03,  1.69it/s]\u001b[A\n",
      "  0%|          | 44/2250484 [00:39<344:43:15,  1.81it/s]\u001b[A\n",
      "  0%|          | 45/2250484 [00:39<350:44:33,  1.78it/s]\u001b[A\n",
      "  0%|          | 46/2250484 [00:40<354:40:23,  1.76it/s]\u001b[A\n",
      "  0%|          | 47/2250484 [00:40<334:42:22,  1.87it/s]\u001b[A\n",
      "  0%|          | 48/2250484 [00:41<320:51:15,  1.95it/s]\u001b[A\n",
      "  0%|          | 49/2250484 [00:41<299:39:40,  2.09it/s]\u001b[A\n",
      "  0%|          | 50/2250484 [00:41<277:30:04,  2.25it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 50/2250484] loss=9.6225, ppl=15101.1743, gnorm=1.5339, throughput=0.93K wps, wc=4.47K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 51/2250484 [00:42<330:36:08,  1.89it/s]\u001b[A\n",
      "  0%|          | 52/2250484 [00:43<289:55:08,  2.16it/s]\u001b[A\n",
      "  0%|          | 53/2250484 [00:43<290:13:50,  2.15it/s]\u001b[A\n",
      "  0%|          | 54/2250484 [00:44<300:15:27,  2.08it/s]\u001b[A\n",
      "  0%|          | 55/2250484 [00:44<302:11:35,  2.07it/s]\u001b[A\n",
      "  0%|          | 56/2250484 [00:45<325:15:21,  1.92it/s]\u001b[A\n",
      "  0%|          | 57/2250484 [00:45<315:23:44,  1.98it/s]\u001b[A\n",
      "  0%|          | 58/2250484 [00:45<287:41:21,  2.17it/s]\u001b[A\n",
      "  0%|          | 59/2250484 [00:46<285:08:20,  2.19it/s]\u001b[A\n",
      "  0%|          | 60/2250484 [00:47<323:48:33,  1.93it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 60/2250484] loss=9.0639, ppl=8637.4898, gnorm=1.3245, throughput=0.82K wps, wc=4.15K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 61/2250484 [00:47<321:18:44,  1.95it/s]\u001b[A\n",
      "  0%|          | 62/2250484 [00:48<325:26:37,  1.92it/s]\u001b[A\n",
      "  0%|          | 63/2250484 [00:48<336:50:05,  1.86it/s]\u001b[A\n",
      "  0%|          | 64/2250484 [00:49<343:41:23,  1.82it/s]\u001b[A\n",
      "  0%|          | 65/2250484 [00:49<323:31:35,  1.93it/s]\u001b[A\n",
      "  0%|          | 66/2250484 [00:50<291:57:44,  2.14it/s]\u001b[A\n",
      "  0%|          | 67/2250484 [00:50<295:26:41,  2.12it/s]\u001b[A\n",
      "  0%|          | 68/2250484 [00:50<276:40:01,  2.26it/s]\u001b[A\n",
      "  0%|          | 69/2250484 [00:51<272:31:05,  2.29it/s]\u001b[A\n",
      "  0%|          | 70/2250484 [00:51<283:12:32,  2.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 70/2250484] loss=8.9813, ppl=7953.0270, gnorm=1.1442, throughput=0.88K wps, wc=4.19K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 71/2250484 [00:52<270:00:17,  2.32it/s]\u001b[A\n",
      "  0%|          | 72/2250484 [00:52<262:42:49,  2.38it/s]\u001b[A\n",
      "  0%|          | 73/2250484 [00:52<252:04:32,  2.48it/s]\u001b[A\n",
      "  0%|          | 74/2250484 [00:53<259:30:53,  2.41it/s]\u001b[A\n",
      "  0%|          | 75/2250484 [00:53<252:32:30,  2.48it/s]\u001b[A\n",
      "  0%|          | 76/2250484 [00:54<276:04:52,  2.26it/s]\u001b[A\n",
      "  0%|          | 77/2250484 [00:54<271:37:10,  2.30it/s]\u001b[A\n",
      "  0%|          | 78/2250484 [00:55<381:42:05,  1.64it/s]\u001b[A\n",
      "  0%|          | 79/2250484 [00:56<369:05:15,  1.69it/s]\u001b[A\n",
      "  0%|          | 80/2250484 [00:56<330:56:13,  1.89it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 80/2250484] loss=8.6340, ppl=5619.4209, gnorm=1.0450, throughput=0.86K wps, wc=4.16K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 81/2250484 [00:57<321:34:04,  1.94it/s]\u001b[A\n",
      "  0%|          | 82/2250484 [00:57<374:42:31,  1.67it/s]\u001b[A\n",
      "  0%|          | 83/2250484 [00:58<347:48:22,  1.80it/s]\u001b[A\n",
      "  0%|          | 84/2250484 [00:58<357:28:23,  1.75it/s]\u001b[A\n",
      "  0%|          | 85/2250484 [00:59<373:27:36,  1.67it/s]\u001b[A\n",
      "  0%|          | 86/2250484 [01:00<380:25:26,  1.64it/s]\u001b[A\n",
      "  0%|          | 87/2250484 [01:00<337:34:09,  1.85it/s]\u001b[A\n",
      "  0%|          | 88/2250484 [01:01<402:01:40,  1.55it/s]\u001b[A\n",
      "  0%|          | 89/2250484 [01:02<395:25:04,  1.58it/s]\u001b[A\n",
      "  0%|          | 90/2250484 [01:02<355:34:35,  1.76it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 90/2250484] loss=8.1087, ppl=3323.3713, gnorm=1.0961, throughput=0.87K wps, wc=5.14K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 91/2250484 [01:03<339:24:55,  1.84it/s]\u001b[A\n",
      "  0%|          | 92/2250484 [01:03<324:01:00,  1.93it/s]\u001b[A\n",
      "  0%|          | 93/2250484 [01:03<302:38:00,  2.07it/s]\u001b[A\n",
      "  0%|          | 94/2250484 [01:04<293:21:08,  2.13it/s]\u001b[A\n",
      "  0%|          | 95/2250484 [01:04<277:48:16,  2.25it/s]\u001b[A\n",
      "  0%|          | 96/2250484 [01:05<260:51:42,  2.40it/s]\u001b[A\n",
      "  0%|          | 97/2250484 [01:05<298:33:22,  2.09it/s]\u001b[A\n",
      "  0%|          | 98/2250484 [01:06<308:34:28,  2.03it/s]\u001b[A\n",
      "  0%|          | 99/2250484 [01:06<283:26:16,  2.21it/s]\u001b[A\n",
      "  0%|          | 100/2250484 [01:07<293:39:24,  2.13it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 100/2250484] loss=8.8250, ppl=6802.4975, gnorm=0.9962, throughput=0.87K wps, wc=3.96K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 101/2250484 [01:07<267:01:16,  2.34it/s]\u001b[A\n",
      "  0%|          | 102/2250484 [01:07<251:04:05,  2.49it/s]\u001b[A\n",
      "  0%|          | 103/2250484 [01:08<292:04:34,  2.14it/s]\u001b[A\n",
      "  0%|          | 104/2250484 [01:08<302:29:48,  2.07it/s]\u001b[A\n",
      "  0%|          | 105/2250484 [01:09<301:54:10,  2.07it/s]\u001b[A\n",
      "  0%|          | 106/2250484 [01:09<296:44:06,  2.11it/s]\u001b[A\n",
      "  0%|          | 107/2250484 [01:10<295:13:55,  2.12it/s]\u001b[A\n",
      "  0%|          | 108/2250484 [01:10<299:54:27,  2.08it/s]\u001b[A\n",
      "  0%|          | 109/2250484 [01:11<308:36:53,  2.03it/s]\u001b[A\n",
      "  0%|          | 110/2250484 [01:12<336:01:04,  1.86it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 110/2250484] loss=8.7276, ppl=6171.1156, gnorm=0.8806, throughput=0.85K wps, wc=4.16K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 111/2250484 [01:12<315:05:37,  1.98it/s]\u001b[A\n",
      "  0%|          | 112/2250484 [01:12<298:45:43,  2.09it/s]\u001b[A\n",
      "  0%|          | 113/2250484 [01:14<480:20:34,  1.30it/s]\u001b[A\n",
      "  0%|          | 114/2250484 [01:14<404:59:42,  1.54it/s]\u001b[A\n",
      "  0%|          | 115/2250484 [01:14<340:11:38,  1.84it/s]\u001b[A\n",
      "  0%|          | 116/2250484 [01:15<324:57:08,  1.92it/s]\u001b[A\n",
      "  0%|          | 117/2250484 [01:15<295:25:35,  2.12it/s]\u001b[A\n",
      "  0%|          | 118/2250484 [01:16<272:06:23,  2.30it/s]\u001b[A\n",
      "  0%|          | 119/2250484 [01:16<268:02:35,  2.33it/s]\u001b[A\n",
      "  0%|          | 120/2250484 [01:17<273:27:04,  2.29it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 120/2250484] loss=8.5823, ppl=5336.3750, gnorm=1.0365, throughput=0.73K wps, wc=3.64K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 121/2250484 [01:17<402:44:33,  1.55it/s]\u001b[A\n",
      "  0%|          | 0/1 [01:17<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-16ac600c9c93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mhparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     ctx)\n\u001b[0m",
      "\u001b[0;32m~/code/packt/Deep-Learning-with-MXNet-Cookbook/ch06/nmt/utils.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_data_loader, valid_data_loader, loss_function, trainer, translator, tgt_vocab, detokenizer, save_dir, hparams, ctx)\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_valid_length\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtgt_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtgt_valid_length\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/mxnet_p37/gpu_cuda11.0/lib/python3.7/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, out_grad, retain_graph, train_mode)\u001b[0m\n\u001b[1;32m   2871\u001b[0m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2872\u001b[0m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2873\u001b[0;31m             ctypes.c_void_p(0)))\n\u001b[0m\u001b[1;32m   2874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2875\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtostype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nmt.utils.train(\n",
    "    gnmt_model,\n",
    "    wmt_train_data_loader,\n",
    "    wmt_test_data_loader,\n",
    "    wmt_loss_function,\n",
    "    trainer,\n",
    "    gnmt_translator,\n",
    "    wmt_tgt_vocab,\n",
    "    wmt_detokenizer,\n",
    "    hparams.save_dir,\n",
    "    hparams,\n",
    "    ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff2d549",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43c7885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b3d87e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2250484 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "(\n",
      "[[  617 10790   638  9378  6311  9368  1430 10790 10794  7187   617 10790\n",
      "   7168  9384  3038  7337  5929 10791  3038  7182   616   589  2152  9809\n",
      "   9368  9393   589  2998   587  5934  9390 10794  9390  2557   615   599\n",
      "   2986 10408  7188  5927  2553  7173 10409  2117  7939  3595  7187  9809\n",
      "   2570  6303  2986  9385  5935  4098  5023  4993   640  7168  7350   641\n",
      "   7173 10408  7188  5927  2553  7173 10409  2117  7939  3595  5014   574\n",
      "   9987  7177   641  7173  2162  4993  4998   606   618  2141  9987  5924\n",
      "   5929 10419   618    28  8356  4630  9804  2553  8356  9801  4614   616\n",
      "    638  9378  6311  9368  1438  6285   595  2986  7187   630  8356  5020\n",
      "    617  2134  3585  8356  9801  4614   616   638  9374  5432  1438  7373\n",
      "   9981  4975  3009    28  1445  4960 10815 10815   624  2553  3031  9383\n",
      "   9373  4998  6285  3033  7945  3039  9981  3041  9385  7937  4981  4637\n",
      "   9390  8367  2998  5432  2557   615   599  3041  3574  7951   617 10790\n",
      "   8356  9801  4614  9825  3038  9390  9385  3574  9804  5927  3045  3064\n",
      "   9371  3033  7350  6285  5023  9371  3009  1430 10790  5929 10405    62\n",
      "      3]\n",
      " [   65 16083 20615 29829 19887 22370 31131 18531 27990 11815 24693  5284\n",
      "  28302 16383 21983 20618  3284    28  3984    28  4321    28  8978    28\n",
      "   7688    28  5288    28  3764 11815  9317    62  5284 28302 22755 14073\n",
      "  24138    65     3     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0]]\n",
      "<NDArray 2x181 @cpu_shared(0)>, \n",
      "[[    2  5298  3010  3038  9985  8356  9801  4614  2557  9820  2138  8374\n",
      "   2986  7170  3021  3030   617  2570  3030  8389  4960  3024  3038    28\n",
      "   3021  2986  1430  3042  2139 31796  2577  4098  9813  9981  7182 10408\n",
      "   7188  5927  2553  7173 10409  2117  7939  3595  7170  3021  2986  9809\n",
      "   9383  1449  3004  4618  9813  2557  3041  5935  4098  5023  4993  3030\n",
      "   1430  3048  7948  3002  8350  9981  7182 10408  7188  5927  2553  7173\n",
      "  10409  2117  7939  3595  4624  1430  3019 10815  9799  4069  4635  3030\n",
      "     28  2569 10815  9792  4960  4618  7943  6281   589  2152  9809  9368\n",
      "  10815  9820 31879  2117  5435  9985  3574  7177  4098  9368 10408  3039\n",
      "   2567  5435   617  6898    28  8399  3024  5946  3021  2986  9985  5935\n",
      "   9371 10815  9813  7371  5027   638    33  9810  8399  7939  3590  3004\n",
      "   4638  5927  4972  3038  4098  3042  3048 10816  2559  7934    28  9810\n",
      "   1445  4960 10815 10815   624  2553  3031  9383  9373  4998  6285  3033\n",
      "   1439  4618 31796  5946  8356  4971  2559  8350  7937  3004  4637  9981\n",
      "   7187    28  2578  4098  3042  3048 10815  5927  4972  3030  6285 31852\n",
      "   4113  4972  5438  5023  3030  4997  9981  7177  5935  6281  9806  3574\n",
      "    617  4093   584  9825 10815  9825  2139 31852  7337  3574  3030    28\n",
      "   9805  9981  7182  2567  1430  3031  9833 10815  3039  6898    28  2578\n",
      "   3021  3030  8387  2139  3030  9985  8356  9801  4614  9809  9383  6900\n",
      "   7180  6285  3030  7170  9809  9383  8399 31879  9371 10815  9368  4618\n",
      "    587  3030    28  8362   595  3031  3039  8356   638 10814 10815  9792\n",
      "   9985  5932  4108    62     3]\n",
      " [    2  1091 34336 34336 34427 34773 34162 35035 35181 35455 20319 27021\n",
      "  29481 18043 22058 36492 34694 36050 35073 34612 36492 35663 34241 35528\n",
      "  35073 34134 34716 34763 33853 35188 35178 35456 35073 35035 35207 35962\n",
      "  34851 34810 36492 35009 34986 36090 36033 35959 35530 34345 34162 36038\n",
      "  34630 35456 35665 35097 34113 36492 35027 34127 35097 34241 34321 34146\n",
      "  34720 35058 34107 35374 34716 34764 35456 34625 34653 33853 35073 35082\n",
      "  34908 34884 35456 35057 36492 34134 34162 35816 34313 35238 35082 35059\n",
      "  35500 34730 35456 36108 36193 36492 35980 34107 35178 35455 20319 27021\n",
      "  29481 18043 22058 35073 35035 35082 34162 34107 34174 34362 35682 34114\n",
      "  35456 36167 35034 36499 10323 20334  7326 33853 35878 34362 35682 34440\n",
      "  34206 34550 34117 34942 34997 35187 34783 35011 34468 35456 34902 34314\n",
      "  34115 36492 34206 35676 35065 36171 35456 35036 34833 34992 35500 34844\n",
      "  34349 35011 34468 35456 36171 34148 34456 35529 36492 35010 34969   181\n",
      "  35523 35881 35818 35456 35872 34343 36492 34379 34964 34129 35029 34550\n",
      "  34303 33853 35034 20319 27021 29481 18043 22058 34607 34597 36042 35420\n",
      "  35498 35490 36051 34732 35868 35856 36492 36195 35722 35036 36166 35082\n",
      "  36085 35722 34490 35284 35339 35722 34440 35988 36492 35676 36166 35456\n",
      "  34625 34654 36042 35420 34117 36087 36079 35102 35032 33853 34657 34273\n",
      "  34694 36050 34335 34133   455  4103 36492 34501 34211   525 35646 34280\n",
      "  36499 33717   455  4103 24138   120  8879    65     3     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]]\n",
      "<NDArray 2x257 @cpu_shared(0)>, \n",
      "[181.  39.]\n",
      "<NDArray 2 @cpu_shared(0)>, \n",
      "[257. 237.]\n",
      "<NDArray 2 @cpu_shared(0)>, \n",
      "[1944286 1949590]\n",
      "<NDArray 2 @cpu_shared(0)>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'src_seq' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-882b7628460b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0msrc_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_in_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mtgt_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgt_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_in_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0msrc_valid_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc_valid_length\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_in_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'src_seq' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "42b625a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(nmt)\n",
    "reload(nmt.utils)\n",
    "reload(nmt.gnmt_hparams)\n",
    "\n",
    "hparams = nmt.gnmt_hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fc7b0611",
   "metadata": {},
   "outputs": [],
   "source": [
    "wmt_loss_function = nlp.loss.MaskedSoftmaxCELoss()\n",
    "wmt_loss_function.hybridize()\n",
    "wmt_detokenizer = nlp.data.SacreMosesDetokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb827da3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
