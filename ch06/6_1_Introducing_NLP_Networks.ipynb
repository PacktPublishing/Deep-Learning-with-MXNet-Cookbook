{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14d14a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import gluonnlp as nlp\n",
    "\n",
    "ctx = mx.gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce859178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNNs MXNet Implementation Example\n",
    "class RNNModel(mx.gluon.Block):\n",
    "    \"\"\"\n",
    "    A basic RNN Model\n",
    "    \"\"\"\n",
    "    def __init__(self, num_hidden, num_layers, embed_size, **kwargs):\n",
    "        \n",
    "        super(RNNModel, self).__init__(**kwargs)\n",
    "        \n",
    "        self.rnn = mx.gluon.rnn.RNN(\n",
    "            num_hidden,\n",
    "            num_layers,\n",
    "            input_size=embed_size)\n",
    "        \n",
    "        \n",
    "    def forward(self, inputs, hidden):\n",
    "        output, hidden = self.rnn(inputs, hidden)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a788839a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN with 3 hidden cells, 1 layer and expecting inputs with 20 embeddings\n",
    "rnn = RNNModel(3, 1, 20)\n",
    "rnn.collect_params().initialize(mx.init.Xavier(), ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf4682df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Hidden Values\n",
    "hidden_initial = mx.nd.random.randn(1, 1, 3, ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "299f8d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs generation\n",
    "# Let's input 3 words \n",
    "# Each word is passed through a 20-component embedding model\n",
    "inputs = []\n",
    "\n",
    "# Each word representation\n",
    "inputs.append(mx.nd.random.randn(3, 1, 20, ctx=ctx))\n",
    "inputs.append(mx.nd.random.randn(3, 1, 20, ctx=ctx))\n",
    "inputs.append(mx.nd.random.randn(3, 1, 20, ctx=ctx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bced23a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extension horovod.torch has not been built: /home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/site-packages/horovod/torch/mpi_lib/_mpi_lib.cpython-37m-x86_64-linux-gnu.so not found\n",
      "If this is not expected, reinstall Horovod with HOROVOD_WITH_PYTORCH=1 to debug the build error.\n",
      "Warning! MPI libs are missing, but python applications are still avaiable.\n",
      "[2022-07-28 11:51:11.543 ip-172-31-28-47:19469 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2022-07-28 11:51:11.572 ip-172-31-28-47:19469 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\n",
      "[[[0.36091858 0.         0.        ]]\n",
      "\n",
      " [[0.7694626  1.3475145  0.5260414 ]]\n",
      "\n",
      " [[0.         0.         0.        ]]]\n",
      "<NDArray 3x1x3 @gpu(0)> [\n",
      "[[[0. 0. 0.]]]\n",
      "<NDArray 1x1x3 @gpu(0)>]\n"
     ]
    }
   ],
   "source": [
    "rnn_hidden = hidden_initial\n",
    "outputs = []\n",
    "\n",
    "for index in range(3):\n",
    "    rnn_output, rnn_hidden = rnn(inputs[index], rnn_hidden)\n",
    "    outputs.append(rnn_output)\n",
    "\n",
    "print(rnn_output, rnn_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64ff8f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTMs MXNet Implementation Example\n",
    "class LSTMModel(mx.gluon.Block):\n",
    "    \"\"\"\n",
    "    A basic LSTM Model\n",
    "    \"\"\"\n",
    "    def __init__(self, num_hidden, num_layers, embed_size, **kwargs):\n",
    "        \n",
    "        super(LSTMModel, self).__init__(**kwargs)\n",
    "        \n",
    "        self.lstm = mx.gluon.rnn.LSTM(\n",
    "            num_hidden,\n",
    "            num_layers,\n",
    "            input_size=embed_size)\n",
    "        \n",
    "        \n",
    "    def forward(self, inputs, hidden):\n",
    "        output, hidden = self.lstm(inputs, hidden)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e0704b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM with 3 hidden cells, 1 layer and expecting inputs with 20 embeddings\n",
    "lstm = LSTMModel(3, 1, 20)\n",
    "lstm.collect_params().initialize(mx.init.Xavier(), ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd156fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Hidden Values\n",
    "hidden_initial = mx.nd.random.randn(1, 1, 3, ctx=ctx)\n",
    "\n",
    "# Initial State Values\n",
    "state_initial = mx.nd.random.randn(1, 1, 3, ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "430f036f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[[ 0.11808932  0.00715288 -0.17337681]]\n",
      "\n",
      " [[ 0.05276631 -0.31671402  0.26189104]]\n",
      "\n",
      " [[-0.2773834   0.00210142  0.2504536 ]]]\n",
      "<NDArray 3x1x3 @gpu(0)> [\n",
      "[[[-0.2773834   0.00210142  0.2504536 ]]]\n",
      "<NDArray 1x1x3 @gpu(0)>, \n",
      "[[[-0.42638525  0.0045678   0.40797684]]]\n",
      "<NDArray 1x1x3 @gpu(0)>]\n"
     ]
    }
   ],
   "source": [
    "lstm_hidden = [hidden_initial, state_initial]\n",
    "outputs = []\n",
    "\n",
    "for index in range(3):\n",
    "    lstm_output, lstm_hidden = lstm(inputs[index], lstm_hidden)\n",
    "    outputs.append(lstm_output)\n",
    "\n",
    "print(lstm_output, lstm_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7247295e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformers MXNet Implementation Example\n",
    "# Transformer with 6 layers (encoder and decoder), 2 parallel heads, and expecting inputs with 20 embeddings\n",
    "transformer_encoder, transformer_decoder, _ = nlp.model.transformer.get_transformer_encoder_decoder(\n",
    "    num_layers=6,\n",
    "    num_heads=2,\n",
    "    units=20)\n",
    "\n",
    "transformer_encoder.collect_params().initialize(mx.init.Xavier(), ctx=ctx)\n",
    "transformer_decoder.collect_params().initialize(mx.init.Xavier(), ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e039951f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[[ 0.83209103 -1.6060255   0.22104202  0.61695844  1.3568467\n",
      "   -0.32727766  0.91617656  0.10976635 -0.9734795  -2.0243998\n",
      "   -0.3601701   0.6375824  -0.7103551  -0.5400416   1.0467256\n",
      "   -0.48623165 -0.74315417 -0.5523693   2.1838753   0.40243995]]\n",
      "\n",
      " [[ 0.8831734  -0.9573856   0.91161126  0.297851    0.1370347\n",
      "   -0.6730614   0.6583741   0.519483   -1.2481059  -1.0314509\n",
      "    0.52972645  0.21611245 -1.0184485  -0.18149762 -0.18714839\n",
      "   -0.46389332 -2.1304226   0.01332407  2.3436754   1.3810486 ]]\n",
      "\n",
      " [[ 0.10657646  0.41115397 -1.4852034  -0.40792608 -0.36205494\n",
      "   -0.65480286 -1.2349089  -0.35988408 -0.16835214  3.1068172\n",
      "   -0.88195777 -0.2612006   0.30937973  0.4125706   0.600156\n",
      "   -0.81594104  0.7318146   0.38038185 -0.8467938   1.4201748 ]]]\n",
      "<NDArray 3x1x20 @gpu(0)>\n"
     ]
    }
   ],
   "source": [
    "# Only encoder shown\n",
    "encoded_inputs, _ = transformer_encoder(inputs[0])\n",
    "\n",
    "print(encoded_inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
