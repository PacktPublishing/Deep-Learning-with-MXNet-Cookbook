{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbbe216b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/andreto/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/andreto/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/andreto/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "import gluonnlp as nlp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import sacremoses\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Local Libraries\n",
    "import nmt\n",
    "import dataprocessor\n",
    "import utils\n",
    "import nmt.transformer_hparams\n",
    "\n",
    "# Seeds for reproducibility\n",
    "np.random.seed(100)\n",
    "random.seed(100)\n",
    "mx.random.seed(10000)\n",
    "\n",
    "# CPU setup\n",
    "# ctx = mx.cpu()\n",
    "# Single GPU setup\n",
    "ctx = mx.gpu(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bac926f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andreto/.local/lib/python3.7/site-packages/gluonnlp/vocab/vocab.py:591: UserWarning: Detected a corrupted index in the deserialize vocabulary. For versions before GluonNLP v0.7 the index is corrupted by specifying the same token for different special purposes, for example eos_token == padding_token. Deserializing the vocabulary nevertheless.\n",
      "  'Detected a corrupted index in the deserialize vocabulary. '\n"
     ]
    }
   ],
   "source": [
    "# IWSLT2015 Dataset (Train, Validation and Test)\n",
    "\n",
    "# Dataset Parameters\n",
    "src_lang, tgt_lang = \"vi\", \"en\"\n",
    "src_max_len, tgt_max_len = 50, 50\n",
    "\n",
    "iwslt_train_text = nlp.data.IWSLT2015(\"train\",\n",
    "                                      src_lang=src_lang,\n",
    "                                      tgt_lang=tgt_lang)\n",
    "\n",
    "iwslt_val_text   = nlp.data.IWSLT2015(\"val\",\n",
    "                                      src_lang=src_lang,\n",
    "                                      tgt_lang=tgt_lang)\n",
    "\n",
    "iwslt_test_text  = nlp.data.IWSLT2015(\"test\",\n",
    "                                      src_lang=src_lang,\n",
    "                                      tgt_lang=tgt_lang)\n",
    "\n",
    "\n",
    "iwslt_src_vocab = iwslt_train_text.src_vocab\n",
    "iwslt_tgt_vocab = iwslt_train_text.tgt_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a3383d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train set: 133166\n",
      "Length of val set  : 1553\n",
      "Length of test set : 1268\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of train set:\", len(iwslt_train_text))\n",
    "print(\"Length of val set  :\", len(iwslt_val_text))\n",
    "print(\"Length of test set :\", len(iwslt_test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "075d11ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset processing: clipping, tokenizing, indexing and adding of EOS (src/tgt) / BOS (tgt)\n",
    "iwslt_train_processed = iwslt_train_text.transform(\n",
    "    dataprocessor.TrainValDataTransform(\n",
    "        iwslt_src_vocab,\n",
    "        iwslt_tgt_vocab,\n",
    "        src_max_len,\n",
    "        tgt_max_len),\n",
    "    lazy=False)\n",
    "\n",
    "iwslt_val_processed   = iwslt_val_text.transform(\n",
    "    dataprocessor.TrainValDataTransform(\n",
    "        iwslt_src_vocab,\n",
    "        iwslt_tgt_vocab,\n",
    "        src_max_len,\n",
    "        tgt_max_len),\n",
    "    lazy=False)\n",
    "\n",
    "iwslt_test_processed  = iwslt_test_text.transform(\n",
    "    dataprocessor.TrainValDataTransform(\n",
    "        iwslt_src_vocab,\n",
    "        iwslt_tgt_vocab,\n",
    "        src_max_len,\n",
    "        tgt_max_len),\n",
    "    lazy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3884e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Sequences (Val, Test)\n",
    "fetch_tgt_sentence = lambda src, tgt: tgt.split()\n",
    "val_tgt_sentences = list(iwslt_val_text.transform(fetch_tgt_sentence))\n",
    "test_tgt_sentences = list(iwslt_test_text.transform(fetch_tgt_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c26bf695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Gluon Datasets\n",
    "# Not needed for training, as training data will be sharded later\n",
    "iwslt_train_transformed = iwslt_train_processed.transform(\n",
    "    lambda src, tgt: (src, tgt, len(src), len(tgt)),\n",
    "    lazy=False)\n",
    "\n",
    "iwslt_val_dataset = mx.gluon.data.SimpleDataset(\n",
    "    [(ele[0], ele[1], len(ele[0]), len(ele[1]),i) for i, ele in enumerate(iwslt_val_processed)])\n",
    "\n",
    "iwslt_test_dataset = mx.gluon.data.SimpleDataset(\n",
    "    [(ele[0], ele[1], len(ele[0]), len(ele[1]), i) for i, ele in enumerate(iwslt_test_processed)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0278d19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for Dataloaders and Training\n",
    "hparams = nmt.transformer_hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19d16ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams.lr = 0.001\n",
    "hparams.max_length = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32d3a2d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andreto/.local/lib/python3.7/site-packages/gluonnlp/data/batchify/batchify.py:235: UserWarning: Padding value is not given and will be set automatically to 0 in data.batchify.Pad(). Please check whether this is intended (e.g. value of padding index in the vocabulary).\n",
      "  'Padding value is not given and will be set automatically to 0 '\n",
      "Process ForkPoolWorker-7:\n",
      "Process ForkPoolWorker-1:\n",
      "Process ForkPoolWorker-8:\n",
      "Process ForkPoolWorker-2:\n",
      "Process ForkPoolWorker-4:\n",
      "Process ForkPoolWorker-3:\n",
      "Process ForkPoolWorker-6:\n",
      "Process ForkPoolWorker-5:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/multiprocessing/queues.py\", line 352, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# Create Gluon Samplers and DataLoaders\n",
    "\n",
    "# Helper function for lengths\n",
    "def get_data_lengths(dataset):\n",
    "    get_lengths = lambda *args: (args[2], args[3])\n",
    "    return list(dataset.transform(get_lengths))\n",
    "\n",
    "# Bucket scheme\n",
    "bucket_scheme = nlp.data.ExpWidthBucket(bucket_len_step=1.2)\n",
    "\n",
    "iwslt_train_lengths = get_data_lengths(iwslt_train_transformed)\n",
    "iwslt_val_lengths = get_data_lengths(iwslt_val_dataset)\n",
    "iwslt_test_lengths = get_data_lengths(iwslt_test_dataset)\n",
    "\n",
    "train_batchify_fn = nlp.data.batchify.Tuple(\n",
    "    nlp.data.batchify.Pad(),\n",
    "    nlp.data.batchify.Pad(),\n",
    "    nlp.data.batchify.Stack(dtype='float32'),\n",
    "    nlp.data.batchify.Stack(dtype='float32'))\n",
    "\n",
    "test_batchify_fn = nlp.data.batchify.Tuple(\n",
    "    nlp.data.batchify.Pad(),\n",
    "    nlp.data.batchify.Pad(),\n",
    "    nlp.data.batchify.Stack(dtype='float32'),\n",
    "    nlp.data.batchify.Stack(dtype='float32'),\n",
    "    nlp.data.batchify.Stack())\n",
    "\n",
    "target_val_lengths = list(map(lambda x: x[-1], iwslt_val_lengths))\n",
    "target_test_lengths = list(map(lambda x: x[-1], iwslt_test_lengths))\n",
    "\n",
    "train_batch_sampler = nlp.data.FixedBucketSampler(\n",
    "    lengths=iwslt_train_lengths,\n",
    "    batch_size=hparams.batch_size,\n",
    "    num_buckets=hparams.num_buckets,\n",
    "    ratio=0,\n",
    "    shuffle=True,\n",
    "    use_average_length=False,\n",
    "    num_shards=0,\n",
    "    bucket_scheme=bucket_scheme)\n",
    "    \n",
    "train_data_loader = nlp.data.ShardedDataLoader(\n",
    "    iwslt_train_transformed,\n",
    "    batch_sampler=train_batch_sampler,\n",
    "    batchify_fn=train_batchify_fn,\n",
    "    num_workers=8)\n",
    "\n",
    "val_batch_sampler = nlp.data.FixedBucketSampler(\n",
    "    lengths=iwslt_val_lengths,\n",
    "    batch_size=hparams.test_batch_size,\n",
    "    num_buckets=hparams.num_buckets,\n",
    "    ratio=0,\n",
    "    shuffle=False,\n",
    "    use_average_length=False,\n",
    "    bucket_scheme=bucket_scheme)\n",
    "\n",
    "val_data_loader = mx.gluon.data.DataLoader(\n",
    "    iwslt_val_dataset,\n",
    "    batch_sampler=val_batch_sampler,\n",
    "    batchify_fn=test_batchify_fn,\n",
    "    num_workers=8)\n",
    "\n",
    "test_batch_sampler = nlp.data.FixedBucketSampler(\n",
    "    lengths=iwslt_test_lengths,\n",
    "    batch_size=hparams.test_batch_size,\n",
    "    num_buckets=hparams.num_buckets,\n",
    "    ratio=0,\n",
    "    shuffle=False,\n",
    "    use_average_length=False,\n",
    "    bucket_scheme=bucket_scheme)\n",
    "\n",
    "test_data_loader = mx.gluon.data.DataLoader(\n",
    "    iwslt_test_dataset,\n",
    "    batch_sampler=test_batch_sampler,\n",
    "    batchify_fn=test_batchify_fn,\n",
    "    num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6433aa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer Model\n",
    "transformer_encoder, transformer_decoder, transformer_one_step_ahead_decoder = nlp.model.transformer.get_transformer_encoder_decoder(\n",
    "    hidden_size=hparams.num_hidden,\n",
    "    dropout=hparams.dropout,\n",
    "    num_layers=hparams.num_layers)\n",
    "\n",
    "transformer_model = nlp.model.translation.NMTModel(\n",
    "    src_vocab=iwslt_src_vocab,\n",
    "    tgt_vocab=iwslt_tgt_vocab,\n",
    "    encoder=transformer_encoder,\n",
    "    decoder=transformer_decoder,\n",
    "    one_step_ahead_decoder=transformer_one_step_ahead_decoder,\n",
    "    #embed_size=hparams.num_hidden,\n",
    "    embed_size=hparams.num_units,\n",
    "    prefix='transformer_')\n",
    "\n",
    "transformer_model.initialize(init=mx.init.Xavier(magnitude=1.0), ctx=ctx)\n",
    "static_alloc = True\n",
    "transformer_model.hybridize(static_alloc=static_alloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d3ae74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translator (using model defined above)\n",
    "transformer_translator = nmt.translation.BeamSearchTranslator(\n",
    "    model=transformer_model,\n",
    "    beam_size=hparams.beam_size,\n",
    "    scorer=nlp.model.BeamSearchScorer(\n",
    "        alpha=hparams.lp_alpha,\n",
    "        K=hparams.lp_k),\n",
    "    max_length=hparams.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "076325eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "loss_function = nlp.loss.MaskedSoftmaxCELoss()\n",
    "loss_function.hybridize(static_alloc=static_alloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0707abf5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85d59902955042ea8fe1218c5b964777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9f9b64ce99447c38efd6f13b4d0b032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1043 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extension horovod.torch has not been built: /home/ubuntu/anaconda3/envs/mxnet_p37/lib/python3.7/site-packages/horovod/torch/mpi_lib/_mpi_lib.cpython-37m-x86_64-linux-gnu.so not found\n",
      "If this is not expected, reinstall Horovod with HOROVOD_WITH_PYTORCH=1 to debug the build error.\n",
      "Warning! MPI libs are missing, but python applications are still avaiable.\n",
      "[2022-08-10 13:15:21.499 ip-172-31-28-47:12165 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2022-08-10 13:15:21.529 ip-172-31-28-47:12165 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "[Epoch 0 Batch 100/1043] loss=6.5200, ppl=678.5641, gnorm=1.4299, throughput=44.41K wps, wc=606.57K\n",
      "[Epoch 0 Batch 200/1043] loss=6.3055, ppl=547.5758, gnorm=1.0860, throughput=49.11K wps, wc=584.18K\n",
      "[Epoch 0 Batch 300/1043] loss=6.3204, ppl=555.7819, gnorm=1.1604, throughput=49.59K wps, wc=592.78K\n",
      "[Epoch 0 Batch 400/1043] loss=6.2811, ppl=534.4000, gnorm=1.0152, throughput=48.59K wps, wc=571.26K\n",
      "[Epoch 0 Batch 500/1043] loss=6.2823, ppl=535.0114, gnorm=0.9928, throughput=48.29K wps, wc=554.48K\n",
      "[Epoch 0 Batch 600/1043] loss=6.2867, ppl=537.3667, gnorm=1.1398, throughput=48.14K wps, wc=546.26K\n",
      "[Epoch 0 Batch 700/1043] loss=6.2730, ppl=530.0703, gnorm=1.0216, throughput=48.77K wps, wc=566.96K\n",
      "[Epoch 0 Batch 800/1043] loss=6.2736, ppl=530.3932, gnorm=0.9553, throughput=48.01K wps, wc=551.40K\n",
      "[Epoch 0 Batch 900/1043] loss=6.2769, ppl=532.1404, gnorm=0.9384, throughput=49.26K wps, wc=577.61K\n",
      "[Epoch 0 Batch 1000/1043] loss=6.2788, ppl=533.1421, gnorm=1.2821, throughput=48.80K wps, wc=588.16K\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f0711192d174d888e035fb0071b537c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] valid Loss=6.1962, valid ppl=490.8849, valid bleu=0.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e59d00ef4e0c4d35b7c7fb2d0eb9764b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1043 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1 Batch 100/1043] loss=6.2946, ppl=541.6185, gnorm=0.9731, throughput=49.51K wps, wc=593.66K\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-ca8f411c8e58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransformer_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_req\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'null'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mgnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgluon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_global_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/mxnet_p37/gpu_cuda11.0/lib/python3.7/site-packages/mxnet/gluon/utils.py\u001b[0m in \u001b[0;36mclip_global_norm\u001b[0;34m(arrays, max_norm, check_isfinite)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mndarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcheck_isfinite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m             warnings.warn(\n\u001b[1;32m    152\u001b[0m                 UserWarning('nan or inf is detected. '\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/mxnet_p37/gpu_cuda11.0/lib/python3.7/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masscalar\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2583\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The current array is not a scalar\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2585\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2586\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2587\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/mxnet_p37/gpu_cuda11.0/lib/python3.7/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2564\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2565\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2566\u001b[0;31m             ctypes.c_size_t(data.size)))\n\u001b[0m\u001b[1;32m   2567\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Let's train\n",
    "trainer = mx.gluon.Trainer(transformer_model.collect_params(), hparams.optimizer, {'learning_rate': hparams.lr})\n",
    "\n",
    "best_valid_bleu = 0.0\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "valid_bleus  = []\n",
    "valid_perplexities = []\n",
    "\n",
    "for epoch_id in tqdm(range(hparams.epochs)):\n",
    "\n",
    "    log_loss = 0\n",
    "    log_denom = 0\n",
    "    log_avg_gnorm = 0\n",
    "    log_wc = 0\n",
    "    log_start_time = time.time()\n",
    "    \n",
    "    for batch_id, (src_seq, tgt_seq, src_valid_length, tgt_valid_length) in enumerate(tqdm(train_data_loader)):\n",
    "        \n",
    "        src_seq = src_seq.as_in_context(ctx)\n",
    "        tgt_seq = tgt_seq.as_in_context(ctx)\n",
    "        src_valid_length = src_valid_length.as_in_context(ctx)\n",
    "        tgt_valid_length = tgt_valid_length.as_in_context(ctx)\n",
    "        \n",
    "        with mx.autograd.record():\n",
    "            out, _ = transformer_model(\n",
    "                src_seq,\n",
    "                tgt_seq[:, :-1],\n",
    "                src_valid_length,\n",
    "                tgt_valid_length - 1)\n",
    "\n",
    "            loss = loss_function(out, tgt_seq[:, 1:], tgt_valid_length - 1).mean()\n",
    "            loss = loss * (tgt_seq.shape[1] - 1)\n",
    "            log_loss += loss * tgt_seq.shape[0]\n",
    "            log_denom += (tgt_valid_length - 1).sum()\n",
    "            loss = loss / (tgt_valid_length - 1).mean()\n",
    "            loss.backward()\n",
    "        \n",
    "        grads = [p.grad(ctx) for p in transformer_model.collect_params().values() if p.grad_req != 'null']\n",
    "        gnorm = mx.gluon.utils.clip_global_norm(grads, hparams.clip)\n",
    "        trainer.step(1)\n",
    "        \n",
    "        src_wc = src_valid_length.sum().asscalar()\n",
    "        tgt_wc = (tgt_valid_length - 1).sum().asscalar()\n",
    "        log_loss = log_loss.asscalar()\n",
    "        log_denom = log_denom.asscalar()\n",
    "        log_avg_gnorm += gnorm\n",
    "        log_wc += src_wc + tgt_wc\n",
    "        \n",
    "        train_loss = log_loss / log_denom\n",
    "        \n",
    "        if (batch_id + 1) % hparams.log_interval == 0:\n",
    "            wps = log_wc / (time.time() - log_start_time)\n",
    "            print(\"[Epoch {} Batch {}/{}] loss={:.4f}, ppl={:.4f}, gnorm={:.4f}, \"\n",
    "                         \"throughput={:.2f}K wps, wc={:.2f}K\"\n",
    "                         .format(epoch_id, batch_id + 1, len(train_data_loader),\n",
    "                                 train_loss,\n",
    "                                 np.exp(log_loss / log_denom),\n",
    "                                 log_avg_gnorm / hparams.log_interval,\n",
    "                                 wps / 1000, log_wc / 1000))\n",
    "            \n",
    "            log_start_time = time.time()\n",
    "            log_loss = 0\n",
    "            log_denom = 0\n",
    "            log_avg_gnorm = 0\n",
    "            log_wc = 0\n",
    "            \n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    valid_loss, valid_translation_out = nmt.utils.evaluate(\n",
    "        val_data_loader,\n",
    "        transformer_model,\n",
    "        transformer_translator,\n",
    "        loss_function,\n",
    "        iwslt_tgt_vocab,\n",
    "        ctx)\n",
    "\n",
    "    valid_perplexity = np.exp(valid_loss)\n",
    "    valid_perplexities.append(valid_perplexity)\n",
    "    \n",
    "    valid_bleu_score, _, _, _, _ = nmt.bleu.compute_bleu([val_tgt_sentences], valid_translation_out)\n",
    "    print(\"[Epoch {}] valid Loss={:.4f}, valid ppl={:.4f}, valid bleu={:.2f}\"\n",
    "          .format(epoch_id, valid_loss, valid_perplexity, valid_bleu_score * 100))\n",
    "    \n",
    "    valid_losses.append(valid_loss)\n",
    "    valid_bleus.append(valid_bleu_score * 100)\n",
    "\n",
    "    if valid_bleu_score > best_valid_bleu:\n",
    "        best_valid_bleu = valid_bleu_score\n",
    "        print(\"Save best parameters to {}\".format(hparams.file_name))\n",
    "        transformer_model.save_parameters(hparams.file_name)\n",
    "    \n",
    "    if epoch_id + 1 >= (hparams.epochs * 2) // 3:\n",
    "        new_lr = trainer.learning_rate * hparams.lr_update_factor\n",
    "        print(\"Learning rate change to {}\".format(new_lr))\n",
    "        trainer.set_learning_rate(new_lr)\n",
    "\n",
    "if os.path.exists(hparams.file_name):\n",
    "    transformer_model.load_parameters(hparams.file_name)\n",
    "\n",
    "valid_loss, valid_translation_out = nmt.utils.evaluate(\n",
    "    val_data_loader,\n",
    "    transformer_model,\n",
    "    transformer_translator,\n",
    "    loss_function,\n",
    "    iwslt_tgt_vocab,\n",
    "    ctx)\n",
    "\n",
    "valid_bleu_score, _, _, _, _ = nmt.bleu.compute_bleu([val_tgt_sentences], valid_translation_out)\n",
    "print(\"Best model valid Loss={:.4f}, valid ppl={:.4f}, valid bleu={:.2f}\"\n",
    "      .format(valid_loss, np.exp(valid_loss), valid_bleu_score * 100))\n",
    "\n",
    "test_loss, test_translation_out = nmt.utils.evaluate(\n",
    "    test_data_loader,\n",
    "    transformer_model,\n",
    "    transformer_translator,\n",
    "    loss_function,\n",
    "    iwslt_tgt_vocab,\n",
    "    ctx)\n",
    "\n",
    "test_bleu_score, _, _, _, _ = nmt.bleu.compute_bleu([test_tgt_sentences], test_translation_out)\n",
    "print(\"Best model test Loss={:.4f}, test ppl={:.4f}, test bleu={:.2f}\"\n",
    "      .format(test_loss, np.exp(test_loss), test_bleu_score * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cded54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot losses and validation accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(range(0, hparams.epochs), train_losses, label=\"Training Loss\")\n",
    "plt.plot(range(0, hparams.epochs), valid_losses, label=\"Validation Loss\")\n",
    "plt.plot(range(0, hparams.epochs), valid_perplexities, label=\"Validation Perplexity\")\n",
    "plt.plot(range(0, hparams.epochs), valid_bleus, label=\"Validation BLEU\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"Losses / Perplexity / BLEU\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe7107c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Qualitative Evaluation: Translating from Vietnamese to English\")\n",
    "\n",
    "expected_tgt_seq = \"I like to read books.\"\n",
    "print(\"Expected translation:\")\n",
    "print(expected_tgt_seq)\n",
    "# From Google Translate\n",
    "src_seq = \"Tôi thích đọc sách kỹ thuật.\"\n",
    "print(\"In Vietnamese (from Google Translate):\")\n",
    "print(src_seq)\n",
    "\n",
    "translation_out = nmt.utils.translate(\n",
    "    transformer_translator,\n",
    "    src_seq,\n",
    "    iwslt_src_vocab,\n",
    "    iwslt_tgt_vocab,\n",
    "    ctx)\n",
    "\n",
    "print(\"The English translation is:\")\n",
    "print(\" \".join(translation_out[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
